{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milkpotato1000/project_NVISIA/blob/main/s_news_categorizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZYovUNaSwrA"
      },
      "source": [
        "### 데이터 로드 from google drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aM7uPZUSVMfk",
        "outputId": "a9616c3c-a138-4234-cbac-974761eefd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3e25ccec",
        "outputId": "0db8588d-8ed5-4311-d09c-025fac79aee3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1V8mFCYrE446qqdx7lAkgLdBmKUEbOtwp\n",
            "To: /content/downloaded_file.csv\n",
            "100%|██████████| 41.8M/41.8M [00:02<00:00, 19.8MB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              id                            title  \\\n",
              "0  spnews_101404  北, 신의주온실종합농장 건설장 지대정리·잔디심기 마감단계   \n",
              "1  spnews_101403              北,  나무 사름률 높이는 제품은?   \n",
              "2  spnews_101402            北 개성시, 식물방역소·돼지종축장 신축   \n",
              "3  spnews_101394         [北 물가] 가을 추수 영향, 곡물가 내림세   \n",
              "4  spnews_101392  북한 각지서 어머니날 경축... 김일성-김정일 동상 참배   \n",
              "\n",
              "                                            contents  source section  \\\n",
              "0  북한 평안북도 신의주온실종합농장 건설장에서 방대한 면적의 지대정리와 잔디심기가 마감...  spnews     북한N   \n",
              "1  북한이 나무의 사름률을 보장에 효과적인 과학기술제품으로 천연생물활성제 등이 있다고 ...  spnews     북한N   \n",
              "2  북한 개성시에서 식물방역소와 돼지종축장 새로 건설했다.\\n노동신문은 17일 \"개성시...  spnews     북한N   \n",
              "3  북한지역에서 가을 추수가 마무리 되면서 쌀과 옥수수 등 곡물류 가격이 내림세로 돌아...  spnews     북한N   \n",
              "4  북한 각지에서 어머니날(11월 16일)을 경축했다.\\n노동신문은 17일 \"어머니날을...  spnews     북한N   \n",
              "\n",
              "     author publish_date                                                url  \\\n",
              "0   안윤석 대기자   2025-11-17  https://www.spnews.co.kr/news/articleView.html...   \n",
              "1  안윤석  대기자   2025-11-17  https://www.spnews.co.kr/news/articleView.html...   \n",
              "2  안윤석  대기자   2025-11-17  https://www.spnews.co.kr/news/articleView.html...   \n",
              "3   안윤석 대기자   2025-11-17  https://www.spnews.co.kr/news/articleView.html...   \n",
              "4  안윤석  대기자   2025-11-17  https://www.spnews.co.kr/news/articleView.html...   \n",
              "\n",
              "   category                                            summary  \\\n",
              "0     경제/산업  신의주온실종합농장 건설장에서 지대정리와 잔디심기가 마감단계에 이르고 있다. 군민건설...   \n",
              "1     경제/산업  북한이 나무의 사름률을 높이는 과학기술제품으로 천연생물활성제를 소개했다. 이 제품은...   \n",
              "2  사회/문화/체육  북한 개성시에서 식물방역소와 돼지종축장이 새로 건설되었다. 개성시식물방역소 건설에 ...   \n",
              "3     경제/산업  가을 추수가 마무리되면서 북한의 곡물 가격이 하락세를 보이고 있다. 평양, 혜산, ...   \n",
              "4  사회/문화/체육  북한 각지에서 어머니날을 경축하며 김일성-김정일 동상에 꽃다발을 바쳤다. 공산주의어...   \n",
              "\n",
              "                    keywords           event_title  event_date event_person  \\\n",
              "0  신의주, 온실농장, 지대정리, 잔디심기, 건설     신의주온실종합농장 건설 마감단계  2025-11-17          NaN   \n",
              "1   나무, 사름률, 천연생물활성제, 제품, 북한  북한, 나무 사름률 높이는 제품 소개  2025-11-17          NaN   \n",
              "2  개성시, 식물방역소, 돼지종축장, 건설, 농업  개성시, 식물방역소와 돼지종축장 신축  2025-11-17          NaN   \n",
              "3     곡물가, 하락, 가을 추수, 물가, 북한      가을 추수로 인한 곡물가 하락  2025-11-15          NaN   \n",
              "4    어머니날, 경축, 동상, 공연, 여성근로자            어머니날 경축 행사  2025-11-16          NaN   \n",
              "\n",
              "                     event_org                       event_loc  \\\n",
              "0                          NaN                       평안북도, 신의주   \n",
              "1                          NaN                             NaN   \n",
              "2  개성시식물방역소, 시남새온실, 시유기질복합비료공장                             개성시   \n",
              "3                          NaN             평양시, 혜산시, 원산시, 사리원시   \n",
              "4                          NaN  평안남도, 황해북도, 강원도, 양강도, 나선시, 개성시   \n",
              "\n",
              "   p_rice(won/kg)  p_corn(won/kg)  p_usd(won/usd)  job_cost  \n",
              "0             NaN             NaN             NaN  0.000318  \n",
              "1             NaN             NaN             NaN  0.000335  \n",
              "2             NaN             NaN             NaN  0.000313  \n",
              "3         19850.0          4500.0         34600.0  0.000379  \n",
              "4             NaN             NaN             NaN  0.000316  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c33c109d-374b-4de3-84fd-f69bd523634a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>contents</th>\n",
              "      <th>source</th>\n",
              "      <th>section</th>\n",
              "      <th>author</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>url</th>\n",
              "      <th>category</th>\n",
              "      <th>summary</th>\n",
              "      <th>keywords</th>\n",
              "      <th>event_title</th>\n",
              "      <th>event_date</th>\n",
              "      <th>event_person</th>\n",
              "      <th>event_org</th>\n",
              "      <th>event_loc</th>\n",
              "      <th>p_rice(won/kg)</th>\n",
              "      <th>p_corn(won/kg)</th>\n",
              "      <th>p_usd(won/usd)</th>\n",
              "      <th>job_cost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spnews_101404</td>\n",
              "      <td>北, 신의주온실종합농장 건설장 지대정리·잔디심기 마감단계</td>\n",
              "      <td>북한 평안북도 신의주온실종합농장 건설장에서 방대한 면적의 지대정리와 잔디심기가 마감...</td>\n",
              "      <td>spnews</td>\n",
              "      <td>북한N</td>\n",
              "      <td>안윤석 대기자</td>\n",
              "      <td>2025-11-17</td>\n",
              "      <td>https://www.spnews.co.kr/news/articleView.html...</td>\n",
              "      <td>경제/산업</td>\n",
              "      <td>신의주온실종합농장 건설장에서 지대정리와 잔디심기가 마감단계에 이르고 있다. 군민건설...</td>\n",
              "      <td>신의주, 온실농장, 지대정리, 잔디심기, 건설</td>\n",
              "      <td>신의주온실종합농장 건설 마감단계</td>\n",
              "      <td>2025-11-17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>평안북도, 신의주</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spnews_101403</td>\n",
              "      <td>北,  나무 사름률 높이는 제품은?</td>\n",
              "      <td>북한이 나무의 사름률을 보장에 효과적인 과학기술제품으로 천연생물활성제 등이 있다고 ...</td>\n",
              "      <td>spnews</td>\n",
              "      <td>북한N</td>\n",
              "      <td>안윤석  대기자</td>\n",
              "      <td>2025-11-17</td>\n",
              "      <td>https://www.spnews.co.kr/news/articleView.html...</td>\n",
              "      <td>경제/산업</td>\n",
              "      <td>북한이 나무의 사름률을 높이는 과학기술제품으로 천연생물활성제를 소개했다. 이 제품은...</td>\n",
              "      <td>나무, 사름률, 천연생물활성제, 제품, 북한</td>\n",
              "      <td>북한, 나무 사름률 높이는 제품 소개</td>\n",
              "      <td>2025-11-17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spnews_101402</td>\n",
              "      <td>北 개성시, 식물방역소·돼지종축장 신축</td>\n",
              "      <td>북한 개성시에서 식물방역소와 돼지종축장 새로 건설했다.\\n노동신문은 17일 \"개성시...</td>\n",
              "      <td>spnews</td>\n",
              "      <td>북한N</td>\n",
              "      <td>안윤석  대기자</td>\n",
              "      <td>2025-11-17</td>\n",
              "      <td>https://www.spnews.co.kr/news/articleView.html...</td>\n",
              "      <td>사회/문화/체육</td>\n",
              "      <td>북한 개성시에서 식물방역소와 돼지종축장이 새로 건설되었다. 개성시식물방역소 건설에 ...</td>\n",
              "      <td>개성시, 식물방역소, 돼지종축장, 건설, 농업</td>\n",
              "      <td>개성시, 식물방역소와 돼지종축장 신축</td>\n",
              "      <td>2025-11-17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>개성시식물방역소, 시남새온실, 시유기질복합비료공장</td>\n",
              "      <td>개성시</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spnews_101394</td>\n",
              "      <td>[北 물가] 가을 추수 영향, 곡물가 내림세</td>\n",
              "      <td>북한지역에서 가을 추수가 마무리 되면서 쌀과 옥수수 등 곡물류 가격이 내림세로 돌아...</td>\n",
              "      <td>spnews</td>\n",
              "      <td>북한N</td>\n",
              "      <td>안윤석 대기자</td>\n",
              "      <td>2025-11-17</td>\n",
              "      <td>https://www.spnews.co.kr/news/articleView.html...</td>\n",
              "      <td>경제/산업</td>\n",
              "      <td>가을 추수가 마무리되면서 북한의 곡물 가격이 하락세를 보이고 있다. 평양, 혜산, ...</td>\n",
              "      <td>곡물가, 하락, 가을 추수, 물가, 북한</td>\n",
              "      <td>가을 추수로 인한 곡물가 하락</td>\n",
              "      <td>2025-11-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>평양시, 혜산시, 원산시, 사리원시</td>\n",
              "      <td>19850.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>34600.0</td>\n",
              "      <td>0.000379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spnews_101392</td>\n",
              "      <td>북한 각지서 어머니날 경축... 김일성-김정일 동상 참배</td>\n",
              "      <td>북한 각지에서 어머니날(11월 16일)을 경축했다.\\n노동신문은 17일 \"어머니날을...</td>\n",
              "      <td>spnews</td>\n",
              "      <td>북한N</td>\n",
              "      <td>안윤석  대기자</td>\n",
              "      <td>2025-11-17</td>\n",
              "      <td>https://www.spnews.co.kr/news/articleView.html...</td>\n",
              "      <td>사회/문화/체육</td>\n",
              "      <td>북한 각지에서 어머니날을 경축하며 김일성-김정일 동상에 꽃다발을 바쳤다. 공산주의어...</td>\n",
              "      <td>어머니날, 경축, 동상, 공연, 여성근로자</td>\n",
              "      <td>어머니날 경축 행사</td>\n",
              "      <td>2025-11-16</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>평안남도, 황해북도, 강원도, 양강도, 나선시, 개성시</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c33c109d-374b-4de3-84fd-f69bd523634a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c33c109d-374b-4de3-84fd-f69bd523634a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c33c109d-374b-4de3-84fd-f69bd523634a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-afbb6ff5-8292-467c-b484-22244d4c5f7d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-afbb6ff5-8292-467c-b484-22244d4c5f7d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-afbb6ff5-8292-467c-b484-22244d4c5f7d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gdown\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Google Drive 파일 ID (공유 버튼을 눌러 해당 파일의 URL에서 추출한 파일 ID)\n",
        "# > full_df_final.csv\n",
        "# https://drive.google.com/file/d/1V8mFCYrE446qqdx7lAkgLdBmKUEbOtwp/view?usp=drive_link\n",
        "file_id = '1V8mFCYrE446qqdx7lAkgLdBmKUEbOtwp'\n",
        "output_path = 'downloaded_file.csv'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id}', output_path, quiet=False)\n",
        "df = pd.read_csv(output_path) # 코랩~구글 드라이브 사용시\n",
        "\n",
        "# 로컬에서 로드하는 경우, 경로 및 파일명 지정\n",
        "# df = pd.read_csv('full_df_final.csv')\n",
        "\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fffb1700"
      },
      "source": [
        "## 데이터 탐색 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acef1875",
        "outputId": "93cef6cb-5941-43ff-d829-36440fe34c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            " summary     0\n",
            "keywords    0\n",
            "category    0\n",
            "dtype: int64\n",
            "\n",
            "Unique values count:\n",
            " summary     19141\n",
            "keywords    18681\n",
            "category        5\n",
            "dtype: int64\n",
            "\n",
            "Category distribution:\n",
            " category\n",
            "경제/산업       7016\n",
            "사회/문화/체육    5855\n",
            "정치          4912\n",
            "군사           680\n",
            "외교           678\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Missing values:\\n\", df[['summary', 'keywords', 'category']].isnull().sum())\n",
        "print(\"\\nUnique values count:\\n\", df[['summary', 'keywords', 'category']].nunique())\n",
        "print(\"\\nCategory distribution:\\n\", df['category'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84fc35ce",
        "outputId": "02e1967a-41c8-44e5-ec7a-f6042c51f4e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed summary (first 5 rows):\n",
            " 0    신의주온실종합농장 건설장에서 지대정리와 잔디심기가 마감단계에 이르고 있다 군민건설자...\n",
            "1    북한이 나무의 사름률을 높이는 과학기술제품으로 천연생물활성제를 소개했다 이 제품은 ...\n",
            "2    북한 개성시에서 식물방역소와 돼지종축장이 새로 건설되었다 개성시식물방역소 건설에 여...\n",
            "3    가을 추수가 마무리되면서 북한의 곡물 가격이 하락세를 보이고 있다 평양 혜산 원산 ...\n",
            "4    북한 각지에서 어머니날을 경축하며 김일성김정일 동상에 꽃다발을 바쳤다 공산주의어머니...\n",
            "Name: preprocessed_summary, dtype: object\n",
            "\n",
            "Preprocessed keywords (first 5 rows):\n",
            " 0    신의주 온실농장 지대정리 잔디심기 건설\n",
            "1     나무 사름률 천연생물활성제 제품 북한\n",
            "2    개성시 식물방역소 돼지종축장 건설 농업\n",
            "3       곡물가 하락 가을 추수 물가 북한\n",
            "4      어머니날 경축 동상 공연 여성근로자\n",
            "Name: preprocessed_keywords, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text): # Handle potential NaN values\n",
        "        return \"\"\n",
        "    text = str(text).lower() # 소문자 변환\n",
        "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text) # 특수문자 제거\n",
        "    return text\n",
        "\n",
        "df['preprocessed_summary'] = df['summary'].apply(preprocess_text)\n",
        "df['preprocessed_keywords'] = df['keywords'].apply(preprocess_text)\n",
        "\n",
        "print(\"Preprocessed summary (first 5 rows):\\n\", df['preprocessed_summary'].head())\n",
        "print(\"\\nPreprocessed keywords (first 5 rows):\\n\", df['preprocessed_keywords'].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62d0a1ce"
      },
      "source": [
        "## 데이터 벡터화"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) TF-IDF"
      ],
      "metadata": {
        "id": "nZ2lT4Kncnz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF 방식\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import numpy as np\n",
        "\n",
        "# 'preprocessed_summary' 벡터화\n",
        "tfidf_vectorizer_summary = TfidfVectorizer(max_features=20000) # max_features 조정 가능\n",
        "X_summary = tfidf_vectorizer_summary.fit_transform(df['preprocessed_summary'])\n",
        "print(f\"'preprocessed_summary' 벡터화 결과 형태: {X_summary.shape}\")\n",
        "\n",
        "# 'preprocessed_keywords' 벡터화\n",
        "tfidf_vectorizer_keywords = TfidfVectorizer(max_features=5000) # max_features 조정 가능\n",
        "X_keywords = tfidf_vectorizer_keywords.fit_transform(df['preprocessed_keywords'])\n",
        "print(f\"'preprocessed_keywords' 벡터화 결과 형태: {X_keywords.shape}\")\n",
        "\n",
        "# 두 벡터화된 데이터를 수평으로 결합\n",
        "X_combined = hstack([X_summary, X_keywords])\n",
        "\n",
        "# 카테고리 라벨 추출\n",
        "y_labels = df['category'].values\n",
        "\n",
        "print(f\"최종 결합된 특징 세트 형태: {X_combined.shape}\")\n",
        "print(f\"카테고리 라벨 형태: {y_labels.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6Ln-iyJ2uR2",
        "outputId": "66917458-26b0-4e06-bd74-bdd6b2323da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'preprocessed_summary' 벡터화 결과 형태: (19141, 20000)\n",
            "'preprocessed_keywords' 벡터화 결과 형태: (19141, 5000)\n",
            "최종 결합된 특징 세트 형태: (19141, 25000)\n",
            "카테고리 라벨 형태: (19141,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) openAI 텍스트 임베딩"
      ],
      "metadata": {
        "id": "5XD2Yb68chVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 임베딩 Query"
      ],
      "metadata": {
        "id": "iSsDCSeMzVxo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "102ba1b9",
        "outputId": "07043da8-931b-439e-8782-e7016f6ab877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating embeddings for 'preprocessed_summary' using OpenAI 'text-embedding-3-small'...\n",
            "'preprocessed_summary' 임베딩 결과 형태: (19141, 1536)\n",
            "Generating embeddings for 'preprocessed_keywords' using OpenAI 'text-embedding-3-small'...\n",
            "'preprocessed_keywords' 임베딩 결과 형태: (19141, 1536)\n",
            "최종 결합된 특징 세트 형태: (19141, 3072)\n",
            "카테고리 라벨 형태: (19141,)\n"
          ]
        }
      ],
      "source": [
        "# # 텍스트 임베딩 방식\n",
        "# import openai\n",
        "# import tiktoken # Optional, for token counting\n",
        "# import numpy as np\n",
        "\n",
        "# # OpenAI API 키 가져오기 (userdata.get('OPENAI_API_KEY')는 이미 실행되어 있다고 가정)\n",
        "# openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "# client = openai.OpenAI(api_key=openai.api_key)\n",
        "\n",
        "# def get_embedding(text, model=\"text-embedding-3-small\"):\n",
        "#     if not isinstance(text, str):\n",
        "#         text = str(text)\n",
        "#     text = text.replace(\"\\n\", \" \") # 줄바꿈 제거\n",
        "#     try:\n",
        "#         return client.embeddings.create(input=[text], model=model).data[0].embedding\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error getting embedding for text: {text[:50]}... Error: {e}\")\n",
        "#         return [0.0] * 1536 # 오류 발생 시 1536차원 제로 벡터 반환\n",
        "\n",
        "# print(\"Generating embeddings for 'preprocessed_summary' using OpenAI 'text-embedding-3-small'...\")\n",
        "# X_summary = np.array(df['preprocessed_summary'].apply(lambda x: get_embedding(x)).tolist())\n",
        "# print(f\"'preprocessed_summary' 임베딩 결과 형태: {X_summary.shape}\")\n",
        "\n",
        "# print(\"Generating embeddings for 'preprocessed_keywords' using OpenAI 'text-embedding-3-small'...\")\n",
        "# X_keywords = np.array(df['preprocessed_keywords'].apply(lambda x: get_embedding(x)).tolist())\n",
        "# print(f\"'preprocessed_keywords' 임베딩 결과 형태: {X_keywords.shape}\")\n",
        "\n",
        "# # 두 임베딩 데이터를 수평으로 결합\n",
        "# X_combined = np.hstack([X_summary, X_keywords])\n",
        "\n",
        "# # 카테고리 라벨 추출\n",
        "# y_labels = df['category'].values\n",
        "\n",
        "# print(f\"최종 결합된 특징 세트 형태: {X_combined.shape}\")\n",
        "# print(f\"카테고리 라벨 형태: {y_labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 임베딩 데이터를 파일로 저장"
      ],
      "metadata": {
        "id": "RzM4ubiXaoSF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYNQiTbuYcIc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "8b1b122c-1524-4c94-cc6a-0db41920b3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI 임베딩 데이터가 '/content/drive/MyDrive/Colab Notebooks/sia_embed.csv'에 성공적으로 저장되었습니다.\n",
            "저장된 데이터의 처음 5행:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0   0.022873   0.057617   0.077078   0.025437  -0.039811   0.045100   \n",
              "1   0.017431   0.007211   0.038271   0.017969  -0.002414  -0.053658   \n",
              "2   0.035629   0.045025   0.052281   0.017052  -0.039927   0.021285   \n",
              "3   0.014035  -0.002810  -0.015359  -0.015873   0.056814   0.003094   \n",
              "4   0.025085   0.029958  -0.027741  -0.023427  -0.033613  -0.060715   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_3064  \\\n",
              "0   0.055962  -0.013990  -0.022873  -0.035208  ...      0.047363   \n",
              "1  -0.003341   0.022324   0.009124  -0.002883  ...     -0.001979   \n",
              "2  -0.000493   0.005451  -0.003000  -0.030978  ...      0.024440   \n",
              "3  -0.002788   0.059026  -0.014697  -0.032259  ...      0.016710   \n",
              "4   0.019293   0.035191  -0.058438  -0.002541  ...     -0.035220   \n",
              "\n",
              "   feature_3065  feature_3066  feature_3067  feature_3068  feature_3069  \\\n",
              "0      0.010006      0.033351      0.037054      0.041374     -0.000171   \n",
              "1     -0.048874      0.011022     -0.012274      0.005244      0.008429   \n",
              "2      0.008236      0.011784      0.019709      0.029847     -0.003328   \n",
              "3      0.001253      0.010360     -0.015580     -0.006557      0.031748   \n",
              "4     -0.007421      0.009615     -0.013928      0.023839      0.019958   \n",
              "\n",
              "   feature_3070  feature_3071  category             id  \n",
              "0     -0.004075     -0.009012     경제/산업  spnews_101404  \n",
              "1      0.001900     -0.010199     경제/산업  spnews_101403  \n",
              "2     -0.026468      0.014008  사회/문화/체육  spnews_101402  \n",
              "3      0.018959     -0.046285     경제/산업  spnews_101394  \n",
              "4     -0.022442     -0.028646  사회/문화/체육  spnews_101392  \n",
              "\n",
              "[5 rows x 3074 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a86ea81-8ad1-4d65-84e2-77235c8e22e2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_3064</th>\n",
              "      <th>feature_3065</th>\n",
              "      <th>feature_3066</th>\n",
              "      <th>feature_3067</th>\n",
              "      <th>feature_3068</th>\n",
              "      <th>feature_3069</th>\n",
              "      <th>feature_3070</th>\n",
              "      <th>feature_3071</th>\n",
              "      <th>category</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.022873</td>\n",
              "      <td>0.057617</td>\n",
              "      <td>0.077078</td>\n",
              "      <td>0.025437</td>\n",
              "      <td>-0.039811</td>\n",
              "      <td>0.045100</td>\n",
              "      <td>0.055962</td>\n",
              "      <td>-0.013990</td>\n",
              "      <td>-0.022873</td>\n",
              "      <td>-0.035208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047363</td>\n",
              "      <td>0.010006</td>\n",
              "      <td>0.033351</td>\n",
              "      <td>0.037054</td>\n",
              "      <td>0.041374</td>\n",
              "      <td>-0.000171</td>\n",
              "      <td>-0.004075</td>\n",
              "      <td>-0.009012</td>\n",
              "      <td>경제/산업</td>\n",
              "      <td>spnews_101404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.017431</td>\n",
              "      <td>0.007211</td>\n",
              "      <td>0.038271</td>\n",
              "      <td>0.017969</td>\n",
              "      <td>-0.002414</td>\n",
              "      <td>-0.053658</td>\n",
              "      <td>-0.003341</td>\n",
              "      <td>0.022324</td>\n",
              "      <td>0.009124</td>\n",
              "      <td>-0.002883</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001979</td>\n",
              "      <td>-0.048874</td>\n",
              "      <td>0.011022</td>\n",
              "      <td>-0.012274</td>\n",
              "      <td>0.005244</td>\n",
              "      <td>0.008429</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>-0.010199</td>\n",
              "      <td>경제/산업</td>\n",
              "      <td>spnews_101403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.035629</td>\n",
              "      <td>0.045025</td>\n",
              "      <td>0.052281</td>\n",
              "      <td>0.017052</td>\n",
              "      <td>-0.039927</td>\n",
              "      <td>0.021285</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>0.005451</td>\n",
              "      <td>-0.003000</td>\n",
              "      <td>-0.030978</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024440</td>\n",
              "      <td>0.008236</td>\n",
              "      <td>0.011784</td>\n",
              "      <td>0.019709</td>\n",
              "      <td>0.029847</td>\n",
              "      <td>-0.003328</td>\n",
              "      <td>-0.026468</td>\n",
              "      <td>0.014008</td>\n",
              "      <td>사회/문화/체육</td>\n",
              "      <td>spnews_101402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.014035</td>\n",
              "      <td>-0.002810</td>\n",
              "      <td>-0.015359</td>\n",
              "      <td>-0.015873</td>\n",
              "      <td>0.056814</td>\n",
              "      <td>0.003094</td>\n",
              "      <td>-0.002788</td>\n",
              "      <td>0.059026</td>\n",
              "      <td>-0.014697</td>\n",
              "      <td>-0.032259</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016710</td>\n",
              "      <td>0.001253</td>\n",
              "      <td>0.010360</td>\n",
              "      <td>-0.015580</td>\n",
              "      <td>-0.006557</td>\n",
              "      <td>0.031748</td>\n",
              "      <td>0.018959</td>\n",
              "      <td>-0.046285</td>\n",
              "      <td>경제/산업</td>\n",
              "      <td>spnews_101394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.025085</td>\n",
              "      <td>0.029958</td>\n",
              "      <td>-0.027741</td>\n",
              "      <td>-0.023427</td>\n",
              "      <td>-0.033613</td>\n",
              "      <td>-0.060715</td>\n",
              "      <td>0.019293</td>\n",
              "      <td>0.035191</td>\n",
              "      <td>-0.058438</td>\n",
              "      <td>-0.002541</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.035220</td>\n",
              "      <td>-0.007421</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>-0.013928</td>\n",
              "      <td>0.023839</td>\n",
              "      <td>0.019958</td>\n",
              "      <td>-0.022442</td>\n",
              "      <td>-0.028646</td>\n",
              "      <td>사회/문화/체육</td>\n",
              "      <td>spnews_101392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3074 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a86ea81-8ad1-4d65-84e2-77235c8e22e2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a86ea81-8ad1-4d65-84e2-77235c8e22e2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a86ea81-8ad1-4d65-84e2-77235c8e22e2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-92369457-4004-4bfe-ad1e-4ff1c0923470\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92369457-4004-4bfe-ad1e-4ff1c0923470')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-92369457-4004-4bfe-ad1e-4ff1c0923470 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# # 임베딩 결과값을 파일로 저장\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import os\n",
        "\n",
        "# # X_combined와 y_labels를 하나의 DataFrame으로 결합\n",
        "# # 컬럼 이름을 \"feature_0\", \"feature_1\" ... 등으로 지정\n",
        "# feature_columns = [f\"feature_{i}\" for i in range(X_combined.shape[1])]\n",
        "# df_embeddings = pd.DataFrame(X_combined, columns=feature_columns)\n",
        "# df_embeddings['category'] = y_labels\n",
        "\n",
        "# # 원본 df의 'id' 컬럼도 함께 저장\n",
        "# df_embeddings['id'] = df['id']\n",
        "\n",
        "# # 저장할 경로 지정\n",
        "# output_csv_path = '/content/drive/MyDrive/Colab Notebooks/sia_embed.csv'\n",
        "\n",
        "# # Google Drive 마운트 확인 (이미 마운트되었다고 가정)\n",
        "# # drive.mount('/content/drive') # 필요시 주석 해제\n",
        "\n",
        "# # 디렉토리 존재 여부 확인 및 생성\n",
        "# output_dir = os.path.dirname(output_csv_path)\n",
        "# if not os.path.exists(output_dir):\n",
        "#     os.makedirs(output_dir)\n",
        "\n",
        "# # CSV 파일로 저장\n",
        "# df_embeddings.to_csv(output_csv_path, index=False)\n",
        "\n",
        "# print(f\"OpenAI 임베딩 데이터가 '{output_csv_path}'에 성공적으로 저장되었습니다.\")\n",
        "# print(\"저장된 데이터의 처음 5행:\")\n",
        "# display(df_embeddings.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 임베딩 파일 불러오기"
      ],
      "metadata": {
        "id": "WthypU9vavhw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "242cda44",
        "outputId": "eb056f3a-9885-4e7f-a5ab-f31d8552e330"
      },
      "source": [
        "# 저장한 임베딩 데이터를 불러오고 모델링 준비\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Google Drive 마운트 확인 (이미 마운트되었다고 가정)\n",
        "# drive.mount('/content/drive') # 필요시 주석 해제\n",
        "\n",
        "# 저장된 파일 경로\n",
        "input_csv_path = '/content/drive/MyDrive/Colab Notebooks/sia_embed.csv'\n",
        "\n",
        "# CSV 파일 불러오기\n",
        "df_loaded = pd.read_csv(input_csv_path)\n",
        "\n",
        "print(f\"'{input_csv_path}'에서 데이터를 성공적으로 불러왔습니다.\")\n",
        "display(df_loaded.head())\n",
        "\n",
        "# 특징과 라벨 분리 (id는 버림)\n",
        "X_combined = df_loaded.drop(columns=['category','id']).values\n",
        "y_labels = df_loaded['category'].values\n",
        "\n",
        "print(f\"불러온 X_combined 형태: {X_combined.shape}\")\n",
        "print(f\"불러온 y_labels 형태: {y_labels.shape}\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/drive/MyDrive/Colab Notebooks/sia_embed.csv'에서 데이터를 성공적으로 불러왔습니다.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
              "0   0.022873   0.057617   0.077078   0.025437  -0.039811   0.045100   \n",
              "1   0.017431   0.007211   0.038271   0.017969  -0.002414  -0.053658   \n",
              "2   0.035629   0.045025   0.052281   0.017052  -0.039927   0.021285   \n",
              "3   0.014035  -0.002810  -0.015359  -0.015873   0.056814   0.003094   \n",
              "4   0.025085   0.029958  -0.027741  -0.023427  -0.033613  -0.060715   \n",
              "\n",
              "   feature_6  feature_7  feature_8  feature_9  ...  feature_3064  \\\n",
              "0   0.055962  -0.013990  -0.022873  -0.035208  ...      0.047363   \n",
              "1  -0.003341   0.022324   0.009124  -0.002883  ...     -0.001979   \n",
              "2  -0.000493   0.005451  -0.003000  -0.030978  ...      0.024440   \n",
              "3  -0.002788   0.059026  -0.014697  -0.032259  ...      0.016710   \n",
              "4   0.019293   0.035191  -0.058438  -0.002541  ...     -0.035220   \n",
              "\n",
              "   feature_3065  feature_3066  feature_3067  feature_3068  feature_3069  \\\n",
              "0      0.010006      0.033351      0.037054      0.041374     -0.000171   \n",
              "1     -0.048874      0.011022     -0.012274      0.005244      0.008429   \n",
              "2      0.008236      0.011784      0.019709      0.029847     -0.003328   \n",
              "3      0.001253      0.010360     -0.015580     -0.006557      0.031748   \n",
              "4     -0.007421      0.009615     -0.013928      0.023839      0.019958   \n",
              "\n",
              "   feature_3070  feature_3071  category             id  \n",
              "0     -0.004075     -0.009012     경제/산업  spnews_101404  \n",
              "1      0.001900     -0.010199     경제/산업  spnews_101403  \n",
              "2     -0.026468      0.014008  사회/문화/체육  spnews_101402  \n",
              "3      0.018959     -0.046285     경제/산업  spnews_101394  \n",
              "4     -0.022442     -0.028646  사회/문화/체육  spnews_101392  \n",
              "\n",
              "[5 rows x 3074 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-963d59cc-a6cc-4ffc-813a-69f3f85e19c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_3064</th>\n",
              "      <th>feature_3065</th>\n",
              "      <th>feature_3066</th>\n",
              "      <th>feature_3067</th>\n",
              "      <th>feature_3068</th>\n",
              "      <th>feature_3069</th>\n",
              "      <th>feature_3070</th>\n",
              "      <th>feature_3071</th>\n",
              "      <th>category</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.022873</td>\n",
              "      <td>0.057617</td>\n",
              "      <td>0.077078</td>\n",
              "      <td>0.025437</td>\n",
              "      <td>-0.039811</td>\n",
              "      <td>0.045100</td>\n",
              "      <td>0.055962</td>\n",
              "      <td>-0.013990</td>\n",
              "      <td>-0.022873</td>\n",
              "      <td>-0.035208</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047363</td>\n",
              "      <td>0.010006</td>\n",
              "      <td>0.033351</td>\n",
              "      <td>0.037054</td>\n",
              "      <td>0.041374</td>\n",
              "      <td>-0.000171</td>\n",
              "      <td>-0.004075</td>\n",
              "      <td>-0.009012</td>\n",
              "      <td>경제/산업</td>\n",
              "      <td>spnews_101404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.017431</td>\n",
              "      <td>0.007211</td>\n",
              "      <td>0.038271</td>\n",
              "      <td>0.017969</td>\n",
              "      <td>-0.002414</td>\n",
              "      <td>-0.053658</td>\n",
              "      <td>-0.003341</td>\n",
              "      <td>0.022324</td>\n",
              "      <td>0.009124</td>\n",
              "      <td>-0.002883</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001979</td>\n",
              "      <td>-0.048874</td>\n",
              "      <td>0.011022</td>\n",
              "      <td>-0.012274</td>\n",
              "      <td>0.005244</td>\n",
              "      <td>0.008429</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>-0.010199</td>\n",
              "      <td>경제/산업</td>\n",
              "      <td>spnews_101403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.035629</td>\n",
              "      <td>0.045025</td>\n",
              "      <td>0.052281</td>\n",
              "      <td>0.017052</td>\n",
              "      <td>-0.039927</td>\n",
              "      <td>0.021285</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>0.005451</td>\n",
              "      <td>-0.003000</td>\n",
              "      <td>-0.030978</td>\n",
              "      <td>...</td>\n",
              "      <td>0.024440</td>\n",
              "      <td>0.008236</td>\n",
              "      <td>0.011784</td>\n",
              "      <td>0.019709</td>\n",
              "      <td>0.029847</td>\n",
              "      <td>-0.003328</td>\n",
              "      <td>-0.026468</td>\n",
              "      <td>0.014008</td>\n",
              "      <td>사회/문화/체육</td>\n",
              "      <td>spnews_101402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.014035</td>\n",
              "      <td>-0.002810</td>\n",
              "      <td>-0.015359</td>\n",
              "      <td>-0.015873</td>\n",
              "      <td>0.056814</td>\n",
              "      <td>0.003094</td>\n",
              "      <td>-0.002788</td>\n",
              "      <td>0.059026</td>\n",
              "      <td>-0.014697</td>\n",
              "      <td>-0.032259</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016710</td>\n",
              "      <td>0.001253</td>\n",
              "      <td>0.010360</td>\n",
              "      <td>-0.015580</td>\n",
              "      <td>-0.006557</td>\n",
              "      <td>0.031748</td>\n",
              "      <td>0.018959</td>\n",
              "      <td>-0.046285</td>\n",
              "      <td>경제/산업</td>\n",
              "      <td>spnews_101394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.025085</td>\n",
              "      <td>0.029958</td>\n",
              "      <td>-0.027741</td>\n",
              "      <td>-0.023427</td>\n",
              "      <td>-0.033613</td>\n",
              "      <td>-0.060715</td>\n",
              "      <td>0.019293</td>\n",
              "      <td>0.035191</td>\n",
              "      <td>-0.058438</td>\n",
              "      <td>-0.002541</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.035220</td>\n",
              "      <td>-0.007421</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>-0.013928</td>\n",
              "      <td>0.023839</td>\n",
              "      <td>0.019958</td>\n",
              "      <td>-0.022442</td>\n",
              "      <td>-0.028646</td>\n",
              "      <td>사회/문화/체육</td>\n",
              "      <td>spnews_101392</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 3074 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-963d59cc-a6cc-4ffc-813a-69f3f85e19c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-963d59cc-a6cc-4ffc-813a-69f3f85e19c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-963d59cc-a6cc-4ffc-813a-69f3f85e19c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-decdd7fb-6f8d-40be-9474-10d1e3c49e60\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-decdd7fb-6f8d-40be-9474-10d1e3c49e60')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-decdd7fb-6f8d-40be-9474-10d1e3c49e60 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불러온 X_combined 형태: (19141, 3072)\n",
            "불러온 y_labels 형태: (19141,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f950cdda"
      },
      "source": [
        "## 모델 학습 및 평가 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36ce6077",
        "outputId": "c133dd4f-279a-4ad3-f1a5-b58eca2bc34e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train 형태: (15312, 25000)\n",
            "X_test 형태: (3829, 25000)\n",
            "y_train 형태: (15312,)\n",
            "y_test 형태: (3829,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 데이터를 훈련 세트와 테스트 세트로 분리\n",
        "# OpenAI 임베딩 데이터인 X_combined_loaded와 y_labels_loaded를 사용\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_labels, test_size=0.2, random_state=42, stratify=y_labels)\n",
        "\n",
        "# 분리된 데이터 형태 확인\n",
        "print(f\"X_train 형태: {X_train.shape}\")\n",
        "print(f\"X_test 형태: {X_test.shape}\")\n",
        "print(f\"y_train 형태: {y_train.shape}\")\n",
        "print(f\"y_test 형태: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a638e72"
      },
      "source": [
        "## 모델 학습 및 성능 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c1a1c6a9",
        "outputId": "7b8e3caf-35ef-4286-ee9d-7308f7420660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 로지스틱 회귀 모델 학습 중 ---\n",
            "정확도 (Accuracy): 0.8073\n",
            "정밀도 (Precision, macro): 0.7870\n",
            "재현율 (Recall, macro): 0.6651\n",
            "F1 스코어 (F1 Score, macro): 0.7047\n",
            "ROC AUC (macro, ovr): 0.9537\n",
            "\n",
            "--- 랜덤 포레스트 모델 학습 중 ---\n",
            "정확도 (Accuracy): 0.7448\n",
            "정밀도 (Precision, macro): 0.7709\n",
            "재현율 (Recall, macro): 0.5528\n",
            "F1 스코어 (F1 Score, macro): 0.5832\n",
            "ROC AUC (macro, ovr): 0.9332\n",
            "\n",
            "--- SVM (선형 커널) 모델 학습 중 ---\n",
            "정확도 (Accuracy): 0.8086\n",
            "정밀도 (Precision, macro): 0.7769\n",
            "재현율 (Recall, macro): 0.6985\n",
            "F1 스코어 (F1 Score, macro): 0.7291\n",
            "ROC AUC (macro, ovr): 0.9516\n",
            "\n",
            "--- XGBoost 모델 학습 중 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [06:40:13] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 (Accuracy): 0.7482\n",
            "정밀도 (Precision, macro): 0.7044\n",
            "재현율 (Recall, macro): 0.6248\n",
            "F1 스코어 (F1 Score, macro): 0.6538\n",
            "ROC AUC (macro, ovr): 0.9259\n",
            "\n",
            "--- LightGBM 모델 학습 중 ---\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.592087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 85851\n",
            "[LightGBM] [Info] Number of data points in the train set: 15312, number of used features: 3390\n",
            "[LightGBM] [Info] Start training from score -1.003551\n",
            "[LightGBM] [Info] Start training from score -3.337443\n",
            "[LightGBM] [Info] Start training from score -1.184484\n",
            "[LightGBM] [Info] Start training from score -3.341126\n",
            "[LightGBM] [Info] Start training from score -1.360252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 (Accuracy): 0.7657\n",
            "정밀도 (Precision, macro): 0.7173\n",
            "재현율 (Recall, macro): 0.6329\n",
            "F1 스코어 (F1 Score, macro): 0.6631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC (macro, ovr): 0.9321\n",
            "\n",
            "--- 모델 성능 비교 ---\n",
            "로지스틱 회귀:\n",
            "  Accuracy: 0.8073\n",
            "  Precision: 0.7870\n",
            "  Recall: 0.6651\n",
            "  F1 Score: 0.7047\n",
            "  Roc Auc: 0.9537\n",
            "랜덤 포레스트:\n",
            "  Accuracy: 0.7448\n",
            "  Precision: 0.7709\n",
            "  Recall: 0.5528\n",
            "  F1 Score: 0.5832\n",
            "  Roc Auc: 0.9332\n",
            "SVM (선형 커널):\n",
            "  Accuracy: 0.8086\n",
            "  Precision: 0.7769\n",
            "  Recall: 0.6985\n",
            "  F1 Score: 0.7291\n",
            "  Roc Auc: 0.9516\n",
            "XGBoost:\n",
            "  Accuracy: 0.7482\n",
            "  Precision: 0.7044\n",
            "  Recall: 0.6248\n",
            "  F1 Score: 0.6538\n",
            "  Roc Auc: 0.9259\n",
            "LightGBM:\n",
            "  Accuracy: 0.7657\n",
            "  Precision: 0.7173\n",
            "  Recall: 0.6329\n",
            "  F1 Score: 0.6631\n",
            "  Roc Auc: 0.9321\n",
            "\n",
            "모델 성능 요약 (업데이트):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             accuracy  precision    recall  f1_score   roc_auc\n",
              "로지스틱 회귀      0.807260   0.787021  0.665086  0.704727  0.953674\n",
              "랜덤 포레스트      0.744842   0.770915  0.552839  0.583159  0.933167\n",
              "SVM (선형 커널)  0.808566   0.776907  0.698505  0.729150  0.951566\n",
              "XGBoost      0.748237   0.704442  0.624776  0.653840  0.925893\n",
              "LightGBM     0.765735   0.717327  0.632927  0.663071  0.932142"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79bf25c4-b973-4eec-8282-d48083af8b84\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>로지스틱 회귀</th>\n",
              "      <td>0.807260</td>\n",
              "      <td>0.787021</td>\n",
              "      <td>0.665086</td>\n",
              "      <td>0.704727</td>\n",
              "      <td>0.953674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>랜덤 포레스트</th>\n",
              "      <td>0.744842</td>\n",
              "      <td>0.770915</td>\n",
              "      <td>0.552839</td>\n",
              "      <td>0.583159</td>\n",
              "      <td>0.933167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM (선형 커널)</th>\n",
              "      <td>0.808566</td>\n",
              "      <td>0.776907</td>\n",
              "      <td>0.698505</td>\n",
              "      <td>0.729150</td>\n",
              "      <td>0.951566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.748237</td>\n",
              "      <td>0.704442</td>\n",
              "      <td>0.624776</td>\n",
              "      <td>0.653840</td>\n",
              "      <td>0.925893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.765735</td>\n",
              "      <td>0.717327</td>\n",
              "      <td>0.632927</td>\n",
              "      <td>0.663071</td>\n",
              "      <td>0.932142</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79bf25c4-b973-4eec-8282-d48083af8b84')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79bf25c4-b973-4eec-8282-d48083af8b84 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79bf25c4-b973-4eec-8282-d48083af8b84');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-af8e6015-7c40-4aee-9b05-e219163485f8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af8e6015-7c40-4aee-9b05-e219163485f8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-af8e6015-7c40-4aee-9b05-e219163485f8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_986c83c6-0406-4ee3-bd50-2cabf046a931\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_986c83c6-0406-4ee3-bd50-2cabf046a931 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.031140767119226555,\n        \"min\": 0.7448419952990337,\n        \"max\": 0.8085662052755288,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7448419952990337,\n          0.7657351788978846,\n          0.8085662052755288\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03763729290800415,\n        \"min\": 0.7044423363375676,\n        \"max\": 0.7870208097497894,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7709148972672776,\n          0.7173269074392795,\n          0.7769072974692507\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05430753946648214,\n        \"min\": 0.5528388156638591,\n        \"max\": 0.6985053102852279,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5528388156638591,\n          0.6329269775003504,\n          0.6985053102852279\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05590973867086819,\n        \"min\": 0.5831593413924694,\n        \"max\": 0.7291499229049104,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5831593413924694,\n          0.6630708900117962,\n          0.7291499229049104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012506605657754005,\n        \"min\": 0.9258931989606165,\n        \"max\": 0.9536742034938743,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9331674815387021,\n          0.932141683305731,\n          0.9515658909891392\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# 타겟 라벨을 수치형 값으로 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# 학습할 모델 정의 (듀얼코어 사용 옵션 포함)\n",
        "models = {\n",
        "    '로지스틱 회귀': LogisticRegression(random_state=42, max_iter=1000, solver='saga', n_jobs=-1),\n",
        "    '랜덤 포레스트': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    'SVM (선형 커널)': SVC(kernel='linear', probability=True, random_state=42),\n",
        "    # '다항 나이브 베이즈': MultinomialNB(),\n",
        "    'XGBoost': XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss', use_label_encoder=False),\n",
        "    'LightGBM': LGBMClassifier(random_state=42, n_jobs=-1)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- {name} 모델 학습 중 ---\")\n",
        "    model.fit(X_train, y_train_encoded) # 인코딩된 라벨로 학습\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 기본 평가 지표 계산\n",
        "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "    precision = precision_score(y_test_encoded, y_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_test_encoded, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_test_encoded, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"정확도 (Accuracy): {accuracy:.4f}\")\n",
        "    print(f\"정밀도 (Precision, macro): {precision:.4f}\")\n",
        "    print(f\"재현율 (Recall, macro): {recall:.4f}\")\n",
        "    print(f\"F1 스코어 (F1 Score, macro): {f1:.4f}\")\n",
        "\n",
        "    # 다중 클래스 ROC AUC 스코어 계산 (one-vs-rest)\n",
        "    roc_auc = None\n",
        "    try:\n",
        "        y_pred_proba = model.predict_proba(X_test)\n",
        "        roc_auc = roc_auc_score(y_test_encoded, y_pred_proba, multi_class='ovr', average='macro')\n",
        "        print(f\"ROC AUC (macro, ovr): {roc_auc:.4f}\")\n",
        "    except AttributeError:\n",
        "        print(\"해당 모델은 predict_proba를 지원하지 않아 ROC AUC를 계산하지 않습니다.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"ROC AUC 계산 오류: {e}\")\n",
        "\n",
        "    # 결과 저장\n",
        "    results[name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'roc_auc': roc_auc\n",
        "    }\n",
        "\n",
        "print(\"\\n--- 모델 성능 비교 ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        if value is not None:\n",
        "            print(f\"  {metric_name.replace('_', ' ').title()}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {metric_name.replace('_', ' ').title()}: N/A\")\n",
        "\n",
        "# 결과를 DataFrame으로 변환\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "\n",
        "print(\"\\n모델 성능 요약 (업데이트):\")\n",
        "display(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65f987cd"
      },
      "source": [
        "##싸이킷런 딥러닝 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ee359cc9",
        "outputId": "4050e485-495a-48fb-bb0c-8eebe5f98d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- MLPClassifier 모델 학습 중 ---\n",
            "정확도 (Accuracy): 0.8169\n",
            "정밀도 (Precision, macro): 0.7630\n",
            "재현율 (Recall, macro): 0.7488\n",
            "F1 스코어 (F1 Score, macro): 0.7555\n",
            "ROC AUC (macro, ovr): 0.9534\n",
            "\n",
            "--- 모델 성능 비교 (MLPClassifier 추가) ---\n",
            "로지스틱 회귀:\n",
            "  Accuracy: 0.8213\n",
            "  Precision: 0.7999\n",
            "  Recall: 0.7254\n",
            "  F1 Score: 0.7551\n",
            "  Roc Auc: 0.9580\n",
            "랜덤 포레스트:\n",
            "  Accuracy: 0.7829\n",
            "  Precision: 0.7910\n",
            "  Recall: 0.6797\n",
            "  F1 Score: 0.7015\n",
            "  Roc Auc: 0.9442\n",
            "SVM (선형 커널):\n",
            "  Accuracy: 0.8307\n",
            "  Precision: 0.8084\n",
            "  Recall: 0.7659\n",
            "  F1 Score: 0.7848\n",
            "  Roc Auc: 0.9569\n",
            "다항 나이브 베이즈:\n",
            "  Accuracy: 0.8032\n",
            "  Precision: 0.7870\n",
            "  Recall: 0.6995\n",
            "  F1 Score: 0.7207\n",
            "  Roc Auc: 0.9489\n",
            "XGBoost:\n",
            "  Accuracy: 0.7750\n",
            "  Precision: 0.7516\n",
            "  Recall: 0.6930\n",
            "  F1 Score: 0.7172\n",
            "  Roc Auc: 0.9383\n",
            "LightGBM:\n",
            "  Accuracy: 0.7699\n",
            "  Precision: 0.7605\n",
            "  Recall: 0.6951\n",
            "  F1 Score: 0.7211\n",
            "  Roc Auc: 0.9358\n",
            "MLPClassifier:\n",
            "  Accuracy: 0.8169\n",
            "  Precision: 0.7630\n",
            "  Recall: 0.7488\n",
            "  F1 Score: 0.7555\n",
            "  Roc Auc: 0.9534\n",
            "\n",
            "모델 성능 요약 (최종 업데이트):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>로지스틱 회귀</th>\n",
              "      <td>0.821274</td>\n",
              "      <td>0.799943</td>\n",
              "      <td>0.725356</td>\n",
              "      <td>0.755069</td>\n",
              "      <td>0.958041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>랜덤 포레스트</th>\n",
              "      <td>0.782923</td>\n",
              "      <td>0.790972</td>\n",
              "      <td>0.679723</td>\n",
              "      <td>0.701499</td>\n",
              "      <td>0.944151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM (선형 커널)</th>\n",
              "      <td>0.830680</td>\n",
              "      <td>0.808433</td>\n",
              "      <td>0.765945</td>\n",
              "      <td>0.784791</td>\n",
              "      <td>0.956873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>다항 나이브 베이즈</th>\n",
              "      <td>0.803184</td>\n",
              "      <td>0.786991</td>\n",
              "      <td>0.699451</td>\n",
              "      <td>0.720733</td>\n",
              "      <td>0.948913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.774964</td>\n",
              "      <td>0.751638</td>\n",
              "      <td>0.692973</td>\n",
              "      <td>0.717220</td>\n",
              "      <td>0.938281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.769899</td>\n",
              "      <td>0.760505</td>\n",
              "      <td>0.695136</td>\n",
              "      <td>0.721088</td>\n",
              "      <td>0.935833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPClassifier</th>\n",
              "      <td>0.816932</td>\n",
              "      <td>0.763008</td>\n",
              "      <td>0.748779</td>\n",
              "      <td>0.755486</td>\n",
              "      <td>0.953398</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               accuracy  precision    recall  f1_score   roc_auc\n",
              "로지스틱 회귀        0.821274   0.799943  0.725356  0.755069  0.958041\n",
              "랜덤 포레스트        0.782923   0.790972  0.679723  0.701499  0.944151\n",
              "SVM (선형 커널)    0.830680   0.808433  0.765945  0.784791  0.956873\n",
              "다항 나이브 베이즈     0.803184   0.786991  0.699451  0.720733  0.948913\n",
              "XGBoost        0.774964   0.751638  0.692973  0.717220  0.938281\n",
              "LightGBM       0.769899   0.760505  0.695136  0.721088  0.935833\n",
              "MLPClassifier  0.816932   0.763008  0.748779  0.755486  0.953398"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Define MLPClassifier model\n",
        "mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50, 25), random_state=42, max_iter=1000)\n",
        "\n",
        "print(\"\\n--- MLPClassifier 모델 학습 중 ---\")\n",
        "mlp_model.fit(X_train, y_train_encoded) # 인코딩된 라벨로 학습\n",
        "y_pred_mlp = mlp_model.predict(X_test)\n",
        "\n",
        "# 기본 평가 지표 계산\n",
        "accuracy_mlp = accuracy_score(y_test_encoded, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_test_encoded, y_pred_mlp, average='macro', zero_division=0)\n",
        "recall_mlp = recall_score(y_test_encoded, y_pred_mlp, average='macro', zero_division=0)\n",
        "f1_mlp = f1_score(y_test_encoded, y_pred_mlp, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"정확도 (Accuracy): {accuracy_mlp:.4f}\")\n",
        "print(f\"정밀도 (Precision, macro): {precision_mlp:.4f}\")\n",
        "print(f\"재현율 (Recall, macro): {recall_mlp:.4f}\")\n",
        "print(f\"F1 스코어 (F1 Score, macro): {f1_mlp:.4f}\")\n",
        "\n",
        "# 다중 클래스 ROC AUC 스코어 계산 (one-vs-rest)\n",
        "roc_auc_mlp = None\n",
        "try:\n",
        "    y_pred_proba_mlp = mlp_model.predict_proba(X_test)\n",
        "    roc_auc_mlp = roc_auc_score(y_test_encoded, y_pred_proba_mlp, multi_class='ovr', average='macro')\n",
        "    print(f\"ROC AUC (macro, ovr): {roc_auc_mlp:.4f}\")\n",
        "except AttributeError:\n",
        "    print(\"해당 모델은 predict_proba를 지원하지 않아 ROC AUC를 계산하지 않습니다.\")\n",
        "except ValueError as e:\n",
        "    print(f\"ROC AUC 계산 오류: {e}\")\n",
        "\n",
        "# 결과 저장\n",
        "results['MLPClassifier'] = {\n",
        "    'accuracy': accuracy_mlp,\n",
        "    'precision': precision_mlp,\n",
        "    'recall': recall_mlp,\n",
        "    'f1_score': f1_mlp,\n",
        "    'roc_auc': roc_auc_mlp\n",
        "}\n",
        "\n",
        "print(\"\\n--- 모델 성능 비교 (MLPClassifier 추가) ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        if value is not None:\n",
        "            print(f\"  {metric_name.replace('_', ' ').title()}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {metric_name.replace('_', ' ').title()}: N/A\")\n",
        "\n",
        "# 결과를 DataFrame으로 변환 및 업데이트\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "\n",
        "print(\"\\n모델 성능 요약 (최종 업데이트):\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz2e0SFhLprh"
      },
      "source": [
        "##TensorFlow 딥러닝 모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e93939c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24be5706",
        "outputId": "ab507935-e754-403f-b6db-7f435a4c2cc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_dense shape: (5526, 25000)\n",
            "X_test_dense shape: (1382, 25000)\n"
          ]
        }
      ],
      "source": [
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "print(f\"X_train_dense shape: {X_train_dense.shape}\")\n",
        "print(f\"X_test_dense shape: {X_test_dense.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "63f50717",
        "outputId": "7edf6040-05b6-449d-ef5e-90d08843fb40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- TensorFlow MLP 모델 학습 중 ---\n",
            "Epoch 1/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6663 - loss: 0.8491\n",
            "Epoch 2/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9461 - loss: 0.1752\n",
            "Epoch 3/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0264\n",
            "Epoch 4/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0053\n",
            "Epoch 5/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0018\n",
            "Epoch 6/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.7855e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.4391e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.9021e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.8458e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.1976e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7480e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.4109e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.1576e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 9.6074e-05\n",
            "Epoch 15/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 8.0912e-05\n",
            "Epoch 16/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.8383e-05\n",
            "Epoch 17/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.8282e-05\n",
            "Epoch 18/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 5.0090e-05\n",
            "Epoch 19/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 4.3241e-05\n",
            "Epoch 20/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.7577e-05\n",
            "Epoch 21/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.2645e-05\n",
            "Epoch 22/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.8582e-05\n",
            "Epoch 23/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.5011e-05\n",
            "Epoch 24/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.2035e-05\n",
            "Epoch 25/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9388e-05\n",
            "Epoch 26/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7177e-05\n",
            "Epoch 27/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5211e-05\n",
            "Epoch 28/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.3501e-05\n",
            "Epoch 29/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2016e-05\n",
            "Epoch 30/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0721e-05\n",
            "Epoch 31/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.5484e-06\n",
            "Epoch 32/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.5461e-06\n",
            "Epoch 33/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.6349e-06\n",
            "Epoch 34/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.8336e-06\n",
            "Epoch 35/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.1311e-06\n",
            "Epoch 36/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.5009e-06\n",
            "Epoch 37/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9354e-06\n",
            "Epoch 38/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4364e-06\n",
            "Epoch 39/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.9880e-06\n",
            "Epoch 40/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.5848e-06\n",
            "Epoch 41/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 3.2279e-06\n",
            "Epoch 42/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.9136e-06\n",
            "Epoch 43/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.6251e-06\n",
            "Epoch 44/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.3705e-06\n",
            "Epoch 45/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 2.1344e-06\n",
            "Epoch 46/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.9275e-06\n",
            "Epoch 47/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.7431e-06\n",
            "Epoch 48/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.5726e-06\n",
            "Epoch 49/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4204e-06\n",
            "Epoch 50/50\n",
            "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 1.2868e-06\n",
            "TensorFlow MLP 모델 학습 완료.\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "정확도 (Accuracy): 0.8234\n",
            "정밀도 (Precision, macro): 0.7775\n",
            "재현율 (Recall, macro): 0.7549\n",
            "F1 스코어 (F1 Score, macro): 0.7654\n",
            "ROC AUC (macro, ovr): 0.9521\n",
            "\n",
            "--- 모델 성능 비교 (TensorFlow MLP 추가) ---\n",
            "로지스틱 회귀:\n",
            "  Accuracy: 0.8213\n",
            "  Precision: 0.7999\n",
            "  Recall: 0.7254\n",
            "  F1 Score: 0.7551\n",
            "  Roc Auc: 0.9580\n",
            "랜덤 포레스트:\n",
            "  Accuracy: 0.7829\n",
            "  Precision: 0.7910\n",
            "  Recall: 0.6797\n",
            "  F1 Score: 0.7015\n",
            "  Roc Auc: 0.9442\n",
            "SVM (선형 커널):\n",
            "  Accuracy: 0.8307\n",
            "  Precision: 0.8084\n",
            "  Recall: 0.7659\n",
            "  F1 Score: 0.7848\n",
            "  Roc Auc: 0.9569\n",
            "다항 나이브 베이즈:\n",
            "  Accuracy: 0.8032\n",
            "  Precision: 0.7870\n",
            "  Recall: 0.6995\n",
            "  F1 Score: 0.7207\n",
            "  Roc Auc: 0.9489\n",
            "XGBoost:\n",
            "  Accuracy: 0.7750\n",
            "  Precision: 0.7516\n",
            "  Recall: 0.6930\n",
            "  F1 Score: 0.7172\n",
            "  Roc Auc: 0.9383\n",
            "LightGBM:\n",
            "  Accuracy: 0.7699\n",
            "  Precision: 0.7605\n",
            "  Recall: 0.6951\n",
            "  F1 Score: 0.7211\n",
            "  Roc Auc: 0.9358\n",
            "MLPClassifier:\n",
            "  Accuracy: 0.8169\n",
            "  Precision: 0.7630\n",
            "  Recall: 0.7488\n",
            "  F1 Score: 0.7555\n",
            "  Roc Auc: 0.9534\n",
            "TensorFlow MLP:\n",
            "  Accuracy: 0.8234\n",
            "  Precision: 0.7775\n",
            "  Recall: 0.7549\n",
            "  F1 Score: 0.7654\n",
            "  Roc Auc: 0.9521\n",
            "\n",
            "모델 성능 요약 (최종 업데이트):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>로지스틱 회귀</th>\n",
              "      <td>0.821274</td>\n",
              "      <td>0.799943</td>\n",
              "      <td>0.725356</td>\n",
              "      <td>0.755069</td>\n",
              "      <td>0.958041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>랜덤 포레스트</th>\n",
              "      <td>0.782923</td>\n",
              "      <td>0.790972</td>\n",
              "      <td>0.679723</td>\n",
              "      <td>0.701499</td>\n",
              "      <td>0.944151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM (선형 커널)</th>\n",
              "      <td>0.830680</td>\n",
              "      <td>0.808433</td>\n",
              "      <td>0.765945</td>\n",
              "      <td>0.784791</td>\n",
              "      <td>0.956873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>다항 나이브 베이즈</th>\n",
              "      <td>0.803184</td>\n",
              "      <td>0.786991</td>\n",
              "      <td>0.699451</td>\n",
              "      <td>0.720733</td>\n",
              "      <td>0.948913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.774964</td>\n",
              "      <td>0.751638</td>\n",
              "      <td>0.692973</td>\n",
              "      <td>0.717220</td>\n",
              "      <td>0.938281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.769899</td>\n",
              "      <td>0.760505</td>\n",
              "      <td>0.695136</td>\n",
              "      <td>0.721088</td>\n",
              "      <td>0.935833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPClassifier</th>\n",
              "      <td>0.816932</td>\n",
              "      <td>0.763008</td>\n",
              "      <td>0.748779</td>\n",
              "      <td>0.755486</td>\n",
              "      <td>0.953398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TensorFlow MLP</th>\n",
              "      <td>0.823444</td>\n",
              "      <td>0.777459</td>\n",
              "      <td>0.754891</td>\n",
              "      <td>0.765364</td>\n",
              "      <td>0.952069</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                accuracy  precision    recall  f1_score   roc_auc\n",
              "로지스틱 회귀         0.821274   0.799943  0.725356  0.755069  0.958041\n",
              "랜덤 포레스트         0.782923   0.790972  0.679723  0.701499  0.944151\n",
              "SVM (선형 커널)     0.830680   0.808433  0.765945  0.784791  0.956873\n",
              "다항 나이브 베이즈      0.803184   0.786991  0.699451  0.720733  0.948913\n",
              "XGBoost         0.774964   0.751638  0.692973  0.717220  0.938281\n",
              "LightGBM        0.769899   0.760505  0.695136  0.721088  0.935833\n",
              "MLPClassifier   0.816932   0.763008  0.748779  0.755486  0.953398\n",
              "TensorFlow MLP  0.823444   0.777459  0.754891  0.765364  0.952069"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "num_classes = y_train_encoded.max() + 1\n",
        "\n",
        "# Define the TensorFlow Keras Sequential model\n",
        "model_tf = Sequential([\n",
        "    Input(shape=(X_train_dense.shape[1],)), # Use Input layer to specify input shape\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_tf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(\"\\n--- TensorFlow MLP 모델 학습 중 ---\")\n",
        "model_tf.fit(X_train_dense, y_train_encoded, epochs=50, batch_size=32) # verbose=0 to suppress epoch output\n",
        "print(\"TensorFlow MLP 모델 학습 완료.\")\n",
        "\n",
        "# Evaluate the trained model\n",
        "y_pred_proba_tf = model_tf.predict(X_test_dense)\n",
        "y_pred_tf = np.argmax(y_pred_proba_tf, axis=1)\n",
        "\n",
        "# Calculate basic metrics\n",
        "accuracy_tf = accuracy_score(y_test_encoded, y_pred_tf)\n",
        "precision_tf = precision_score(y_test_encoded, y_pred_tf, average='macro', zero_division=0)\n",
        "recall_tf = recall_score(y_test_encoded, y_pred_tf, average='macro', zero_division=0)\n",
        "f1_tf = f1_score(y_test_encoded, y_pred_tf, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"정확도 (Accuracy): {accuracy_tf:.4f}\")\n",
        "print(f\"정밀도 (Precision, macro): {precision_tf:.4f}\")\n",
        "print(f\"재현율 (Recall, macro): {recall_tf:.4f}\")\n",
        "print(f\"F1 스코어 (F1 Score, macro): {f1_tf:.4f}\")\n",
        "\n",
        "# Calculate ROC AUC score for multiclass (one-vs-rest)\n",
        "roc_auc_tf = None\n",
        "try:\n",
        "    roc_auc_tf = roc_auc_score(y_test_encoded, y_pred_proba_tf, multi_class='ovr', average='macro')\n",
        "    print(f\"ROC AUC (macro, ovr): {roc_auc_tf:.4f}\")\n",
        "except ValueError as e:\n",
        "    print(f\"ROC AUC 계산 오류: {e}\")\n",
        "\n",
        "# Store results\n",
        "results['TensorFlow MLP'] = {\n",
        "    'accuracy': accuracy_tf,\n",
        "    'precision': precision_tf,\n",
        "    'recall': recall_tf,\n",
        "    'f1_score': f1_tf,\n",
        "    'roc_auc': roc_auc_tf\n",
        "}\n",
        "\n",
        "print(\"\\n--- 모델 성능 비교 (TensorFlow MLP 추가) ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        if value is not None:\n",
        "            print(f\"  {metric_name.replace('_', ' ').title()}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {metric_name.replace('_', ' ').title()}: N/A\")\n",
        "\n",
        "# 결과를 DataFrame으로 변환 및 업데이트\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "\n",
        "print(\"\\n모델 성능 요약 (최종 업데이트):\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4f33255"
      },
      "source": [
        "## SMOTE 적용: ML모델"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f6c5256",
        "outputId": "ea65716c-e1cb-4a0f-e56b-e28dc53f73ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X_train shape: (15312, 25000)\n",
            "Resampled X_train shape: (28065, 25000)\n",
            "Original y_train shape: (15312,)\n",
            "Resampled y_train shape: (28065,)\n",
            "\n",
            "Class distribution before SMOTE:\n",
            " 0    5613\n",
            "2    4684\n",
            "4    3929\n",
            "1     544\n",
            "3     542\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class distribution after SMOTE:\n",
            " 2    5613\n",
            "0    5613\n",
            "4    5613\n",
            "3    5613\n",
            "1    5613\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize SMOTE with random_state=42\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "# Resample the training data\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_encoded)\n",
        "\n",
        "# Print the shapes of the resampled datasets to verify changes\n",
        "print(f\"Original X_train shape: {X_train.shape}\")\n",
        "print(f\"Resampled X_train shape: {X_train_resampled.shape}\")\n",
        "print(f\"Original y_train shape: {y_train_encoded.shape}\")\n",
        "print(f\"Resampled y_train shape: {y_train_resampled.shape}\")\n",
        "\n",
        "# Display the class distribution before and after SMOTE\n",
        "print(\"\\nClass distribution before SMOTE:\\n\", pd.Series(y_train_encoded).value_counts())\n",
        "print(\"\\nClass distribution after SMOTE:\\n\", pd.Series(y_train_resampled).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7acbf107",
        "outputId": "49b45eeb-b834-4c3c-fa56-b0a40bfba7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 로지스틱 회귀 (SMOTE) 모델 학습 중 ---\n",
            "정확도 (Accuracy): 0.8026\n",
            "정밀도 (Precision, macro): 0.7185\n",
            "재현율 (Recall, macro): 0.7398\n",
            "F1 스코어 (F1 Score, macro): 0.7281\n",
            "ROC AUC (macro, ovr): 0.9502\n",
            "\n",
            "--- 랜덤 포레스트 (SMOTE) 모델 학습 중 ---\n",
            "정확도 (Accuracy): 0.7448\n",
            "정밀도 (Precision, macro): 0.7057\n",
            "재현율 (Recall, macro): 0.6299\n",
            "F1 스코어 (F1 Score, macro): 0.6552\n",
            "ROC AUC (macro, ovr): 0.9375\n",
            "\n",
            "--- SVM (선형 커널) (SMOTE) 모델 학습 중 ---\n",
            "정확도 (Accuracy): 0.8044\n",
            "정밀도 (Precision, macro): 0.7571\n",
            "재현율 (Recall, macro): 0.7097\n",
            "F1 스코어 (F1 Score, macro): 0.7302\n",
            "ROC AUC (macro, ovr): 0.9312\n",
            "\n",
            "--- XGBoost (SMOTE) 모델 학습 중 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [07:06:56] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 (Accuracy): 0.7495\n",
            "정밀도 (Precision, macro): 0.7037\n",
            "재현율 (Recall, macro): 0.6571\n",
            "F1 스코어 (F1 Score, macro): 0.6762\n",
            "ROC AUC (macro, ovr): 0.9261\n",
            "\n",
            "--- LightGBM (SMOTE) 모델 학습 중 ---\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 4.039798 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 255787\n",
            "[LightGBM] [Info] Number of data points in the train set: 28065, number of used features: 7686\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 (Accuracy): 0.7644\n",
            "정밀도 (Precision, macro): 0.7078\n",
            "재현율 (Recall, macro): 0.6751\n",
            "F1 스코어 (F1 Score, macro): 0.6895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC (macro, ovr): 0.9345\n",
            "\n",
            "--- SMOTE 적용 모델 성능 비교 ---\n",
            "로지스틱 회귀 (SMOTE):\n",
            "  Accuracy: 0.8026\n",
            "  Precision: 0.7185\n",
            "  Recall: 0.7398\n",
            "  F1 Score: 0.7281\n",
            "  Roc Auc: 0.9502\n",
            "랜덤 포레스트 (SMOTE):\n",
            "  Accuracy: 0.7448\n",
            "  Precision: 0.7057\n",
            "  Recall: 0.6299\n",
            "  F1 Score: 0.6552\n",
            "  Roc Auc: 0.9375\n",
            "SVM (선형 커널) (SMOTE):\n",
            "  Accuracy: 0.8044\n",
            "  Precision: 0.7571\n",
            "  Recall: 0.7097\n",
            "  F1 Score: 0.7302\n",
            "  Roc Auc: 0.9312\n",
            "XGBoost (SMOTE):\n",
            "  Accuracy: 0.7495\n",
            "  Precision: 0.7037\n",
            "  Recall: 0.6571\n",
            "  F1 Score: 0.6762\n",
            "  Roc Auc: 0.9261\n",
            "LightGBM (SMOTE):\n",
            "  Accuracy: 0.7644\n",
            "  Precision: 0.7078\n",
            "  Recall: 0.6751\n",
            "  F1 Score: 0.6895\n",
            "  Roc Auc: 0.9345\n",
            "\n",
            "모델 성능 요약 (SMOTE 적용 모델 추가):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                     accuracy  precision    recall  f1_score   roc_auc\n",
              "로지스틱 회귀              0.807260   0.787021  0.665086  0.704727  0.953674\n",
              "랜덤 포레스트              0.744842   0.770915  0.552839  0.583159  0.933167\n",
              "SVM (선형 커널)          0.808566   0.776907  0.698505  0.729150  0.951566\n",
              "XGBoost              0.748237   0.704442  0.624776  0.653840  0.925893\n",
              "LightGBM             0.765735   0.717327  0.632927  0.663071  0.932142\n",
              "로지스틱 회귀 (SMOTE)      0.802559   0.718499  0.739819  0.728063  0.950174\n",
              "랜덤 포레스트 (SMOTE)      0.744842   0.705710  0.629868  0.655164  0.937508\n",
              "SVM (선형 커널) (SMOTE)  0.804388   0.757111  0.709704  0.730218  0.931172\n",
              "XGBoost (SMOTE)      0.749543   0.703657  0.657081  0.676250  0.926066\n",
              "LightGBM (SMOTE)     0.764429   0.707777  0.675117  0.689485  0.934525"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9751caa5-35cc-4ca2-bb53-def769d4203a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>로지스틱 회귀</th>\n",
              "      <td>0.807260</td>\n",
              "      <td>0.787021</td>\n",
              "      <td>0.665086</td>\n",
              "      <td>0.704727</td>\n",
              "      <td>0.953674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>랜덤 포레스트</th>\n",
              "      <td>0.744842</td>\n",
              "      <td>0.770915</td>\n",
              "      <td>0.552839</td>\n",
              "      <td>0.583159</td>\n",
              "      <td>0.933167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM (선형 커널)</th>\n",
              "      <td>0.808566</td>\n",
              "      <td>0.776907</td>\n",
              "      <td>0.698505</td>\n",
              "      <td>0.729150</td>\n",
              "      <td>0.951566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.748237</td>\n",
              "      <td>0.704442</td>\n",
              "      <td>0.624776</td>\n",
              "      <td>0.653840</td>\n",
              "      <td>0.925893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.765735</td>\n",
              "      <td>0.717327</td>\n",
              "      <td>0.632927</td>\n",
              "      <td>0.663071</td>\n",
              "      <td>0.932142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>로지스틱 회귀 (SMOTE)</th>\n",
              "      <td>0.802559</td>\n",
              "      <td>0.718499</td>\n",
              "      <td>0.739819</td>\n",
              "      <td>0.728063</td>\n",
              "      <td>0.950174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>랜덤 포레스트 (SMOTE)</th>\n",
              "      <td>0.744842</td>\n",
              "      <td>0.705710</td>\n",
              "      <td>0.629868</td>\n",
              "      <td>0.655164</td>\n",
              "      <td>0.937508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM (선형 커널) (SMOTE)</th>\n",
              "      <td>0.804388</td>\n",
              "      <td>0.757111</td>\n",
              "      <td>0.709704</td>\n",
              "      <td>0.730218</td>\n",
              "      <td>0.931172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost (SMOTE)</th>\n",
              "      <td>0.749543</td>\n",
              "      <td>0.703657</td>\n",
              "      <td>0.657081</td>\n",
              "      <td>0.676250</td>\n",
              "      <td>0.926066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM (SMOTE)</th>\n",
              "      <td>0.764429</td>\n",
              "      <td>0.707777</td>\n",
              "      <td>0.675117</td>\n",
              "      <td>0.689485</td>\n",
              "      <td>0.934525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9751caa5-35cc-4ca2-bb53-def769d4203a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9751caa5-35cc-4ca2-bb53-def769d4203a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9751caa5-35cc-4ca2-bb53-def769d4203a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-314971d7-05df-4b12-9639-1a02f8f00d47\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-314971d7-05df-4b12-9639-1a02f8f00d47')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-314971d7-05df-4b12-9639-1a02f8f00d47 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_18080cd9-15be-48af-9eba-ab14d212a9b5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_18080cd9-15be-48af-9eba-ab14d212a9b5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02821004281037641,\n        \"min\": 0.7448419952990337,\n        \"max\": 0.8085662052755288,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.7495429616087751,\n          0.7448419952990337,\n          0.8025594149908593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03389668216798148,\n        \"min\": 0.7036573500009776,\n        \"max\": 0.7870208097497894,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.7036573500009776,\n          0.7709148972672776,\n          0.7184993659994566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.052632872630569656,\n        \"min\": 0.5528388156638591,\n        \"max\": 0.7398194166066979,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6570807080656137,\n          0.5528388156638591,\n          0.7398194166066979\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0458398623606285,\n        \"min\": 0.5831593413924694,\n        \"max\": 0.7302178761695564,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.6762498252660112,\n          0.5831593413924694,\n          0.7280625683168817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010444814030273393,\n        \"min\": 0.9258931989606165,\n        \"max\": 0.9536742034938743,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.9260659838266498,\n          0.9331674815387021,\n          0.9501742919801236\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Define models to train\n",
        "models_smote = {\n",
        "    '로지스틱 회귀 (SMOTE)': LogisticRegression(random_state=42, max_iter=1000, solver='saga', n_jobs=-1),\n",
        "    '랜덤 포레스트 (SMOTE)': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
        "    'SVM (선형 커널) (SMOTE)': SVC(kernel='linear', probability=True, random_state=42),\n",
        "    # '다항 나이브 베이즈 (SMOTE)': MultinomialNB(),\n",
        "    'XGBoost (SMOTE)': XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss', use_label_encoder=False),\n",
        "    'LightGBM (SMOTE)': LGBMClassifier(random_state=42, n_jobs=-1)\n",
        "}\n",
        "\n",
        "results_smote = {}\n",
        "\n",
        "for name, model in models_smote.items():\n",
        "    print(f\"\\n--- {name} 모델 학습 중 ---\")\n",
        "    model.fit(X_train_resampled, y_train_resampled) # Fit with resampled labels\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate basic metrics\n",
        "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
        "    precision = precision_score(y_test_encoded, y_pred, average='macro', zero_division=0)\n",
        "    recall = recall_score(y_test_encoded, y_pred, average='macro', zero_division=0)\n",
        "    f1 = f1_score(y_test_encoded, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"정확도 (Accuracy): {accuracy:.4f}\")\n",
        "    print(f\"정밀도 (Precision, macro): {precision:.4f}\")\n",
        "    print(f\"재현율 (Recall, macro): {recall:.4f}\")\n",
        "    print(f\"F1 스코어 (F1 Score, macro): {f1:.4f}\")\n",
        "\n",
        "    # Calculate ROC AUC score for multiclass (one-vs-rest)\n",
        "    roc_auc = None\n",
        "    try:\n",
        "        y_pred_proba = model.predict_proba(X_test)\n",
        "        roc_auc = roc_auc_score(y_test_encoded, y_pred_proba, multi_class='ovr', average='macro')\n",
        "        print(f\"ROC AUC (macro, ovr): {roc_auc:.4f}\")\n",
        "    except AttributeError:\n",
        "        print(\"해당 모델은 predict_proba를 지원하지 않아 ROC AUC를 계산하지 않습니다.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"ROC AUC 계산 오류: {e}\")\n",
        "\n",
        "    # Store results\n",
        "    results_smote[name] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'roc_auc': roc_auc\n",
        "    }\n",
        "\n",
        "print(\"\\n--- SMOTE 적용 모델 성능 비교 ---\")\n",
        "for name, metrics in results_smote.items():\n",
        "    print(f\"{name}:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        if value is not None:\n",
        "            print(f\"  {metric_name.replace('_', ' ').title()}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {metric_name.replace('_', ' ').title()}: N/A\")\n",
        "\n",
        "# Combine results with previous results\n",
        "results_df_smote = pd.DataFrame.from_dict(results_smote, orient='index')\n",
        "# Merge with previous results_df if it exists, otherwise just use results_df_smote\n",
        "if 'results_df' in globals():\n",
        "    results_df = pd.concat([results_df, results_df_smote])\n",
        "else:\n",
        "    results_df = results_df_smote\n",
        "\n",
        "print(\"\\n모델 성능 요약 (SMOTE 적용 모델 추가):\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3e31783"
      },
      "source": [
        "## SMOTE 적용: TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62a2dc45",
        "outputId": "cc6d843f-6120-4065-d5c5-0dc4e37e06a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resampled X_train_dense shape: (11760, 25000)\n"
          ]
        }
      ],
      "source": [
        "X_train_resampled_dense = X_train_resampled.toarray()\n",
        "\n",
        "print(f\"Resampled X_train_dense shape: {X_train_resampled_dense.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5a12a922",
        "outputId": "83c005b4-75c7-40cc-b98d-729c690013d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- TensorFlow MLP (SMOTE) 모델 학습 중 ---\n",
            "TensorFlow MLP (SMOTE) 모델 학습 완료.\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "정확도 (Accuracy): 0.8177\n",
            "정밀도 (Precision, macro): 0.7741\n",
            "재현율 (Recall, macro): 0.7370\n",
            "F1 스코어 (F1 Score, macro): 0.7535\n",
            "ROC AUC (macro, ovr): 0.9498\n",
            "\n",
            "--- 모델 성능 비교 (TensorFlow MLP (SMOTE) 추가) ---\n",
            "로지스틱 회귀:\n",
            "  Accuracy: 0.8213\n",
            "  Precision: 0.7999\n",
            "  Recall: 0.7254\n",
            "  F1 Score: 0.7551\n",
            "  Roc Auc: 0.9583\n",
            "랜덤 포레스트:\n",
            "  Accuracy: 0.7786\n",
            "  Precision: 0.7962\n",
            "  Recall: 0.6736\n",
            "  F1 Score: 0.6950\n",
            "  Roc Auc: 0.9475\n",
            "SVM (선형 커널):\n",
            "  Accuracy: 0.8314\n",
            "  Precision: 0.8083\n",
            "  Recall: 0.7663\n",
            "  F1 Score: 0.7849\n",
            "  Roc Auc: 0.9570\n",
            "다항 나이브 베이즈:\n",
            "  Accuracy: 0.8032\n",
            "  Precision: 0.7870\n",
            "  Recall: 0.6995\n",
            "  F1 Score: 0.7207\n",
            "  Roc Auc: 0.9493\n",
            "XGBoost:\n",
            "  Accuracy: 0.7721\n",
            "  Precision: 0.7516\n",
            "  Recall: 0.6880\n",
            "  F1 Score: 0.7137\n",
            "  Roc Auc: 0.9365\n",
            "LightGBM:\n",
            "  Accuracy: 0.7721\n",
            "  Precision: 0.7496\n",
            "  Recall: 0.6900\n",
            "  F1 Score: 0.7136\n",
            "  Roc Auc: 0.9361\n",
            "MLPClassifier:\n",
            "  Accuracy: 0.8198\n",
            "  Precision: 0.7720\n",
            "  Recall: 0.7486\n",
            "  F1 Score: 0.7592\n",
            "  Roc Auc: 0.9532\n",
            "TensorFlow MLP:\n",
            "  Accuracy: 0.8234\n",
            "  Precision: 0.7852\n",
            "  Recall: 0.7473\n",
            "  F1 Score: 0.7636\n",
            "  Roc Auc: 0.9487\n",
            "TensorFlow MLP (SMOTE):\n",
            "  Accuracy: 0.8177\n",
            "  Precision: 0.7741\n",
            "  Recall: 0.7370\n",
            "  F1 Score: 0.7535\n",
            "  Roc Auc: 0.9498\n",
            "\n",
            "모델 성능 요약 (최종 업데이트):\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023845523955548602,\n        \"min\": 0.7720694645441389,\n        \"max\": 0.8314037626628076,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7785817655571635,\n          0.8198263386396527,\n          0.821273516642547\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020501701600491893,\n        \"min\": 0.7496185285317345,\n        \"max\": 0.8083237262279646,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.7851628005559469,\n          0.7961809379575124,\n          0.7496185285317345\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03261896889840139,\n        \"min\": 0.6736416032442095,\n        \"max\": 0.7662854292481497,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.7472587675358247,\n          0.6736416032442095,\n          0.6899861746107069\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.029887057375654506,\n        \"min\": 0.6949858767784244,\n        \"max\": 0.7849056613865046,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.7636245959149901,\n          0.6949858767784244,\n          0.7135605664209456\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.007833236622498106,\n        \"min\": 0.9361131761582347,\n        \"max\": 0.958272094868198,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.9486574614687726,\n          0.9474594972700874,\n          0.9361131761582347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "results_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-19c99825-f7df-4c29-ba74-44ab70bc0f48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>로지스틱 회귀</th>\n",
              "      <td>0.821274</td>\n",
              "      <td>0.799943</td>\n",
              "      <td>0.725356</td>\n",
              "      <td>0.755069</td>\n",
              "      <td>0.958272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>랜덤 포레스트</th>\n",
              "      <td>0.778582</td>\n",
              "      <td>0.796181</td>\n",
              "      <td>0.673642</td>\n",
              "      <td>0.694986</td>\n",
              "      <td>0.947459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM (선형 커널)</th>\n",
              "      <td>0.831404</td>\n",
              "      <td>0.808324</td>\n",
              "      <td>0.766285</td>\n",
              "      <td>0.784906</td>\n",
              "      <td>0.957019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>다항 나이브 베이즈</th>\n",
              "      <td>0.803184</td>\n",
              "      <td>0.786991</td>\n",
              "      <td>0.699451</td>\n",
              "      <td>0.720733</td>\n",
              "      <td>0.949336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoost</th>\n",
              "      <td>0.772069</td>\n",
              "      <td>0.751617</td>\n",
              "      <td>0.688020</td>\n",
              "      <td>0.713656</td>\n",
              "      <td>0.936507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LightGBM</th>\n",
              "      <td>0.772069</td>\n",
              "      <td>0.749619</td>\n",
              "      <td>0.689986</td>\n",
              "      <td>0.713561</td>\n",
              "      <td>0.936113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPClassifier</th>\n",
              "      <td>0.819826</td>\n",
              "      <td>0.772006</td>\n",
              "      <td>0.748561</td>\n",
              "      <td>0.759240</td>\n",
              "      <td>0.953203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TensorFlow MLP</th>\n",
              "      <td>0.823444</td>\n",
              "      <td>0.785163</td>\n",
              "      <td>0.747259</td>\n",
              "      <td>0.763625</td>\n",
              "      <td>0.948657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TensorFlow MLP (SMOTE)</th>\n",
              "      <td>0.817656</td>\n",
              "      <td>0.774126</td>\n",
              "      <td>0.737014</td>\n",
              "      <td>0.753545</td>\n",
              "      <td>0.949765</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19c99825-f7df-4c29-ba74-44ab70bc0f48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19c99825-f7df-4c29-ba74-44ab70bc0f48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19c99825-f7df-4c29-ba74-44ab70bc0f48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1eade305-cd42-4c1a-8328-83cf7583e6fd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1eade305-cd42-4c1a-8328-83cf7583e6fd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1eade305-cd42-4c1a-8328-83cf7583e6fd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_917c4462-f82d-47bb-a23f-c556a706adce\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_917c4462-f82d-47bb-a23f-c556a706adce button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                        accuracy  precision    recall  f1_score   roc_auc\n",
              "로지스틱 회귀                 0.821274   0.799943  0.725356  0.755069  0.958272\n",
              "랜덤 포레스트                 0.778582   0.796181  0.673642  0.694986  0.947459\n",
              "SVM (선형 커널)             0.831404   0.808324  0.766285  0.784906  0.957019\n",
              "다항 나이브 베이즈              0.803184   0.786991  0.699451  0.720733  0.949336\n",
              "XGBoost                 0.772069   0.751617  0.688020  0.713656  0.936507\n",
              "LightGBM                0.772069   0.749619  0.689986  0.713561  0.936113\n",
              "MLPClassifier           0.819826   0.772006  0.748561  0.759240  0.953203\n",
              "TensorFlow MLP          0.823444   0.785163  0.747259  0.763625  0.948657\n",
              "TensorFlow MLP (SMOTE)  0.817656   0.774126  0.737014  0.753545  0.949765"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import pandas as pd\n",
        "\n",
        "# 1. num_classes 변수 정의\n",
        "num_classes = y_train_resampled.max() + 1\n",
        "\n",
        "# 2. TensorFlow Keras Sequential 모델 정의\n",
        "model_tf_smote = Sequential([\n",
        "    Input(shape=(X_train_resampled_dense.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 3. 모델 컴파일\n",
        "model_tf_smote.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5. 모델 훈련\n",
        "print(\"\\n--- TensorFlow MLP (SMOTE) 모델 학습 중 ---\")\n",
        "model_tf_smote.fit(X_train_resampled_dense, y_train_resampled, epochs=50, batch_size=32, verbose=0)\n",
        "print(\"TensorFlow MLP (SMOTE) 모델 학습 완료.\")\n",
        "\n",
        "# 6. X_test는 이미 X_test_dense로 변환되어 있습니다.\n",
        "\n",
        "# 7. 훈련된 모델을 사용하여 예측 확률 및 예측 클래스 계산\n",
        "y_pred_proba_tf_smote = model_tf_smote.predict(X_test_dense)\n",
        "y_pred_tf_smote = np.argmax(y_pred_proba_tf_smote, axis=1)\n",
        "\n",
        "# 8. 기본 평가 지표 계산\n",
        "accuracy_tf_smote = accuracy_score(y_test_encoded, y_pred_tf_smote)\n",
        "precision_tf_smote = precision_score(y_test_encoded, y_pred_tf_smote, average='macro', zero_division=0)\n",
        "recall_tf_smote = recall_score(y_test_encoded, y_pred_tf_smote, average='macro', zero_division=0)\n",
        "f1_tf_smote = f1_score(y_test_encoded, y_pred_tf_smote, average='macro', zero_division=0)\n",
        "\n",
        "print(f\"정확도 (Accuracy): {accuracy_tf_smote:.4f}\")\n",
        "print(f\"정밀도 (Precision, macro): {precision_tf_smote:.4f}\")\n",
        "print(f\"재현율 (Recall, macro): {recall_tf_smote:.4f}\")\n",
        "print(f\"F1 스코어 (F1 Score, macro): {f1_tf_smote:.4f}\")\n",
        "\n",
        "# 9. 다중 클래스 ROC AUC 스코어 계산 (one-vs-rest)\n",
        "roc_auc_tf_smote = None\n",
        "try:\n",
        "    roc_auc_tf_smote = roc_auc_score(y_test_encoded, y_pred_proba_tf_smote, multi_class='ovr', average='macro')\n",
        "    print(f\"ROC AUC (macro, ovr): {roc_auc_tf_smote:.4f}\")\n",
        "except ValueError as e:\n",
        "    print(f\"ROC AUC 계산 오류: {e}\")\n",
        "\n",
        "# 10. 계산된 지표들을 'TensorFlow MLP (SMOTE)'라는 키로 results 딕셔너리에 추가\n",
        "results['TensorFlow MLP (SMOTE)'] = {\n",
        "    'accuracy': accuracy_tf_smote,\n",
        "    'precision': precision_tf_smote,\n",
        "    'recall': recall_tf_smote,\n",
        "    'f1_score': f1_tf_smote,\n",
        "    'roc_auc': roc_auc_tf_smote\n",
        "}\n",
        "\n",
        "print(\"\\n--- 모델 성능 비교 (TensorFlow MLP (SMOTE) 추가) ---\")\n",
        "for name, metrics in results.items():\n",
        "    print(f\"{name}:\")\n",
        "    for metric_name, value in metrics.items():\n",
        "        if value is not None:\n",
        "            print(f\"  {metric_name.replace('_', ' ').title()}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {metric_name.replace('_', ' ').title()}: N/A\")\n",
        "\n",
        "# 결과를 DataFrame으로 변환 및 업데이트\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "\n",
        "print(\"\\n모델 성능 요약 (최종 업데이트):\")\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼 파라미터 튜닝: 로지스틱 회귀(SMOTE 적용)"
      ],
      "metadata": {
        "id": "al2p7Kaabx7k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE8iz-IVYcL_",
        "outputId": "6c41a558-210d-44b2-ba77-adbb030e490b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [07:27<00:00, 14.91s/trial, best loss: -0.9405636177743849]\n",
            "\n",
            "Best raw hyperopt result: {'C': np.float64(94.05296206259835), 'l1_ratio': np.float64(0.5896443347363269), 'penalty': np.int64(0), 'solver': np.int64(0)}\n",
            "Mapped best params: {'C': 94.05296206259835, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "\n",
            "\n",
            "Best raw hyperopt result: {'C': np.float64(94.05296206259835), 'l1_ratio': np.float64(0.5896443347363269), 'penalty': np.int64(0), 'solver': np.int64(0)}\n",
            "Mapped best params: {'C': 94.05296206259835, 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "\n",
            "--- Final evaluation on test set ---\n",
            "accuracy: 0.8249\n",
            "precision_macro: 0.7830\n",
            "recall_macro: 0.7725\n",
            "f1_macro: 0.7774\n",
            "roc_auc_ovr: 0.9568\n",
            "\n",
            "--- Final evaluation on test set ---\n",
            "accuracy: 0.8249\n",
            "precision_macro: 0.7830\n",
            "recall_macro: 0.7725\n",
            "f1_macro: 0.7774\n",
            "roc_auc_ovr: 0.9568\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression 하이퍼파라미터 튜닝 (SMOTE 적용 데이터 사용)\n",
        "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 데이터가 존재하는지 확인 (이전 셀에서 SMOTE가 적용되어야 함)\n",
        "required_vars = ['X_train_resampled', 'y_train_resampled', 'X_test', 'y_test_encoded']\n",
        "missing = [v for v in required_vars if v not in globals()]\n",
        "if missing:\n",
        "    raise NameError(f\"필요한 변수가 세션에 없습니다: {missing}. 먼저 관련 셀들을 실행하세요.\")\n",
        "\n",
        "# 하이퍼파라미터 탐색 공간 정의\n",
        "space = {\n",
        "    'C': hp.loguniform('C', np.log(1e-4), np.log(1e2)),\n",
        "    # hp.choice는 fmin이 인덱스를 반환하므로, objective에서 인덱스를 실제 값으로 매핑합니다.\n",
        "    'penalty': hp.choice('penalty', ['l2', 'l1', 'elasticnet']),\n",
        "    'solver': hp.choice('solver', ['liblinear', 'saga']),\n",
        "    'l1_ratio': hp.uniform('l1_ratio', 0.0, 1.0)  # elasticnet일 때만 사용\n",
        "}\n",
        "\n",
        "# choice 리스트(인덱스 -> 값 매핑용)\n",
        "penalty_choices = ['l2', 'l1', 'elasticnet']\n",
        "solver_choices = ['liblinear', 'saga']\n",
        "\n",
        "def _is_intlike(val):\n",
        "    # Accept Python int and numpy integer types\n",
        "    return isinstance(val, (int, np.integer))\n",
        "\n",
        "def objective(params):\n",
        "    # hyperopt의 hp.choice는 인덱스를 반환하므로 실제 값으로 변환\n",
        "    penalty = penalty_choices[params['penalty']] if _is_intlike(params.get('penalty')) else params['penalty']\n",
        "    solver = solver_choices[params['solver']] if _is_intlike(params.get('solver')) else params['solver']\n",
        "    C = float(params['C'])\n",
        "    l1_ratio = float(params['l1_ratio'])\n",
        "\n",
        "    # elasticnet은 saga 전용이므로 solver를 강제\n",
        "    if penalty == 'elasticnet':\n",
        "        solver = 'saga'\n",
        "\n",
        "    # Build LogisticRegression args safely\n",
        "    lr_kwargs = {\n",
        "        'C': C,\n",
        "        'penalty': penalty,\n",
        "        'solver': solver,\n",
        "        'max_iter': 1000,\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1\n",
        "    }\n",
        "    if penalty == 'elasticnet':\n",
        "        lr_kwargs['l1_ratio'] = l1_ratio\n",
        "\n",
        "    try:\n",
        "        model = LogisticRegression(**lr_kwargs)\n",
        "        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "        scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "        f1_mean = np.mean(scores)\n",
        "        # hyperopt는 loss를 최소화하므로 음수 F1을 반환\n",
        "        return {'loss': -f1_mean, 'status': STATUS_OK}\n",
        "    except Exception as e:\n",
        "        # 실패 시 큰 손실을 반환하여 해당 파라미터 조합을 기각\n",
        "        print('Objective error:', e)\n",
        "        return {'loss': 1.0, 'status': STATUS_OK}\n",
        "\n",
        "# 튜닝 실행 (탐색 횟수는 환경/시간에 맞춰 조절)\n",
        "trials = Trials()\n",
        "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=30, trials=trials, rstate=np.random.default_rng(42))\n",
        "\n",
        "# hyperopt 결과를 사람이 읽기 쉬운 값으로 변환\n",
        "best_params = {}\n",
        "best_params['C'] = float(best['C']) if best.get('C') is not None else None\n",
        "best_params['penalty'] = penalty_choices[int(best['penalty'])] if _is_intlike(best.get('penalty')) else best.get('penalty')\n",
        "best_params['solver'] = solver_choices[int(best['solver'])] if _is_intlike(best.get('solver')) else best.get('solver')\n",
        "if best_params['penalty'] == 'elasticnet':\n",
        "    best_params['l1_ratio'] = float(best.get('l1_ratio', 0.5))\n",
        "\n",
        "print('\\nBest raw hyperopt result:', best)\n",
        "print('Mapped best params:', best_params)\n",
        "\n",
        "# 최적 파라미터로 모델 재학습 및 평가\n",
        "final_kwargs = {\n",
        "    'C': best_params['C'],\n",
        "    'penalty': best_params['penalty'],\n",
        "    'solver': best_params['solver'],\n",
        "    'max_iter': 1000,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1\n",
        "}\n",
        "if best_params['penalty'] == 'elasticnet':\n",
        "    final_kwargs['l1_ratio'] = best_params['l1_ratio']\n",
        "\n",
        "final_model = LogisticRegression(**final_kwargs)\n",
        "final_model.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "y_pred = final_model.predict(X_test)\n",
        "metrics = {\n",
        "    'accuracy': accuracy_score(y_test_encoded, y_pred),\n",
        "    'precision_macro': precision_score(y_test_encoded, y_pred, average='macro', zero_division=0),\n",
        "    'recall_macro': recall_score(y_test_encoded, y_pred, average='macro', zero_division=0),\n",
        "    'f1_macro': f1_score(y_test_encoded, y_pred, average='macro', zero_division=0)\n",
        "}\n",
        "print('\\n--- Final evaluation on test set ---')\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# ROC AUC (멀티클래스) 시도\n",
        "if hasattr(final_model, 'predict_proba'):\n",
        "    try:\n",
        "        y_proba = final_model.predict_proba(X_test)\n",
        "        roc = roc_auc_score(y_test_encoded, y_proba, multi_class='ovr', average='macro')\n",
        "        print(f\"roc_auc_ovr: {roc:.4f}\")\n",
        "    except Exception as e:\n",
        "        print('ROC AUC 계산 중 오류:', e)\n",
        "else:\n",
        "    print('predict_proba를 지원하지 않아 ROC AUC를 계산하지 않습니다.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼 파라미터 튜닝: SVM(SMOTE 적용)"
      ],
      "metadata": {
        "id": "j25-iDyQb1gg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwCiRbgFaRYc",
        "outputId": "1eee4fcc-38cc-4734-9cbf-8d753e73ee95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [15:20<00:00, 92.08s/trial, best loss: -0.942136424520681]\n",
            "\n",
            "Best raw hyperopt result (SVM): {'C': np.float64(8.136814186461567), 'class_weight': np.int64(1), 'degree': np.float64(5.0), 'gamma': np.float64(0.007250316961973838), 'kernel': np.int64(0)}\n",
            "Mapped best params (SVM): {'C': 8.136814186461567, 'kernel': 'linear', 'gamma': 0.007250316961973838, 'degree': 5, 'class_weight': 'balanced'}\n",
            "\n",
            "\n",
            "Best raw hyperopt result (SVM): {'C': np.float64(8.136814186461567), 'class_weight': np.int64(1), 'degree': np.float64(5.0), 'gamma': np.float64(0.007250316961973838), 'kernel': np.int64(0)}\n",
            "Mapped best params (SVM): {'C': 8.136814186461567, 'kernel': 'linear', 'gamma': 0.007250316961973838, 'degree': 5, 'class_weight': 'balanced'}\n",
            "\n",
            "--- Final SVM evaluation on test set ---\n",
            "accuracy: 0.8213\n",
            "precision_macro: 0.7974\n",
            "recall_macro: 0.7611\n",
            "f1_macro: 0.7776\n",
            "\n",
            "--- Final SVM evaluation on test set ---\n",
            "accuracy: 0.8213\n",
            "precision_macro: 0.7974\n",
            "recall_macro: 0.7611\n",
            "f1_macro: 0.7776\n",
            "roc_auc_ovr: 0.9513\n",
            "roc_auc_ovr: 0.9513\n"
          ]
        }
      ],
      "source": [
        "# SVM 하이퍼파라미터 튜닝 (SMOTE 적용 데이터 사용)\n",
        "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 필요한 변수 확인\n",
        "required_vars = ['X_train_resampled', 'y_train_resampled', 'X_test', 'y_test_encoded']\n",
        "missing = [v for v in required_vars if v not in globals()]\n",
        "if missing:\n",
        "    raise NameError(f\"필요한 변수가 세션에 없습니다: {missing}. 먼저 관련 셀들을 실행하세요.\")\n",
        "\n",
        "# 검색 공간 정의\n",
        "space_svm = {\n",
        "    'C': hp.loguniform('C', np.log(1e-3), np.log(1e3)),\n",
        "    'kernel': hp.choice('kernel', ['linear', 'rbf', 'poly']),\n",
        "    # gamma는 수치형으로 탐색하되 linear 커널에서는 무시됩니다.\n",
        "    'gamma': hp.loguniform('gamma', np.log(1e-4), np.log(1e-1)),\n",
        "    # degree는 poly 커널에서만 사용\n",
        "    'degree': hp.quniform('degree', 2, 5, 1),\n",
        "    # 클래스 가중치 (None 또는 'balanced')\n",
        "    'class_weight': hp.choice('class_weight', [None, 'balanced'])\n",
        "}\n",
        "\n",
        "kernel_choices = ['linear', 'rbf', 'poly']\n",
        "class_weight_choices = [None, 'balanced']\n",
        "\n",
        "def _is_intlike(val):\n",
        "    return isinstance(val, (int, np.integer))\n",
        "\n",
        "\n",
        "def objective_svm(params):\n",
        "    # hp.choice는 인덱스를 반환할 수 있으므로 안전하게 변환\n",
        "    kernel = kernel_choices[params['kernel']] if _is_intlike(params.get('kernel')) else params['kernel']\n",
        "    class_weight = class_weight_choices[params['class_weight']] if _is_intlike(params.get('class_weight')) else params['class_weight']\n",
        "    C = float(params['C'])\n",
        "    gamma = float(params['gamma'])\n",
        "    degree = int(params['degree'])\n",
        "\n",
        "    # SVC 인자 구성\n",
        "    svc_kwargs = {\n",
        "        'C': C,\n",
        "        'kernel': kernel,\n",
        "        'probability': True,  # predict_proba 사용을 위해 True로 설정\n",
        "        'random_state': 42\n",
        "    }\n",
        "    if kernel in ['rbf', 'poly']:\n",
        "        svc_kwargs['gamma'] = gamma\n",
        "    if kernel == 'poly':\n",
        "        svc_kwargs['degree'] = degree\n",
        "    if class_weight is not None:\n",
        "        svc_kwargs['class_weight'] = class_weight\n",
        "\n",
        "    try:\n",
        "        model = SVC(**svc_kwargs)\n",
        "        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "        scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "        f1_mean = np.mean(scores)\n",
        "        return {'loss': -f1_mean, 'status': STATUS_OK}\n",
        "    except Exception as e:\n",
        "        print('Objective error (SVM):', e)\n",
        "        return {'loss': 1.0, 'status': STATUS_OK}\n",
        "\n",
        "# 튜닝 실행\n",
        "trials = Trials()\n",
        "best_svm = fmin(fn=objective_svm, space=space_svm, algo=tpe.suggest, max_evals=10, trials=trials, rstate=np.random.default_rng(42))\n",
        "\n",
        "# 결과 매핑\n",
        "best_params_svm = {}\n",
        "best_params_svm['C'] = float(best_svm['C'])\n",
        "best_params_svm['kernel'] = kernel_choices[int(best_svm['kernel'])] if _is_intlike(best_svm.get('kernel')) else best_svm.get('kernel')\n",
        "best_params_svm['gamma'] = float(best_svm['gamma'])\n",
        "best_params_svm['degree'] = int(best_svm['degree'])\n",
        "best_params_svm['class_weight'] = class_weight_choices[int(best_svm['class_weight'])] if _is_intlike(best_svm.get('class_weight')) else best_svm.get('class_weight')\n",
        "\n",
        "print('\\nBest raw hyperopt result (SVM):', best_svm)\n",
        "print('Mapped best params (SVM):', best_params_svm)\n",
        "\n",
        "# 최적 파라미터로 재학습 및 평가\n",
        "svc_final_kwargs = {\n",
        "    'C': best_params_svm['C'],\n",
        "    'kernel': best_params_svm['kernel'],\n",
        "    'probability': True,\n",
        "    'random_state': 42\n",
        "}\n",
        "if svc_final_kwargs['kernel'] in ['rbf', 'poly']:\n",
        "    svc_final_kwargs['gamma'] = best_params_svm['gamma']\n",
        "if svc_final_kwargs['kernel'] == 'poly':\n",
        "    svc_final_kwargs['degree'] = best_params_svm['degree']\n",
        "if best_params_svm['class_weight'] is not None:\n",
        "    svc_final_kwargs['class_weight'] = best_params_svm['class_weight']\n",
        "\n",
        "svc_final = SVC(**svc_final_kwargs)\n",
        "svc_final.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "y_pred_svm = svc_final.predict(X_test)\n",
        "metrics_svm = {\n",
        "    'accuracy': accuracy_score(y_test_encoded, y_pred_svm),\n",
        "    'precision_macro': precision_score(y_test_encoded, y_pred_svm, average='macro', zero_division=0),\n",
        "    'recall_macro': recall_score(y_test_encoded, y_pred_svm, average='macro', zero_division=0),\n",
        "    'f1_macro': f1_score(y_test_encoded, y_pred_svm, average='macro', zero_division=0)\n",
        "}\n",
        "\n",
        "print('\\n--- Final SVM evaluation on test set ---')\n",
        "for k, v in metrics_svm.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# ROC AUC (멀티클래스)\n",
        "if hasattr(svc_final, 'predict_proba'):\n",
        "    try:\n",
        "        y_proba_svm = svc_final.predict_proba(X_test)\n",
        "        roc_svm = roc_auc_score(y_test_encoded, y_proba_svm, multi_class='ovr', average='macro')\n",
        "        print(f\"roc_auc_ovr: {roc_svm:.4f}\")\n",
        "    except Exception as e:\n",
        "        print('ROC AUC 계산 중 오류 (SVM):', e)\n",
        "else:\n",
        "    print('predict_proba를 지원하지 않아 ROC AUC를 계산하지 않습니다.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼 파라미터 튜닝: LightGBM(SMOTE 적용)"
      ],
      "metadata": {
        "id": "1FxTuHKab4y2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxwarKRGaRYc",
        "outputId": "d213788b-af08-465e-b7a5-c340daadc082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [12:24<00:00, 24.82s/trial, best loss: -0.9152872761096339]\n",
            "\n",
            "Best raw hyperopt result (LightGBM): {'colsample_bytree': np.float64(0.50352260569653), 'learning_rate': np.float64(0.045782746092955094), 'max_depth': np.float64(7.0), 'min_child_samples': np.float64(6.0), 'n_estimators': np.float64(750.0), 'num_leaves': np.float64(16.0), 'reg_alpha': np.float64(4.176807414168082e-07), 'reg_lambda': np.float64(1.4471260182754633e-05), 'subsample': np.float64(0.7980030856766458)}\n",
            "Mapped best params (LightGBM): {'n_estimators': 750, 'learning_rate': 0.045782746092955094, 'num_leaves': 16, 'max_depth': 7, 'min_child_samples': 6, 'subsample': 0.7980030856766458, 'colsample_bytree': 0.50352260569653, 'reg_alpha': 4.176807414168082e-07, 'reg_lambda': 1.4471260182754633e-05}\n",
            "\n",
            "\n",
            "Best raw hyperopt result (LightGBM): {'colsample_bytree': np.float64(0.50352260569653), 'learning_rate': np.float64(0.045782746092955094), 'max_depth': np.float64(7.0), 'min_child_samples': np.float64(6.0), 'n_estimators': np.float64(750.0), 'num_leaves': np.float64(16.0), 'reg_alpha': np.float64(4.176807414168082e-07), 'reg_lambda': np.float64(1.4471260182754633e-05), 'subsample': np.float64(0.7980030856766458)}\n",
            "Mapped best params (LightGBM): {'n_estimators': 750, 'learning_rate': 0.045782746092955094, 'num_leaves': 16, 'max_depth': 7, 'min_child_samples': 6, 'subsample': 0.7980030856766458, 'colsample_bytree': 0.50352260569653, 'reg_alpha': 4.176807414168082e-07, 'reg_lambda': 1.4471260182754633e-05}\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081673 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 147785\n",
            "[LightGBM] [Info] Number of data points in the train set: 11760, number of used features: 10379\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081673 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 147785\n",
            "[LightGBM] [Info] Number of data points in the train set: 11760, number of used features: 10379\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "--- Final LightGBM evaluation on test set ---\n",
            "accuracy: 0.7981\n",
            "precision_macro: 0.7771\n",
            "recall_macro: 0.7208\n",
            "f1_macro: 0.7444\n",
            "roc_auc_ovr: 0.9432\n",
            "\n",
            "--- Final LightGBM evaluation on test set ---\n",
            "accuracy: 0.7981\n",
            "precision_macro: 0.7771\n",
            "recall_macro: 0.7208\n",
            "f1_macro: 0.7444\n",
            "roc_auc_ovr: 0.9432\n"
          ]
        }
      ],
      "source": [
        "# LightGBM 하이퍼파라미터 튜닝 (SMOTE 적용 데이터 사용)\n",
        "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 필요한 변수 확인\n",
        "required_vars = ['X_train_resampled', 'y_train_resampled', 'X_test', 'y_test_encoded']\n",
        "missing = [v for v in required_vars if v not in globals()]\n",
        "if missing:\n",
        "    raise NameError(f\"필요한 변수가 세션에 없습니다: {missing}. 먼저 관련 셀들을 실행하세요.\")\n",
        "\n",
        "# 탐색 공간 정의\n",
        "space_lgbm = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 100, 1000, 50),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(1e-3), np.log(0.3)),\n",
        "    'num_leaves': hp.quniform('num_leaves', 16, 256, 8),\n",
        "    'max_depth': hp.quniform('max_depth', 3, 15, 1),\n",
        "    'min_child_samples': hp.quniform('min_child_samples', 5, 100, 1),\n",
        "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
        "    'reg_alpha': hp.loguniform('reg_alpha', np.log(1e-8), np.log(10)),\n",
        "    'reg_lambda': hp.loguniform('reg_lambda', np.log(1e-8), np.log(10))\n",
        "}\n",
        "\n",
        "# Objective 함수\n",
        "def objective_lgbm(params):\n",
        "    # quniform으로 나온 값들을 적절히 변환\n",
        "    params_converted = {\n",
        "        'n_estimators': int(params['n_estimators']),\n",
        "        'learning_rate': float(params['learning_rate']),\n",
        "        'num_leaves': int(params['num_leaves']),\n",
        "        'max_depth': int(params['max_depth']),\n",
        "        'min_child_samples': int(params['min_child_samples']),\n",
        "        'subsample': float(params['subsample']),\n",
        "        'colsample_bytree': float(params['colsample_bytree']),\n",
        "        'reg_alpha': float(params['reg_alpha']),\n",
        "        'reg_lambda': float(params['reg_lambda'])\n",
        "    }\n",
        "\n",
        "    # 안전한 고정 파라미터\n",
        "    lgbm_kwargs = {**params_converted, 'random_state': 42, 'n_jobs': -1}\n",
        "\n",
        "    try:\n",
        "        model = LGBMClassifier(**lgbm_kwargs)\n",
        "        cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "        scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=cv, scoring='f1_macro', n_jobs=-1)\n",
        "        f1_mean = np.mean(scores)\n",
        "        return {'loss': -f1_mean, 'status': STATUS_OK}\n",
        "    except Exception as e:\n",
        "        print('Objective error (LightGBM):', e)\n",
        "        return {'loss': 1.0, 'status': STATUS_OK}\n",
        "\n",
        "# 튜닝 실행\n",
        "trials = Trials()\n",
        "best_lgbm = fmin(fn=objective_lgbm, space=space_lgbm, algo=tpe.suggest, max_evals=30, trials=trials, rstate=np.random.default_rng(42))\n",
        "\n",
        "# 결과 매핑 및 변환\n",
        "best_params_lgbm = {\n",
        "    'n_estimators': int(best_lgbm['n_estimators']),\n",
        "    'learning_rate': float(best_lgbm['learning_rate']),\n",
        "    'num_leaves': int(best_lgbm['num_leaves']),\n",
        "    'max_depth': int(best_lgbm['max_depth']),\n",
        "    'min_child_samples': int(best_lgbm['min_child_samples']),\n",
        "    'subsample': float(best_lgbm['subsample']),\n",
        "    'colsample_bytree': float(best_lgbm['colsample_bytree']),\n",
        "    'reg_alpha': float(best_lgbm['reg_alpha']),\n",
        "    'reg_lambda': float(best_lgbm['reg_lambda'])\n",
        "}\n",
        "\n",
        "print('\\nBest raw hyperopt result (LightGBM):', best_lgbm)\n",
        "print('Mapped best params (LightGBM):', best_params_lgbm)\n",
        "\n",
        "# 최적 파라미터로 재학습 및 평가\n",
        "lgbm_final = LGBMClassifier(**best_params_lgbm, random_state=42, n_jobs=-1)\n",
        "lgbm_final.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "y_pred_lgbm = lgbm_final.predict(X_test)\n",
        "metrics_lgbm = {\n",
        "    'accuracy': accuracy_score(y_test_encoded, y_pred_lgbm),\n",
        "    'precision_macro': precision_score(y_test_encoded, y_pred_lgbm, average='macro', zero_division=0),\n",
        "    'recall_macro': recall_score(y_test_encoded, y_pred_lgbm, average='macro', zero_division=0),\n",
        "    'f1_macro': f1_score(y_test_encoded, y_pred_lgbm, average='macro', zero_division=0)\n",
        "}\n",
        "\n",
        "print('\\n--- Final LightGBM evaluation on test set ---')\n",
        "for k, v in metrics_lgbm.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# ROC AUC (멀티클래스)\n",
        "if hasattr(lgbm_final, 'predict_proba'):\n",
        "    try:\n",
        "        y_proba_lgbm = lgbm_final.predict_proba(X_test)\n",
        "        roc_lgbm = roc_auc_score(y_test_encoded, y_proba_lgbm, multi_class='ovr', average='macro')\n",
        "        print(f\"roc_auc_ovr: {roc_lgbm:.4f}\")\n",
        "    except Exception as e:\n",
        "        print('ROC AUC 계산 중 오류 (LightGBM):', e)\n",
        "else:\n",
        "    print('predict_proba를 지원하지 않아 ROC AUC를 계산하지 않습니다.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvZJtTARaRYf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIr2xvC5bOxg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY6terBTbOu_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3405a7c7"
      },
      "source": [
        "## 하이퍼 파라미터 튜닝: TensorFlow(SMOTE 적용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "319f3bd8",
        "outputId": "fd2403ae-8bb0-4001-f76f-d4a2023d9213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Hyperparameter Tuning for TensorFlow MLP (SMOTE) ---\n",
            "Epoch 1/50                                            \n",
            "\n",
            "Epoch 1/50                                            \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 387ms/step - accuracy: 0.1562 - loss: 1.6080\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22\u001b[0m 387ms/step - accuracy: 0.1562 - loss: 1.6080\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.3886 - loss: 1.5247   \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.3886 - loss: 1.5247   \n",
            "\u001b[1m 11/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.4578 - loss: 1.4514\n",
            "\u001b[1m 11/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.4578 - loss: 1.4514\n",
            "\u001b[1m 16/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5080 - loss: 1.3713\n",
            "\u001b[1m 16/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5080 - loss: 1.3713\n",
            "\u001b[1m 21/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5452 - loss: 1.3010\n",
            "\u001b[1m 21/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5452 - loss: 1.3010\n",
            "\u001b[1m 27/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5782 - loss: 1.2275\n",
            "\u001b[1m 27/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5782 - loss: 1.2275\n",
            "\u001b[1m 33/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6041 - loss: 1.1633\n",
            "\u001b[1m 33/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6041 - loss: 1.1633\n",
            "\u001b[1m 39/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6241 - loss: 1.1096\n",
            "\u001b[1m 39/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6241 - loss: 1.1096\n",
            "\u001b[1m 45/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6412 - loss: 1.0622\n",
            "\u001b[1m 45/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6412 - loss: 1.0622\n",
            "\u001b[1m 51/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6560 - loss: 1.0194\n",
            "\u001b[1m 51/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6560 - loss: 1.0194\n",
            "\u001b[1m 57/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6692 - loss: 0.9808\n",
            "\u001b[1m 57/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6692 - loss: 0.9808\n",
            "\u001b[1m 63/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6808 - loss: 0.9463\n",
            "\u001b[1m 63/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6808 - loss: 0.9463\n",
            "\u001b[1m 69/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6913 - loss: 0.9149\n",
            "\u001b[1m 69/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6913 - loss: 0.9149\n",
            "\u001b[1m 75/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7007 - loss: 0.8868 \n",
            "\u001b[1m 75/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7007 - loss: 0.8868 \n",
            "\u001b[1m 81/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7091 - loss: 0.8616\n",
            "\u001b[1m 81/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7091 - loss: 0.8616\n",
            "\u001b[1m 87/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7169 - loss: 0.8386\n",
            "\u001b[1m 87/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7169 - loss: 0.8386\n",
            "\u001b[1m 93/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7239 - loss: 0.8174\n",
            "\u001b[1m 93/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7239 - loss: 0.8174\n",
            "\u001b[1m 99/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7305 - loss: 0.7976\n",
            "\u001b[1m 99/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7305 - loss: 0.7976\n",
            "\u001b[1m104/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7356 - loss: 0.7821\n",
            "\u001b[1m104/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7356 - loss: 0.7821\n",
            "\u001b[1m110/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7413 - loss: 0.7647\n",
            "\u001b[1m110/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7413 - loss: 0.7647\n",
            "\u001b[1m116/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7468 - loss: 0.7484\n",
            "\u001b[1m116/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7468 - loss: 0.7484\n",
            "\u001b[1m122/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7519 - loss: 0.7331\n",
            "\u001b[1m122/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7519 - loss: 0.7331\n",
            "\u001b[1m128/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7567 - loss: 0.7186\n",
            "\u001b[1m128/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7567 - loss: 0.7186\n",
            "\u001b[1m134/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7613 - loss: 0.7049\n",
            "\u001b[1m134/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7613 - loss: 0.7049\n",
            "\u001b[1m140/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7657 - loss: 0.6920\n",
            "\u001b[1m140/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7657 - loss: 0.6920\n",
            "\u001b[1m146/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7698 - loss: 0.6798\n",
            "\u001b[1m146/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7698 - loss: 0.6798\n",
            "\u001b[1m152/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7738 - loss: 0.6682\n",
            "\u001b[1m152/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7738 - loss: 0.6682\n",
            "\u001b[1m158/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7774 - loss: 0.6573\n",
            "\u001b[1m158/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7774 - loss: 0.6573\n",
            "\u001b[1m164/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7809 - loss: 0.6470\n",
            "\u001b[1m164/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7809 - loss: 0.6470\n",
            "\u001b[1m170/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7843 - loss: 0.6371\n",
            "\u001b[1m170/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7843 - loss: 0.6371\n",
            "\u001b[1m176/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7874 - loss: 0.6277\n",
            "\u001b[1m176/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7874 - loss: 0.6277\n",
            "\u001b[1m181/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7900 - loss: 0.6201\n",
            "\u001b[1m181/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7900 - loss: 0.6201\n",
            "\u001b[1m187/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7929 - loss: 0.6115\n",
            "\u001b[1m187/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7929 - loss: 0.6115\n",
            "\u001b[1m193/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7956 - loss: 0.6032\n",
            "\u001b[1m193/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7956 - loss: 0.6032\n",
            "\u001b[1m199/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7983 - loss: 0.5952\n",
            "\u001b[1m199/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7983 - loss: 0.5952\n",
            "\u001b[1m205/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8009 - loss: 0.5875\n",
            "\u001b[1m205/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8009 - loss: 0.5875\n",
            "\u001b[1m211/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8033 - loss: 0.5800\n",
            "\u001b[1m211/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8033 - loss: 0.5800\n",
            "\u001b[1m217/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8057 - loss: 0.5729\n",
            "\u001b[1m217/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8057 - loss: 0.5729\n",
            "\u001b[1m223/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8080 - loss: 0.5659\n",
            "\u001b[1m223/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8080 - loss: 0.5659\n",
            "\u001b[1m229/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8103 - loss: 0.5592\n",
            "\u001b[1m229/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8103 - loss: 0.5592\n",
            "\u001b[1m235/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8124 - loss: 0.5528\n",
            "\u001b[1m235/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8124 - loss: 0.5528\n",
            "\u001b[1m241/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8145 - loss: 0.5466\n",
            "\u001b[1m241/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8145 - loss: 0.5466\n",
            "\u001b[1m247/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8165 - loss: 0.5405\n",
            "\u001b[1m247/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8165 - loss: 0.5405\n",
            "\u001b[1m252/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8182 - loss: 0.5356\n",
            "\u001b[1m252/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8182 - loss: 0.5356\n",
            "\u001b[1m258/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8201 - loss: 0.5299\n",
            "\u001b[1m258/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8201 - loss: 0.5299\n",
            "\u001b[1m264/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8219 - loss: 0.5244\n",
            "\u001b[1m264/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8219 - loss: 0.5244\n",
            "\u001b[1m270/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8237 - loss: 0.5191\n",
            "\u001b[1m270/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8237 - loss: 0.5191\n",
            "\u001b[1m276/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8255 - loss: 0.5139\n",
            "\u001b[1m276/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8255 - loss: 0.5139\n",
            "\u001b[1m282/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8272 - loss: 0.5089\n",
            "\u001b[1m282/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8272 - loss: 0.5089\n",
            "\u001b[1m288/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8288 - loss: 0.5040\n",
            "\u001b[1m288/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8288 - loss: 0.5040\n",
            "\u001b[1m294/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8304 - loss: 0.4992\n",
            "\u001b[1m294/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8304 - loss: 0.4992\n",
            "\u001b[1m300/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8320 - loss: 0.4946\n",
            "\u001b[1m300/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8320 - loss: 0.4946\n",
            "\u001b[1m306/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8335 - loss: 0.4901\n",
            "\u001b[1m306/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8335 - loss: 0.4901\n",
            "\u001b[1m312/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8350 - loss: 0.4857\n",
            "\u001b[1m312/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8350 - loss: 0.4857\n",
            "\u001b[1m318/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8364 - loss: 0.4815\n",
            "\u001b[1m318/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8364 - loss: 0.4815\n",
            "\u001b[1m323/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8375 - loss: 0.4780\n",
            "\u001b[1m323/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8375 - loss: 0.4780\n",
            "\u001b[1m328/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8387 - loss: 0.4746\n",
            "\u001b[1m328/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8387 - loss: 0.4746\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8400 - loss: 0.4706\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8400 - loss: 0.4706\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8413 - loss: 0.4667\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8413 - loss: 0.4667\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8426 - loss: 0.4630\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8426 - loss: 0.4630\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8438 - loss: 0.4593\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8438 - loss: 0.4593\n",
            "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8448 - loss: 0.4563\n",
            "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8448 - loss: 0.4563\n",
            "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8460 - loss: 0.4527\n",
            "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8460 - loss: 0.4527\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9173 - loss: 0.2391\n",
            "\n",
            "Epoch 2/50                                            \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9173 - loss: 0.2391\n",
            "\n",
            "Epoch 2/50                                            \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0168\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0168\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0255  \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9906 - loss: 0.0255  \n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9904 - loss: 0.0271\n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9904 - loss: 0.0271\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.0262\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9910 - loss: 0.0262\n",
            "\u001b[1m 25/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9915 - loss: 0.0253\n",
            "\u001b[1m 25/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9915 - loss: 0.0253\n",
            "\u001b[1m 31/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9917 - loss: 0.0248\n",
            "\u001b[1m 31/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9917 - loss: 0.0248\n",
            "\u001b[1m 37/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0244\n",
            "\u001b[1m 37/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9921 - loss: 0.0244\n",
            "\u001b[1m 43/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0239\n",
            "\u001b[1m 43/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0239\n",
            "\u001b[1m 49/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0238\n",
            "\u001b[1m 49/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0238\n",
            "\u001b[1m 55/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0236\n",
            "\u001b[1m 55/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0236\n",
            "\u001b[1m 61/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0237\n",
            "\u001b[1m 61/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0237\n",
            "\u001b[1m 67/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0237\n",
            "\u001b[1m 67/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9927 - loss: 0.0237\n",
            "\u001b[1m 73/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.0236\n",
            "\u001b[1m 73/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.0236\n",
            "\u001b[1m 80/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.0235\n",
            "\u001b[1m 80/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9928 - loss: 0.0235\n",
            "\u001b[1m 86/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.0233\n",
            "\u001b[1m 86/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.0233\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0230\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9930 - loss: 0.0230\n",
            "\u001b[1m 98/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0228\n",
            "\u001b[1m 98/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0228\n",
            "\u001b[1m104/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0226\n",
            "\u001b[1m104/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0226\n",
            "\u001b[1m111/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0225\n",
            "\u001b[1m111/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0225\n",
            "\u001b[1m117/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0223\n",
            "\u001b[1m117/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9932 - loss: 0.0223\n",
            "\u001b[1m123/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0221\n",
            "\u001b[1m123/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0221\n",
            "\u001b[1m129/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0220\n",
            "\u001b[1m129/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0220\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0219\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0219\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0218\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0218\n",
            "\u001b[1m147/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0216\n",
            "\u001b[1m147/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0216\n",
            "\u001b[1m153/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0215\n",
            "\u001b[1m153/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0215\n",
            "\u001b[1m160/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0213\n",
            "\u001b[1m160/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0213\n",
            "\u001b[1m165/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0212\n",
            "\u001b[1m165/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0212\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0211\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0211\n",
            "\u001b[1m177/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0210\n",
            "\u001b[1m177/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0210\n",
            "\u001b[1m183/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0209\n",
            "\u001b[1m183/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9937 - loss: 0.0209\n",
            "\u001b[1m189/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0207\n",
            "\u001b[1m189/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0207\n",
            "\u001b[1m195/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0206\n",
            "\u001b[1m195/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0206\n",
            "\u001b[1m201/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0205\n",
            "\u001b[1m201/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9938 - loss: 0.0205\n",
            "\u001b[1m207/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0203\n",
            "\u001b[1m207/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0203\n",
            "\u001b[1m213/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0202\n",
            "\u001b[1m213/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0202\n",
            "\u001b[1m219/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0201\n",
            "\u001b[1m219/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0201\n",
            "\u001b[1m224/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0200\n",
            "\u001b[1m224/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9939 - loss: 0.0200\n",
            "\u001b[1m230/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0199\n",
            "\u001b[1m230/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0199\n",
            "\u001b[1m236/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0198\n",
            "\u001b[1m236/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0198\n",
            "\u001b[1m242/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0197\n",
            "\u001b[1m242/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9940 - loss: 0.0197\n",
            "\u001b[1m248/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0196\n",
            "\u001b[1m248/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0196\n",
            "\u001b[1m254/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0195\n",
            "\u001b[1m254/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0195\n",
            "\u001b[1m260/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0194\n",
            "\u001b[1m260/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0194\n",
            "\u001b[1m266/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0194\n",
            "\u001b[1m266/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0194\n",
            "\u001b[1m272/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0193\n",
            "\u001b[1m272/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0193\n",
            "\u001b[1m278/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0192\n",
            "\u001b[1m278/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0192\n",
            "\u001b[1m284/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0191\n",
            "\u001b[1m284/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0191\n",
            "\u001b[1m290/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0190\n",
            "\u001b[1m290/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0190\n",
            "\u001b[1m296/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0189\n",
            "\u001b[1m296/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0189\n",
            "\u001b[1m302/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0189\n",
            "\u001b[1m302/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0189\n",
            "\u001b[1m308/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0188\n",
            "\u001b[1m308/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0188\n",
            "\u001b[1m314/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0187\n",
            "\u001b[1m314/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0187\n",
            "\u001b[1m320/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0186\n",
            "\u001b[1m320/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0186\n",
            "\u001b[1m325/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0186\n",
            "\u001b[1m325/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0186\n",
            "\u001b[1m331/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0185\n",
            "\u001b[1m331/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0185\n",
            "\u001b[1m337/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0185\n",
            "\u001b[1m337/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9943 - loss: 0.0185\n",
            "\u001b[1m343/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0184\n",
            "\u001b[1m343/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0184\n",
            "\u001b[1m349/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0184\n",
            "\u001b[1m349/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0184\n",
            "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0183\n",
            "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0183\n",
            "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0183\n",
            "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9944 - loss: 0.0183\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0149\n",
            "\n",
            "Epoch 3/50                                            \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9952 - loss: 0.0149\n",
            "\n",
            "Epoch 3/50                                            \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.6847e-04\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 5.6847e-04\n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 9.1526e-04\n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 9.1526e-04\n",
            "\u001b[1m 11/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.6661e-04\n",
            "\u001b[1m 11/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.6661e-04\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.2611e-04 \n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.2611e-04 \n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.8289e-04\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 8.8289e-04\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.3561e-04\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.3561e-04\n",
            "\u001b[1m 37/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.8341e-04\n",
            "\u001b[1m 37/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 9.8341e-04\n",
            "\u001b[1m 44/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0010    \n",
            "\u001b[1m 44/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0010    \n",
            "\u001b[1m 50/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0011\n",
            "\u001b[1m 50/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0011\n",
            "\u001b[1m 56/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0011\n",
            "\u001b[1m 56/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 0.0011\n",
            "\u001b[1m 62/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0013\n",
            "\u001b[1m 62/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0013\n",
            "\u001b[1m 68/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0014\n",
            "\u001b[1m 68/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0014\n",
            "\u001b[1m 74/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0015\n",
            "\u001b[1m 74/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0015\n",
            "\u001b[1m 80/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0015\n",
            "\u001b[1m 80/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0015\n",
            "\u001b[1m 86/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0016\n",
            "\u001b[1m 86/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0016\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0016\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0016\n",
            "\u001b[1m 98/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0016\n",
            "\u001b[1m 98/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0016\n",
            "\u001b[1m103/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0016\n",
            "\u001b[1m103/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0016\n",
            "\u001b[1m108/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m108/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m114/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m114/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m120/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m120/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m126/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "\u001b[1m126/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "\u001b[1m132/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "\u001b[1m132/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "\u001b[1m138/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "\u001b[1m138/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "\u001b[1m144/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "\u001b[1m144/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "\u001b[1m150/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "\u001b[1m150/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0017\n",
            "\u001b[1m157/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m157/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m163/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m163/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m169/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m169/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m175/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m175/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m182/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m182/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0017\n",
            "\u001b[1m188/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0018\n",
            "\u001b[1m188/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0018\n",
            "\u001b[1m194/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m194/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m200/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m200/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m213/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m213/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m219/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m219/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m225/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m225/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m230/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m230/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m236/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m236/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m242/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m242/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m248/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m248/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m254/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m254/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m260/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m260/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m267/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m267/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m273/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m273/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m279/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m279/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m285/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m285/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m291/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m291/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m297/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m297/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m303/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m303/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m309/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m309/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m315/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m315/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m321/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m321/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m327/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m327/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m333/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m333/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0018\n",
            "\u001b[1m339/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "\u001b[1m339/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "\u001b[1m345/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "\u001b[1m345/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9995 - loss: 0.0019\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0019\n",
            "\n",
            "Epoch 4/50                                            \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9994 - loss: 0.0019\n",
            "\n",
            "Epoch 4/50                                            \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9688 - loss: 0.0231\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9688 - loss: 0.0231\n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0096\n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9872 - loss: 0.0096\n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0062\n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0062\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9939 - loss: 0.0047\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9939 - loss: 0.0047\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0038 \n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0038 \n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0033\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0033\n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0029\n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0029\n",
            "\u001b[1m 42/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.0026\n",
            "\u001b[1m 42/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.0026\n",
            "\u001b[1m 48/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0027\n",
            "\u001b[1m 48/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9971 - loss: 0.0027\n",
            "\u001b[1m 54/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0031\n",
            "\u001b[1m 54/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0031\n",
            "\u001b[1m 60/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0034\n",
            "\u001b[1m 60/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9974 - loss: 0.0034\n",
            "\u001b[1m 66/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0037\n",
            "\u001b[1m 66/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0037\n",
            "\u001b[1m 73/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0038\n",
            "\u001b[1m 73/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9977 - loss: 0.0038\n",
            "\u001b[1m 79/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0039\n",
            "\u001b[1m 79/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0039\n",
            "\u001b[1m 85/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0040\n",
            "\u001b[1m 85/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9979 - loss: 0.0040\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0040\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0040\n",
            "\u001b[1m 98/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0040\n",
            "\u001b[1m 98/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0040\n",
            "\u001b[1m104/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0040\n",
            "\u001b[1m104/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9982 - loss: 0.0040\n",
            "\u001b[1m110/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0040\n",
            "\u001b[1m110/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0040\n",
            "\u001b[1m117/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0039\n",
            "\u001b[1m117/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0039\n",
            "\u001b[1m123/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0039\n",
            "\u001b[1m123/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0039\n",
            "\u001b[1m129/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0039\n",
            "\u001b[1m129/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0039\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0038\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0038\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0038\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0038\n",
            "\u001b[1m147/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0037\n",
            "\u001b[1m147/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0037\n",
            "\u001b[1m153/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0037\n",
            "\u001b[1m153/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0037\n",
            "\u001b[1m159/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0037\n",
            "\u001b[1m159/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9986 - loss: 0.0037\n",
            "\u001b[1m165/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0036\n",
            "\u001b[1m165/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0036\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0036\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0036\n",
            "\u001b[1m177/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0035\n",
            "\u001b[1m177/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9987 - loss: 0.0035\n",
            "\u001b[1m183/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0035\n",
            "\u001b[1m183/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0035\n",
            "\u001b[1m189/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0035\n",
            "\u001b[1m189/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0035\n",
            "\u001b[1m195/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0034\n",
            "\u001b[1m195/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9988 - loss: 0.0034\n",
            "\u001b[1m201/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0034\n",
            "\u001b[1m201/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0034\n",
            "\u001b[1m207/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0034\n",
            "\u001b[1m207/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0034\n",
            "\u001b[1m213/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0033\n",
            "\u001b[1m213/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0033\n",
            "\u001b[1m219/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0033\n",
            "\u001b[1m219/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0033\n",
            "\u001b[1m225/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0032\n",
            "\u001b[1m225/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0032\n",
            "\u001b[1m231/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0032\n",
            "\u001b[1m231/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0032\n",
            "\u001b[1m237/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0032\n",
            "\u001b[1m237/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0032\n",
            "\u001b[1m243/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0031\n",
            "\u001b[1m243/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0031\n",
            "\u001b[1m249/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0031\n",
            "\u001b[1m249/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0031\n",
            "\u001b[1m255/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0031\n",
            "\u001b[1m255/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0031\n",
            "\u001b[1m261/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0031\n",
            "\u001b[1m261/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0031\n",
            "\u001b[1m267/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0031\n",
            "\u001b[1m267/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0031\n",
            "\u001b[1m273/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m273/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m279/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m279/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m285/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m285/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m290/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m290/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m296/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m296/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m302/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m302/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m308/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m308/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0030\n",
            "\u001b[1m315/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m315/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m321/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m321/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m327/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m327/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m333/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m333/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9992 - loss: 0.0029\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0023\n",
            "\n",
            "Epoch 5/50                                            \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0023\n",
            "\n",
            "Epoch 5/50                                            \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.6259e-05\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.6259e-05\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3769e-04 \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3769e-04 \n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4487e-04\n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4487e-04\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4938e-04\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4938e-04\n",
            "\u001b[1m 26/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4887e-04\n",
            "\u001b[1m 26/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4887e-04\n",
            "\u001b[1m 32/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4861e-04\n",
            "\u001b[1m 32/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4861e-04\n",
            "\u001b[1m 38/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 3.0945e-04\n",
            "\u001b[1m 38/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9999 - loss: 3.0945e-04\n",
            "\u001b[1m 44/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 4.3189e-04\n",
            "\u001b[1m 44/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 4.3189e-04\n",
            "\u001b[1m 50/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.0879e-04\n",
            "\u001b[1m 50/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.0879e-04\n",
            "\u001b[1m 56/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.5788e-04\n",
            "\u001b[1m 56/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.5788e-04\n",
            "\u001b[1m 62/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.8918e-04\n",
            "\u001b[1m 62/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.8918e-04\n",
            "\u001b[1m 68/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0926e-04\n",
            "\u001b[1m 68/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0926e-04\n",
            "\u001b[1m 74/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.2200e-04\n",
            "\u001b[1m 74/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.2200e-04\n",
            "\u001b[1m 80/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.2987e-04\n",
            "\u001b[1m 80/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.2987e-04\n",
            "\u001b[1m 84/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3303e-04\n",
            "\u001b[1m 84/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3303e-04\n",
            "\u001b[1m 90/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3763e-04\n",
            "\u001b[1m 90/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3763e-04\n",
            "\u001b[1m 96/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.4010e-04\n",
            "\u001b[1m 96/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.4010e-04\n",
            "\u001b[1m102/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.4037e-04\n",
            "\u001b[1m102/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.4037e-04\n",
            "\u001b[1m108/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3919e-04\n",
            "\u001b[1m108/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3919e-04\n",
            "\u001b[1m114/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3691e-04\n",
            "\u001b[1m114/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3691e-04\n",
            "\u001b[1m120/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3374e-04\n",
            "\u001b[1m120/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3374e-04\n",
            "\u001b[1m126/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3079e-04\n",
            "\u001b[1m126/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.3079e-04\n",
            "\u001b[1m132/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.2740e-04\n",
            "\u001b[1m132/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.2740e-04\n",
            "\u001b[1m138/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.2394e-04\n",
            "\u001b[1m138/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.2394e-04\n",
            "\u001b[1m144/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.2054e-04\n",
            "\u001b[1m144/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.2054e-04\n",
            "\u001b[1m150/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.1762e-04\n",
            "\u001b[1m150/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.1762e-04\n",
            "\u001b[1m156/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.1522e-04\n",
            "\u001b[1m156/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.1522e-04\n",
            "\u001b[1m162/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.1250e-04\n",
            "\u001b[1m162/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.1250e-04\n",
            "\u001b[1m168/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0952e-04\n",
            "\u001b[1m168/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0952e-04\n",
            "\u001b[1m174/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0633e-04\n",
            "\u001b[1m174/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0633e-04\n",
            "\u001b[1m180/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0340e-04\n",
            "\u001b[1m180/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0340e-04\n",
            "\u001b[1m186/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0048e-04\n",
            "\u001b[1m186/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0048e-04\n",
            "\u001b[1m191/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.9793e-04\n",
            "\u001b[1m191/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.9793e-04\n",
            "\u001b[1m196/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.9528e-04\n",
            "\u001b[1m196/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.9528e-04\n",
            "\u001b[1m202/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.9201e-04\n",
            "\u001b[1m202/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.9201e-04\n",
            "\u001b[1m208/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.8861e-04\n",
            "\u001b[1m208/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.8861e-04\n",
            "\u001b[1m214/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.8518e-04\n",
            "\u001b[1m214/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.8518e-04\n",
            "\u001b[1m220/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.8179e-04\n",
            "\u001b[1m220/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.8179e-04\n",
            "\u001b[1m226/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7833e-04\n",
            "\u001b[1m226/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7833e-04\n",
            "\u001b[1m232/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7483e-04\n",
            "\u001b[1m232/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7483e-04\n",
            "\u001b[1m238/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7130e-04\n",
            "\u001b[1m238/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7130e-04\n",
            "\u001b[1m244/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6862e-04\n",
            "\u001b[1m244/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6862e-04\n",
            "\u001b[1m250/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6753e-04\n",
            "\u001b[1m250/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6753e-04\n",
            "\u001b[1m256/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6630e-04\n",
            "\u001b[1m256/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6630e-04\n",
            "\u001b[1m262/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6492e-04\n",
            "\u001b[1m262/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6492e-04\n",
            "\u001b[1m268/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6340e-04\n",
            "\u001b[1m268/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6340e-04\n",
            "\u001b[1m274/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6178e-04\n",
            "\u001b[1m274/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6178e-04\n",
            "\u001b[1m280/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6007e-04\n",
            "\u001b[1m280/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6007e-04\n",
            "\u001b[1m286/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.5952e-04\n",
            "\u001b[1m286/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.5952e-04\n",
            "\u001b[1m292/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6062e-04\n",
            "\u001b[1m292/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6062e-04\n",
            "\u001b[1m296/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6322e-04\n",
            "\u001b[1m296/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6322e-04\n",
            "\u001b[1m301/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6622e-04\n",
            "\u001b[1m301/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6622e-04\n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6844e-04\n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.6844e-04\n",
            "\u001b[1m310/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7103e-04\n",
            "\u001b[1m310/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7103e-04\n",
            "\u001b[1m315/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7344e-04\n",
            "\u001b[1m315/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7344e-04\n",
            "\u001b[1m320/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7565e-04\n",
            "\u001b[1m320/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7565e-04\n",
            "\u001b[1m324/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7729e-04\n",
            "\u001b[1m324/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7729e-04\n",
            "\u001b[1m329/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7918e-04\n",
            "\u001b[1m329/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.7918e-04\n",
            "\u001b[1m335/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.8640e-04\n",
            "\u001b[1m335/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.8640e-04\n",
            "\u001b[1m341/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.9826e-04\n",
            "\u001b[1m341/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 5.9826e-04\n",
            "\u001b[1m347/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0940e-04\n",
            "\u001b[1m347/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 6.0940e-04\n",
            "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 6.1643e-04\n",
            "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 6.1643e-04\n",
            "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 6.2152e-04\n",
            "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 6.2152e-04\n",
            "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 6.2964e-04\n",
            "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 6.2964e-04\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 6.3884e-04\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 6.3884e-04\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0012    \n",
            "\n",
            "Epoch 6/50                                            \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9997 - loss: 0.0012    \n",
            "\n",
            "Epoch 6/50                                            \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2480e-04\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 1.2480e-04\n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.3577e-04 \n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.3577e-04 \n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1991e-04\n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1991e-04\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1396e-04\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1396e-04\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1524e-04\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1524e-04\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1748e-04 \n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1748e-04 \n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1893e-04\n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1893e-04\n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1990e-04\n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1990e-04\n",
            "\u001b[1m 45/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2041e-04\n",
            "\u001b[1m 45/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2041e-04\n",
            "\u001b[1m 51/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2061e-04\n",
            "\u001b[1m 51/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2061e-04\n",
            "\u001b[1m 57/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2032e-04\n",
            "\u001b[1m 57/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2032e-04\n",
            "\u001b[1m 63/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1992e-04\n",
            "\u001b[1m 63/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1992e-04\n",
            "\u001b[1m 69/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1982e-04\n",
            "\u001b[1m 69/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1982e-04\n",
            "\u001b[1m 75/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1973e-04 \n",
            "\u001b[1m 75/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1973e-04 \n",
            "\u001b[1m 81/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1977e-04\n",
            "\u001b[1m 81/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1977e-04\n",
            "\u001b[1m 87/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1980e-04\n",
            "\u001b[1m 87/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1980e-04\n",
            "\u001b[1m 93/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1980e-04\n",
            "\u001b[1m 93/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1980e-04\n",
            "\u001b[1m 99/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1998e-04\n",
            "\u001b[1m 99/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1998e-04\n",
            "\u001b[1m105/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2013e-04\n",
            "\u001b[1m105/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2013e-04\n",
            "\u001b[1m111/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2020e-04\n",
            "\u001b[1m111/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2020e-04\n",
            "\u001b[1m117/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2029e-04\n",
            "\u001b[1m117/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2029e-04\n",
            "\u001b[1m122/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2041e-04\n",
            "\u001b[1m122/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2041e-04\n",
            "\u001b[1m127/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2046e-04\n",
            "\u001b[1m127/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2046e-04\n",
            "\u001b[1m132/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2053e-04\n",
            "\u001b[1m132/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2053e-04\n",
            "\u001b[1m138/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2058e-04\n",
            "\u001b[1m138/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2058e-04\n",
            "\u001b[1m143/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2060e-04\n",
            "\u001b[1m143/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2060e-04\n",
            "\u001b[1m148/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2061e-04\n",
            "\u001b[1m148/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2061e-04\n",
            "\u001b[1m154/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2058e-04\n",
            "\u001b[1m154/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2058e-04\n",
            "\u001b[1m160/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2049e-04\n",
            "\u001b[1m160/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2049e-04\n",
            "\u001b[1m166/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2032e-04\n",
            "\u001b[1m166/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2032e-04\n",
            "\u001b[1m172/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2017e-04\n",
            "\u001b[1m172/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2017e-04\n",
            "\u001b[1m178/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2001e-04\n",
            "\u001b[1m178/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.2001e-04\n",
            "\u001b[1m184/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1981e-04\n",
            "\u001b[1m184/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1981e-04\n",
            "\u001b[1m190/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1961e-04\n",
            "\u001b[1m190/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1961e-04\n",
            "\u001b[1m196/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1949e-04\n",
            "\u001b[1m196/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1949e-04\n",
            "\u001b[1m202/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1944e-04\n",
            "\u001b[1m202/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1944e-04\n",
            "\u001b[1m208/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1940e-04\n",
            "\u001b[1m208/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1940e-04\n",
            "\u001b[1m212/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1935e-04\n",
            "\u001b[1m212/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1935e-04\n",
            "\u001b[1m217/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1931e-04\n",
            "\u001b[1m217/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1931e-04\n",
            "\u001b[1m223/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1924e-04\n",
            "\u001b[1m223/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1924e-04\n",
            "\u001b[1m229/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1917e-04\n",
            "\u001b[1m229/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1917e-04\n",
            "\u001b[1m235/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1911e-04\n",
            "\u001b[1m235/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1911e-04\n",
            "\u001b[1m240/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1908e-04\n",
            "\u001b[1m240/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1908e-04\n",
            "\u001b[1m245/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1905e-04\n",
            "\u001b[1m245/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1905e-04\n",
            "\u001b[1m251/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1900e-04\n",
            "\u001b[1m251/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1900e-04\n",
            "\u001b[1m257/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1893e-04\n",
            "\u001b[1m257/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1893e-04\n",
            "\u001b[1m263/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1886e-04\n",
            "\u001b[1m263/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1886e-04\n",
            "\u001b[1m269/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1877e-04\n",
            "\u001b[1m269/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1877e-04\n",
            "\u001b[1m275/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1866e-04\n",
            "\u001b[1m275/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1866e-04\n",
            "\u001b[1m281/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1854e-04\n",
            "\u001b[1m281/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1854e-04\n",
            "\u001b[1m287/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1843e-04\n",
            "\u001b[1m287/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1843e-04\n",
            "\u001b[1m293/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1836e-04\n",
            "\u001b[1m293/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1836e-04\n",
            "\u001b[1m299/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1841e-04 \n",
            "\u001b[1m299/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1841e-04 \n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1846e-04\n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1846e-04\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1849e-04\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1849e-04\n",
            "\u001b[1m315/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1851e-04\n",
            "\u001b[1m315/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1851e-04\n",
            "\u001b[1m321/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1856e-04\n",
            "\u001b[1m321/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1856e-04\n",
            "\u001b[1m327/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1869e-04\n",
            "\u001b[1m327/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1869e-04\n",
            "\u001b[1m333/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1880e-04 \n",
            "\u001b[1m333/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1880e-04 \n",
            "\u001b[1m339/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1889e-04\n",
            "\u001b[1m339/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1889e-04\n",
            "\u001b[1m345/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1896e-04\n",
            "\u001b[1m345/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1896e-04\n",
            "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1902e-04\n",
            "\u001b[1m351/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1902e-04\n",
            "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1908e-04\n",
            "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1908e-04\n",
            "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1914e-04\n",
            "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1914e-04\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2140e-04\n",
            "\n",
            "Epoch 7/50                                            \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2140e-04\n",
            "\n",
            "Epoch 7/50                                            \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.3995e-05\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.3995e-05\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.4832e-05 \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.4832e-05 \n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.6175e-05\n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.6175e-05\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.7688e-05\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.7688e-05\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.8575e-05 \n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.8575e-05 \n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.9058e-05\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.9058e-05\n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.9964e-05\n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.9964e-05\n",
            "\u001b[1m 42/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.0621e-05\n",
            "\u001b[1m 42/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.0621e-05\n",
            "\u001b[1m 48/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1011e-05\n",
            "\u001b[1m 48/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1011e-05\n",
            "\u001b[1m 54/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1327e-05\n",
            "\u001b[1m 54/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1327e-05\n",
            "\u001b[1m 60/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1480e-05\n",
            "\u001b[1m 60/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1480e-05\n",
            "\u001b[1m 66/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1742e-05\n",
            "\u001b[1m 66/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1742e-05\n",
            "\u001b[1m 72/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2105e-05\n",
            "\u001b[1m 72/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2105e-05\n",
            "\u001b[1m 78/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2485e-05\n",
            "\u001b[1m 78/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2485e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2750e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.2750e-05\n",
            "\u001b[1m 89/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3039e-05\n",
            "\u001b[1m 89/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3039e-05\n",
            "\u001b[1m 95/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3236e-05\n",
            "\u001b[1m 95/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3236e-05\n",
            "\u001b[1m101/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3379e-05\n",
            "\u001b[1m101/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3379e-05\n",
            "\u001b[1m107/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3609e-05\n",
            "\u001b[1m107/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3609e-05\n",
            "\u001b[1m113/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3818e-05\n",
            "\u001b[1m113/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3818e-05\n",
            "\u001b[1m119/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3987e-05\n",
            "\u001b[1m119/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.3987e-05\n",
            "\u001b[1m125/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4119e-05\n",
            "\u001b[1m125/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4119e-05\n",
            "\u001b[1m131/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4239e-05\n",
            "\u001b[1m131/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4239e-05\n",
            "\u001b[1m137/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4308e-05\n",
            "\u001b[1m137/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4308e-05\n",
            "\u001b[1m143/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4376e-05\n",
            "\u001b[1m143/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4376e-05\n",
            "\u001b[1m149/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4422e-05\n",
            "\u001b[1m149/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4422e-05\n",
            "\u001b[1m155/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4448e-05\n",
            "\u001b[1m155/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4448e-05\n",
            "\u001b[1m161/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4486e-05\n",
            "\u001b[1m161/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4486e-05\n",
            "\u001b[1m167/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4532e-05\n",
            "\u001b[1m167/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4532e-05\n",
            "\u001b[1m173/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4601e-05\n",
            "\u001b[1m173/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4601e-05\n",
            "\u001b[1m179/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4670e-05\n",
            "\u001b[1m179/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4670e-05\n",
            "\u001b[1m185/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4723e-05\n",
            "\u001b[1m185/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4723e-05\n",
            "\u001b[1m191/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4768e-05\n",
            "\u001b[1m191/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4768e-05\n",
            "\u001b[1m197/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4806e-05\n",
            "\u001b[1m197/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4806e-05\n",
            "\u001b[1m203/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4836e-05\n",
            "\u001b[1m203/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4836e-05\n",
            "\u001b[1m209/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4857e-05\n",
            "\u001b[1m209/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4857e-05\n",
            "\u001b[1m215/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4877e-05\n",
            "\u001b[1m215/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4877e-05\n",
            "\u001b[1m220/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4904e-05\n",
            "\u001b[1m220/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4904e-05\n",
            "\u001b[1m226/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4926e-05\n",
            "\u001b[1m226/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4926e-05\n",
            "\u001b[1m232/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4942e-05\n",
            "\u001b[1m232/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4942e-05\n",
            "\u001b[1m238/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4951e-05\n",
            "\u001b[1m238/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4951e-05\n",
            "\u001b[1m244/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4959e-05\n",
            "\u001b[1m244/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4959e-05\n",
            "\u001b[1m250/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4968e-05\n",
            "\u001b[1m250/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4968e-05\n",
            "\u001b[1m256/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4961e-05\n",
            "\u001b[1m256/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4961e-05\n",
            "\u001b[1m262/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4950e-05\n",
            "\u001b[1m262/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4950e-05\n",
            "\u001b[1m268/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4929e-05\n",
            "\u001b[1m268/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4929e-05\n",
            "\u001b[1m274/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4910e-05\n",
            "\u001b[1m274/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4910e-05\n",
            "\u001b[1m280/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4904e-05\n",
            "\u001b[1m280/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4904e-05\n",
            "\u001b[1m285/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4897e-05\n",
            "\u001b[1m285/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4897e-05\n",
            "\u001b[1m291/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4889e-05\n",
            "\u001b[1m291/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4889e-05\n",
            "\u001b[1m297/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4871e-05\n",
            "\u001b[1m297/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4871e-05\n",
            "\u001b[1m303/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4849e-05\n",
            "\u001b[1m303/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4849e-05\n",
            "\u001b[1m309/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4823e-05\n",
            "\u001b[1m309/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4823e-05\n",
            "\u001b[1m315/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4793e-05\n",
            "\u001b[1m315/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4793e-05\n",
            "\u001b[1m321/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4757e-05\n",
            "\u001b[1m321/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4757e-05\n",
            "\u001b[1m327/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4723e-05\n",
            "\u001b[1m327/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4723e-05\n",
            "\u001b[1m332/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4694e-05\n",
            "\u001b[1m332/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4694e-05\n",
            "\u001b[1m338/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4655e-05\n",
            "\u001b[1m338/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4655e-05\n",
            "\u001b[1m344/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4613e-05\n",
            "\u001b[1m344/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4613e-05\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4571e-05\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4571e-05\n",
            "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4543e-05\n",
            "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4543e-05\n",
            "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4503e-05\n",
            "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4503e-05\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4453e-05\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.4453e-05\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1237e-05\n",
            "\n",
            "Epoch 8/50                                            \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 6.1237e-05\n",
            "\n",
            "Epoch 8/50                                            \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.2033e-05\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 3.2033e-05\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1799e-05  \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1799e-05  \n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6104e-05\n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6104e-05\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6798e-05\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6798e-05\n",
            "\u001b[1m 25/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7315e-05\n",
            "\u001b[1m 25/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7315e-05\n",
            "\u001b[1m 31/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7586e-05\n",
            "\u001b[1m 31/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7586e-05\n",
            "\u001b[1m 37/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7521e-05\n",
            "\u001b[1m 37/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7521e-05\n",
            "\u001b[1m 43/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7336e-05\n",
            "\u001b[1m 43/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7336e-05\n",
            "\u001b[1m 49/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7193e-05\n",
            "\u001b[1m 49/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7193e-05\n",
            "\u001b[1m 55/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6995e-05\n",
            "\u001b[1m 55/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6995e-05\n",
            "\u001b[1m 61/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6786e-05\n",
            "\u001b[1m 61/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6786e-05\n",
            "\u001b[1m 67/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6595e-05\n",
            "\u001b[1m 67/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6595e-05\n",
            "\u001b[1m 73/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6384e-05\n",
            "\u001b[1m 73/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6384e-05\n",
            "\u001b[1m 79/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6163e-05\n",
            "\u001b[1m 79/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6163e-05\n",
            "\u001b[1m 85/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5976e-05\n",
            "\u001b[1m 85/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5976e-05\n",
            "\u001b[1m 91/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5813e-05\n",
            "\u001b[1m 91/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5813e-05\n",
            "\u001b[1m 97/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5654e-05\n",
            "\u001b[1m 97/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5654e-05\n",
            "\u001b[1m102/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5554e-05\n",
            "\u001b[1m102/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5554e-05\n",
            "\u001b[1m108/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5489e-05\n",
            "\u001b[1m108/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5489e-05\n",
            "\u001b[1m112/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5485e-05\n",
            "\u001b[1m112/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5485e-05\n",
            "\u001b[1m117/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5480e-05\n",
            "\u001b[1m117/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5480e-05\n",
            "\u001b[1m123/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5517e-05\n",
            "\u001b[1m123/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5517e-05\n",
            "\u001b[1m127/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5538e-05\n",
            "\u001b[1m127/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5538e-05\n",
            "\u001b[1m133/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5543e-05\n",
            "\u001b[1m133/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5543e-05\n",
            "\u001b[1m139/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5520e-05\n",
            "\u001b[1m139/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5520e-05\n",
            "\u001b[1m145/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5472e-05\n",
            "\u001b[1m145/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5472e-05\n",
            "\u001b[1m151/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5418e-05\n",
            "\u001b[1m151/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5418e-05\n",
            "\u001b[1m157/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5368e-05\n",
            "\u001b[1m157/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5368e-05\n",
            "\u001b[1m163/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5307e-05\n",
            "\u001b[1m163/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5307e-05\n",
            "\u001b[1m169/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5243e-05\n",
            "\u001b[1m169/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5243e-05\n",
            "\u001b[1m175/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5183e-05 \n",
            "\u001b[1m175/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5183e-05 \n",
            "\u001b[1m181/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5131e-05\n",
            "\u001b[1m181/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5131e-05\n",
            "\u001b[1m187/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5060e-05\n",
            "\u001b[1m187/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.5060e-05\n",
            "\u001b[1m192/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4991e-05\n",
            "\u001b[1m192/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4991e-05\n",
            "\u001b[1m198/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4908e-05\n",
            "\u001b[1m198/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4908e-05\n",
            "\u001b[1m204/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4822e-05\n",
            "\u001b[1m204/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4822e-05\n",
            "\u001b[1m210/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4739e-05\n",
            "\u001b[1m210/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4739e-05\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4657e-05\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4657e-05\n",
            "\u001b[1m222/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4577e-05 \n",
            "\u001b[1m222/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4577e-05 \n",
            "\u001b[1m228/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4498e-05\n",
            "\u001b[1m228/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4498e-05\n",
            "\u001b[1m234/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4422e-05\n",
            "\u001b[1m234/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4422e-05\n",
            "\u001b[1m239/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4369e-05\n",
            "\u001b[1m239/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4369e-05\n",
            "\u001b[1m244/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4321e-05\n",
            "\u001b[1m244/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4321e-05\n",
            "\u001b[1m250/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4263e-05\n",
            "\u001b[1m250/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4263e-05\n",
            "\u001b[1m256/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4206e-05 \n",
            "\u001b[1m256/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4206e-05 \n",
            "\u001b[1m261/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4165e-05\n",
            "\u001b[1m261/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4165e-05\n",
            "\u001b[1m266/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4122e-05\n",
            "\u001b[1m266/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4122e-05\n",
            "\u001b[1m272/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4074e-05\n",
            "\u001b[1m272/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4074e-05\n",
            "\u001b[1m278/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4040e-05\n",
            "\u001b[1m278/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4040e-05\n",
            "\u001b[1m284/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4015e-05\n",
            "\u001b[1m284/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.4015e-05\n",
            "\u001b[1m289/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3992e-05\n",
            "\u001b[1m289/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3992e-05\n",
            "\u001b[1m295/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3969e-05\n",
            "\u001b[1m295/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3969e-05\n",
            "\u001b[1m301/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3947e-05\n",
            "\u001b[1m301/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3947e-05\n",
            "\u001b[1m307/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3926e-05\n",
            "\u001b[1m307/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3926e-05\n",
            "\u001b[1m313/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3902e-05\n",
            "\u001b[1m313/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3902e-05\n",
            "\u001b[1m319/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3875e-05\n",
            "\u001b[1m319/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3875e-05\n",
            "\u001b[1m325/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3845e-05 \n",
            "\u001b[1m325/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3845e-05 \n",
            "\u001b[1m331/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3813e-05\n",
            "\u001b[1m331/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3813e-05\n",
            "\u001b[1m337/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3778e-05\n",
            "\u001b[1m337/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3778e-05\n",
            "\u001b[1m343/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3744e-05\n",
            "\u001b[1m343/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3744e-05\n",
            "\u001b[1m349/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3712e-05\n",
            "\u001b[1m349/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3712e-05\n",
            "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3680e-05\n",
            "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3680e-05\n",
            "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3658e-05\n",
            "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3658e-05\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3623e-05\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.3623e-05\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.1394e-05\n",
            "\n",
            "Epoch 9/50                                            \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.1394e-05\n",
            "\n",
            "Epoch 9/50                                            \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.5129e-05\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 4.5129e-05\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.8683e-05  \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.8683e-05  \n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.0291e-05\n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.0291e-05\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.1294e-05\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.1294e-05\n",
            "\u001b[1m 25/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.1965e-05\n",
            "\u001b[1m 25/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.1965e-05\n",
            "\u001b[1m 29/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2357e-05\n",
            "\u001b[1m 29/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2357e-05\n",
            "\u001b[1m 35/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2676e-05\n",
            "\u001b[1m 35/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2676e-05\n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2792e-05\n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2792e-05\n",
            "\u001b[1m 47/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2857e-05 \n",
            "\u001b[1m 47/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2857e-05 \n",
            "\u001b[1m 53/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3042e-05\n",
            "\u001b[1m 53/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3042e-05\n",
            "\u001b[1m 59/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3219e-05\n",
            "\u001b[1m 59/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3219e-05\n",
            "\u001b[1m 65/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3378e-05\n",
            "\u001b[1m 65/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3378e-05\n",
            "\u001b[1m 71/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3460e-05\n",
            "\u001b[1m 71/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3460e-05\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3537e-05\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3537e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3609e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3609e-05\n",
            "\u001b[1m 89/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3647e-05\n",
            "\u001b[1m 89/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3647e-05\n",
            "\u001b[1m 95/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3672e-05\n",
            "\u001b[1m 95/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3672e-05\n",
            "\u001b[1m101/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3675e-05\n",
            "\u001b[1m101/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3675e-05\n",
            "\u001b[1m107/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3655e-05\n",
            "\u001b[1m107/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3655e-05\n",
            "\u001b[1m113/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3614e-05\n",
            "\u001b[1m113/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3614e-05\n",
            "\u001b[1m119/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3553e-05\n",
            "\u001b[1m119/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3553e-05\n",
            "\u001b[1m125/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3510e-05\n",
            "\u001b[1m125/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3510e-05\n",
            "\u001b[1m131/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3456e-05\n",
            "\u001b[1m131/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3456e-05\n",
            "\u001b[1m137/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3406e-05\n",
            "\u001b[1m137/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3406e-05\n",
            "\u001b[1m143/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3344e-05\n",
            "\u001b[1m143/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3344e-05\n",
            "\u001b[1m149/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3288e-05\n",
            "\u001b[1m149/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3288e-05\n",
            "\u001b[1m154/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3242e-05\n",
            "\u001b[1m154/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3242e-05\n",
            "\u001b[1m159/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3191e-05\n",
            "\u001b[1m159/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3191e-05\n",
            "\u001b[1m165/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3147e-05\n",
            "\u001b[1m165/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3147e-05\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3104e-05\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3104e-05\n",
            "\u001b[1m177/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3073e-05\n",
            "\u001b[1m177/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3073e-05\n",
            "\u001b[1m182/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3052e-05\n",
            "\u001b[1m182/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3052e-05\n",
            "\u001b[1m188/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3021e-05\n",
            "\u001b[1m188/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3021e-05\n",
            "\u001b[1m194/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2987e-05\n",
            "\u001b[1m194/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2987e-05\n",
            "\u001b[1m200/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2951e-05\n",
            "\u001b[1m200/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2951e-05\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2913e-05\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2913e-05\n",
            "\u001b[1m212/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2880e-05\n",
            "\u001b[1m212/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2880e-05\n",
            "\u001b[1m218/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2844e-05\n",
            "\u001b[1m218/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2844e-05\n",
            "\u001b[1m224/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2808e-05\n",
            "\u001b[1m224/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2808e-05\n",
            "\u001b[1m229/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2779e-05\n",
            "\u001b[1m229/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2779e-05\n",
            "\u001b[1m234/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2748e-05\n",
            "\u001b[1m234/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2748e-05\n",
            "\u001b[1m240/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2712e-05\n",
            "\u001b[1m240/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2712e-05\n",
            "\u001b[1m246/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2674e-05\n",
            "\u001b[1m246/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2674e-05\n",
            "\u001b[1m252/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2634e-05\n",
            "\u001b[1m252/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2634e-05\n",
            "\u001b[1m258/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2593e-05\n",
            "\u001b[1m258/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2593e-05\n",
            "\u001b[1m264/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2564e-05\n",
            "\u001b[1m264/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2564e-05\n",
            "\u001b[1m270/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2532e-05\n",
            "\u001b[1m270/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2532e-05\n",
            "\u001b[1m276/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2499e-05\n",
            "\u001b[1m276/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2499e-05\n",
            "\u001b[1m282/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2468e-05\n",
            "\u001b[1m282/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2468e-05\n",
            "\u001b[1m287/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2443e-05\n",
            "\u001b[1m287/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2443e-05\n",
            "\u001b[1m293/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2412e-05\n",
            "\u001b[1m293/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2412e-05\n",
            "\u001b[1m299/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2383e-05\n",
            "\u001b[1m299/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2383e-05\n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2352e-05\n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2352e-05\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2321e-05\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2321e-05\n",
            "\u001b[1m317/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2289e-05\n",
            "\u001b[1m317/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2289e-05\n",
            "\u001b[1m323/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2254e-05\n",
            "\u001b[1m323/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2254e-05\n",
            "\u001b[1m329/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2219e-05\n",
            "\u001b[1m329/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2219e-05\n",
            "\u001b[1m335/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2186e-05\n",
            "\u001b[1m335/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2186e-05\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2159e-05\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2159e-05\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2127e-05\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2127e-05\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2092e-05\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2092e-05\n",
            "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2057e-05\n",
            "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2057e-05\n",
            "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2026e-05\n",
            "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2026e-05\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.0054e-05\n",
            "\n",
            "Epoch 10/50                                           \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.0054e-05\n",
            "\n",
            "Epoch 10/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.7981e-05\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.7981e-05\n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.4789e-05 \n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.4789e-05 \n",
            "\u001b[1m 11/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.6733e-05\n",
            "\u001b[1m 11/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 2.6733e-05\n",
            "\u001b[1m 17/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6285e-05\n",
            "\u001b[1m 17/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6285e-05\n",
            "\u001b[1m 23/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6323e-05\n",
            "\u001b[1m 23/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6323e-05\n",
            "\u001b[1m 29/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6327e-05\n",
            "\u001b[1m 29/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6327e-05\n",
            "\u001b[1m 33/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6410e-05\n",
            "\u001b[1m 33/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6410e-05\n",
            "\u001b[1m 39/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6455e-05\n",
            "\u001b[1m 39/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6455e-05\n",
            "\u001b[1m 45/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6258e-05\n",
            "\u001b[1m 45/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.6258e-05\n",
            "\u001b[1m 51/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5983e-05\n",
            "\u001b[1m 51/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5983e-05\n",
            "\u001b[1m 57/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5713e-05\n",
            "\u001b[1m 57/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5713e-05\n",
            "\u001b[1m 63/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5507e-05\n",
            "\u001b[1m 63/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5507e-05\n",
            "\u001b[1m 69/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5405e-05\n",
            "\u001b[1m 69/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5405e-05\n",
            "\u001b[1m 75/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5320e-05 \n",
            "\u001b[1m 75/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5320e-05 \n",
            "\u001b[1m 80/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5272e-05\n",
            "\u001b[1m 80/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5272e-05\n",
            "\u001b[1m 86/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5275e-05\n",
            "\u001b[1m 86/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5275e-05\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5262e-05\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 2.5262e-05\n",
            "\u001b[1m 98/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5232e-05 \n",
            "\u001b[1m 98/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5232e-05 \n",
            "\u001b[1m104/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5199e-05\n",
            "\u001b[1m104/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5199e-05\n",
            "\u001b[1m110/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5166e-05\n",
            "\u001b[1m110/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5166e-05\n",
            "\u001b[1m116/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5118e-05\n",
            "\u001b[1m116/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5118e-05\n",
            "\u001b[1m122/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5062e-05\n",
            "\u001b[1m122/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5062e-05\n",
            "\u001b[1m128/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5020e-05\n",
            "\u001b[1m128/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.5020e-05\n",
            "\u001b[1m134/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4994e-05\n",
            "\u001b[1m134/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4994e-05\n",
            "\u001b[1m140/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4966e-05\n",
            "\u001b[1m140/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4966e-05\n",
            "\u001b[1m146/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4929e-05\n",
            "\u001b[1m146/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4929e-05\n",
            "\u001b[1m152/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4890e-05\n",
            "\u001b[1m152/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4890e-05\n",
            "\u001b[1m158/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4848e-05\n",
            "\u001b[1m158/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4848e-05\n",
            "\u001b[1m164/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4805e-05\n",
            "\u001b[1m164/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4805e-05\n",
            "\u001b[1m170/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4772e-05\n",
            "\u001b[1m170/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4772e-05\n",
            "\u001b[1m174/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4754e-05\n",
            "\u001b[1m174/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4754e-05\n",
            "\u001b[1m180/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4734e-05\n",
            "\u001b[1m180/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4734e-05\n",
            "\u001b[1m186/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4721e-05\n",
            "\u001b[1m186/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4721e-05\n",
            "\u001b[1m192/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4707e-05\n",
            "\u001b[1m192/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4707e-05\n",
            "\u001b[1m198/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4695e-05\n",
            "\u001b[1m198/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4695e-05\n",
            "\u001b[1m204/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4679e-05\n",
            "\u001b[1m204/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4679e-05\n",
            "\u001b[1m210/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4660e-05\n",
            "\u001b[1m210/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4660e-05\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4643e-05\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4643e-05\n",
            "\u001b[1m221/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4626e-05\n",
            "\u001b[1m221/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4626e-05\n",
            "\u001b[1m227/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4601e-05\n",
            "\u001b[1m227/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4601e-05\n",
            "\u001b[1m233/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4575e-05\n",
            "\u001b[1m233/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4575e-05\n",
            "\u001b[1m239/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4552e-05\n",
            "\u001b[1m239/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4552e-05\n",
            "\u001b[1m244/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4531e-05\n",
            "\u001b[1m244/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4531e-05\n",
            "\u001b[1m250/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4509e-05\n",
            "\u001b[1m250/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4509e-05\n",
            "\u001b[1m256/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4487e-05\n",
            "\u001b[1m256/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4487e-05\n",
            "\u001b[1m262/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4461e-05\n",
            "\u001b[1m262/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4461e-05\n",
            "\u001b[1m268/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4435e-05\n",
            "\u001b[1m268/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4435e-05\n",
            "\u001b[1m274/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4411e-05\n",
            "\u001b[1m274/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4411e-05\n",
            "\u001b[1m280/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4389e-05\n",
            "\u001b[1m280/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4389e-05\n",
            "\u001b[1m286/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4368e-05\n",
            "\u001b[1m286/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4368e-05\n",
            "\u001b[1m290/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4354e-05\n",
            "\u001b[1m290/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4354e-05\n",
            "\u001b[1m296/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4333e-05\n",
            "\u001b[1m296/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4333e-05\n",
            "\u001b[1m302/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4313e-05\n",
            "\u001b[1m302/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4313e-05\n",
            "\u001b[1m308/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4292e-05\n",
            "\u001b[1m308/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4292e-05\n",
            "\u001b[1m314/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4274e-05\n",
            "\u001b[1m314/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4274e-05\n",
            "\u001b[1m320/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4256e-05\n",
            "\u001b[1m320/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4256e-05\n",
            "\u001b[1m326/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4237e-05\n",
            "\u001b[1m326/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4237e-05\n",
            "\u001b[1m332/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4217e-05\n",
            "\u001b[1m332/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4217e-05\n",
            "\u001b[1m338/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4195e-05\n",
            "\u001b[1m338/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4195e-05\n",
            "\u001b[1m344/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4172e-05\n",
            "\u001b[1m344/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4172e-05\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4148e-05\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4148e-05\n",
            "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4124e-05\n",
            "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4124e-05\n",
            "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4100e-05\n",
            "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4100e-05\n",
            "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4079e-05\n",
            "\u001b[1m367/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.4079e-05\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.2563e-05\n",
            "\n",
            "Epoch 11/50                                           \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 2.2563e-05\n",
            "\n",
            "Epoch 11/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.0219e-05\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 2.0219e-05\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4462e-05  \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4462e-05  \n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4498e-05\n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4498e-05\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4782e-05\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.4782e-05\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5131e-05\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5131e-05\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5535e-05\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5535e-05\n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5688e-05\n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5688e-05\n",
            "\u001b[1m 42/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5786e-05\n",
            "\u001b[1m 42/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.5786e-05\n",
            "\u001b[1m 48/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6049e-05\n",
            "\u001b[1m 48/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6049e-05\n",
            "\u001b[1m 54/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6331e-05\n",
            "\u001b[1m 54/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6331e-05\n",
            "\u001b[1m 60/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6580e-05\n",
            "\u001b[1m 60/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6580e-05\n",
            "\u001b[1m 66/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6790e-05\n",
            "\u001b[1m 66/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6790e-05\n",
            "\u001b[1m 71/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6922e-05\n",
            "\u001b[1m 71/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.6922e-05\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7102e-05\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7102e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7251e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7251e-05\n",
            "\u001b[1m 89/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7372e-05\n",
            "\u001b[1m 89/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7372e-05\n",
            "\u001b[1m 95/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7495e-05\n",
            "\u001b[1m 95/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7495e-05\n",
            "\u001b[1m101/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7616e-05\n",
            "\u001b[1m101/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7616e-05\n",
            "\u001b[1m107/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7716e-05\n",
            "\u001b[1m107/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7716e-05\n",
            "\u001b[1m113/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7791e-05\n",
            "\u001b[1m113/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7791e-05\n",
            "\u001b[1m118/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7841e-05\n",
            "\u001b[1m118/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7841e-05\n",
            "\u001b[1m124/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7907e-05\n",
            "\u001b[1m124/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7907e-05\n",
            "\u001b[1m129/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7959e-05\n",
            "\u001b[1m129/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7959e-05\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8011e-05\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8011e-05\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8059e-05\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8059e-05\n",
            "\u001b[1m147/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8107e-05\n",
            "\u001b[1m147/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8107e-05\n",
            "\u001b[1m153/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8152e-05\n",
            "\u001b[1m153/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8152e-05\n",
            "\u001b[1m159/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8192e-05\n",
            "\u001b[1m159/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8192e-05\n",
            "\u001b[1m164/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8217e-05\n",
            "\u001b[1m164/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8217e-05\n",
            "\u001b[1m170/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8237e-05\n",
            "\u001b[1m170/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8237e-05\n",
            "\u001b[1m176/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8252e-05\n",
            "\u001b[1m176/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8252e-05\n",
            "\u001b[1m182/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8272e-05\n",
            "\u001b[1m182/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8272e-05\n",
            "\u001b[1m188/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8285e-05\n",
            "\u001b[1m188/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8285e-05\n",
            "\u001b[1m194/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8296e-05\n",
            "\u001b[1m194/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8296e-05\n",
            "\u001b[1m200/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8306e-05\n",
            "\u001b[1m200/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8306e-05\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8313e-05\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8313e-05\n",
            "\u001b[1m212/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8318e-05\n",
            "\u001b[1m212/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8318e-05\n",
            "\u001b[1m217/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8319e-05\n",
            "\u001b[1m217/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8319e-05\n",
            "\u001b[1m223/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8319e-05\n",
            "\u001b[1m223/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8319e-05\n",
            "\u001b[1m229/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8321e-05\n",
            "\u001b[1m229/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8321e-05\n",
            "\u001b[1m235/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8322e-05\n",
            "\u001b[1m235/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8322e-05\n",
            "\u001b[1m241/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8320e-05\n",
            "\u001b[1m241/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8320e-05\n",
            "\u001b[1m247/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8315e-05\n",
            "\u001b[1m247/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8315e-05\n",
            "\u001b[1m253/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8308e-05\n",
            "\u001b[1m253/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8308e-05\n",
            "\u001b[1m259/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8302e-05\n",
            "\u001b[1m259/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8302e-05\n",
            "\u001b[1m264/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8296e-05\n",
            "\u001b[1m264/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8296e-05\n",
            "\u001b[1m269/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8287e-05\n",
            "\u001b[1m269/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8287e-05\n",
            "\u001b[1m274/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8278e-05\n",
            "\u001b[1m274/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8278e-05\n",
            "\u001b[1m280/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8266e-05\n",
            "\u001b[1m280/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8266e-05\n",
            "\u001b[1m286/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8257e-05\n",
            "\u001b[1m286/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8257e-05\n",
            "\u001b[1m292/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8246e-05\n",
            "\u001b[1m292/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8246e-05\n",
            "\u001b[1m298/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8235e-05\n",
            "\u001b[1m298/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8235e-05\n",
            "\u001b[1m304/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8224e-05\n",
            "\u001b[1m304/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8224e-05\n",
            "\u001b[1m310/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8213e-05\n",
            "\u001b[1m310/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8213e-05\n",
            "\u001b[1m314/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8208e-05\n",
            "\u001b[1m314/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8208e-05\n",
            "\u001b[1m320/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8199e-05\n",
            "\u001b[1m320/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8199e-05\n",
            "\u001b[1m326/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8189e-05\n",
            "\u001b[1m326/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8189e-05\n",
            "\u001b[1m332/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8178e-05\n",
            "\u001b[1m332/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8178e-05\n",
            "\u001b[1m338/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8166e-05\n",
            "\u001b[1m338/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8166e-05\n",
            "\u001b[1m344/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8154e-05\n",
            "\u001b[1m344/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8154e-05\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8143e-05\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8143e-05\n",
            "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8135e-05\n",
            "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8135e-05\n",
            "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8125e-05\n",
            "\u001b[1m359/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8125e-05\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8113e-05\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.8113e-05\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7309e-05\n",
            "\n",
            "Epoch 12/50                                           \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.7309e-05\n",
            "\n",
            "Epoch 12/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1511e-05\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.1511e-05\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1113e-05  \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1113e-05  \n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0814e-05\n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0814e-05\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1274e-05\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1274e-05\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1538e-05\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1538e-05\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1747e-05\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1747e-05\n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1896e-05 \n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1896e-05 \n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1987e-05\n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1987e-05\n",
            "\u001b[1m 47/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2057e-05 \n",
            "\u001b[1m 47/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2057e-05 \n",
            "\u001b[1m 53/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2119e-05\n",
            "\u001b[1m 53/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2119e-05\n",
            "\u001b[1m 59/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2211e-05\n",
            "\u001b[1m 59/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2211e-05\n",
            "\u001b[1m 65/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2295e-05\n",
            "\u001b[1m 65/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2295e-05\n",
            "\u001b[1m 71/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2400e-05\n",
            "\u001b[1m 71/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2400e-05\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2492e-05\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2492e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2572e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2572e-05\n",
            "\u001b[1m 89/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2634e-05\n",
            "\u001b[1m 89/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2634e-05\n",
            "\u001b[1m 94/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2677e-05\n",
            "\u001b[1m 94/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2677e-05\n",
            "\u001b[1m100/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2711e-05\n",
            "\u001b[1m100/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2711e-05\n",
            "\u001b[1m106/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2741e-05\n",
            "\u001b[1m106/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2741e-05\n",
            "\u001b[1m112/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2768e-05\n",
            "\u001b[1m112/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2768e-05\n",
            "\u001b[1m118/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2810e-05\n",
            "\u001b[1m118/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2810e-05\n",
            "\u001b[1m124/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2860e-05\n",
            "\u001b[1m124/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2860e-05\n",
            "\u001b[1m130/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2912e-05\n",
            "\u001b[1m130/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2912e-05\n",
            "\u001b[1m136/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2960e-05\n",
            "\u001b[1m136/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2960e-05\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3005e-05\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3005e-05\n",
            "\u001b[1m146/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3050e-05\n",
            "\u001b[1m146/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3050e-05\n",
            "\u001b[1m152/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3097e-05\n",
            "\u001b[1m152/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3097e-05\n",
            "\u001b[1m158/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3143e-05\n",
            "\u001b[1m158/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3143e-05\n",
            "\u001b[1m164/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3181e-05\n",
            "\u001b[1m164/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3181e-05\n",
            "\u001b[1m170/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3216e-05\n",
            "\u001b[1m170/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3216e-05\n",
            "\u001b[1m176/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3253e-05\n",
            "\u001b[1m176/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3253e-05\n",
            "\u001b[1m182/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3292e-05\n",
            "\u001b[1m182/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3292e-05\n",
            "\u001b[1m187/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3321e-05\n",
            "\u001b[1m187/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3321e-05\n",
            "\u001b[1m193/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3353e-05\n",
            "\u001b[1m193/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3353e-05\n",
            "\u001b[1m199/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3385e-05\n",
            "\u001b[1m199/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3385e-05\n",
            "\u001b[1m205/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3415e-05\n",
            "\u001b[1m205/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3415e-05\n",
            "\u001b[1m211/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3440e-05\n",
            "\u001b[1m211/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3440e-05\n",
            "\u001b[1m217/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3464e-05\n",
            "\u001b[1m217/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3464e-05\n",
            "\u001b[1m223/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3487e-05\n",
            "\u001b[1m223/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3487e-05\n",
            "\u001b[1m229/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3509e-05\n",
            "\u001b[1m229/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3509e-05\n",
            "\u001b[1m234/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3527e-05\n",
            "\u001b[1m234/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3527e-05\n",
            "\u001b[1m240/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3545e-05\n",
            "\u001b[1m240/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3545e-05\n",
            "\u001b[1m246/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3560e-05\n",
            "\u001b[1m246/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3560e-05\n",
            "\u001b[1m252/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3574e-05\n",
            "\u001b[1m252/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3574e-05\n",
            "\u001b[1m258/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3588e-05\n",
            "\u001b[1m258/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3588e-05\n",
            "\u001b[1m264/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3602e-05\n",
            "\u001b[1m264/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3602e-05\n",
            "\u001b[1m270/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3615e-05\n",
            "\u001b[1m270/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3615e-05\n",
            "\u001b[1m275/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3625e-05\n",
            "\u001b[1m275/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3625e-05\n",
            "\u001b[1m281/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3636e-05\n",
            "\u001b[1m281/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3636e-05\n",
            "\u001b[1m287/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3646e-05\n",
            "\u001b[1m287/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3646e-05\n",
            "\u001b[1m293/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3659e-05\n",
            "\u001b[1m293/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3659e-05\n",
            "\u001b[1m299/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3671e-05\n",
            "\u001b[1m299/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3671e-05\n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3682e-05\n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3682e-05\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3691e-05\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3691e-05\n",
            "\u001b[1m316/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3697e-05\n",
            "\u001b[1m316/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3697e-05\n",
            "\u001b[1m322/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3703e-05\n",
            "\u001b[1m322/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3703e-05\n",
            "\u001b[1m328/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3707e-05\n",
            "\u001b[1m328/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3707e-05\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3710e-05\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3710e-05\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3710e-05\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3710e-05\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3710e-05\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3710e-05\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3711e-05\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3711e-05\n",
            "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3710e-05\n",
            "\u001b[1m357/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3710e-05\n",
            "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3708e-05\n",
            "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3708e-05\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3507e-05\n",
            "\n",
            "Epoch 13/50                                           \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.3507e-05\n",
            "\n",
            "Epoch 13/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.2647e-05\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 1.2647e-05\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1263e-05 \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1263e-05 \n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1931e-05\n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1931e-05\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2039e-05\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2039e-05\n",
            "\u001b[1m 25/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1998e-05\n",
            "\u001b[1m 25/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1998e-05\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2246e-05\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2246e-05\n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2359e-05\n",
            "\u001b[1m 36/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2359e-05\n",
            "\u001b[1m 42/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2358e-05\n",
            "\u001b[1m 42/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2358e-05\n",
            "\u001b[1m 48/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2316e-05\n",
            "\u001b[1m 48/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2316e-05\n",
            "\u001b[1m 54/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2250e-05\n",
            "\u001b[1m 54/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2250e-05\n",
            "\u001b[1m 60/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2214e-05\n",
            "\u001b[1m 60/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2214e-05\n",
            "\u001b[1m 66/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2188e-05\n",
            "\u001b[1m 66/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2188e-05\n",
            "\u001b[1m 72/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2168e-05\n",
            "\u001b[1m 72/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2168e-05\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2144e-05\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2144e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2095e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2095e-05\n",
            "\u001b[1m 89/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2040e-05\n",
            "\u001b[1m 89/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.2040e-05\n",
            "\u001b[1m 95/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1980e-05\n",
            "\u001b[1m 95/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1980e-05\n",
            "\u001b[1m101/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1949e-05\n",
            "\u001b[1m101/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1949e-05\n",
            "\u001b[1m107/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1918e-05\n",
            "\u001b[1m107/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1918e-05\n",
            "\u001b[1m112/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1893e-05\n",
            "\u001b[1m112/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1893e-05\n",
            "\u001b[1m117/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1872e-05\n",
            "\u001b[1m117/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1872e-05\n",
            "\u001b[1m123/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1841e-05\n",
            "\u001b[1m123/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1841e-05\n",
            "\u001b[1m129/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1811e-05\n",
            "\u001b[1m129/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1811e-05\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1778e-05\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1778e-05\n",
            "\u001b[1m140/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1752e-05\n",
            "\u001b[1m140/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1752e-05\n",
            "\u001b[1m145/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1727e-05\n",
            "\u001b[1m145/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1727e-05\n",
            "\u001b[1m151/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1706e-05\n",
            "\u001b[1m151/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1706e-05\n",
            "\u001b[1m157/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1689e-05\n",
            "\u001b[1m157/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1689e-05\n",
            "\u001b[1m163/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1679e-05\n",
            "\u001b[1m163/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1679e-05\n",
            "\u001b[1m169/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1671e-05\n",
            "\u001b[1m169/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1671e-05\n",
            "\u001b[1m175/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1665e-05\n",
            "\u001b[1m175/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1665e-05\n",
            "\u001b[1m180/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1658e-05\n",
            "\u001b[1m180/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1658e-05\n",
            "\u001b[1m186/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1649e-05\n",
            "\u001b[1m186/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1649e-05\n",
            "\u001b[1m192/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1640e-05\n",
            "\u001b[1m192/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1640e-05\n",
            "\u001b[1m198/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1630e-05\n",
            "\u001b[1m198/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1630e-05\n",
            "\u001b[1m204/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1618e-05\n",
            "\u001b[1m204/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1618e-05\n",
            "\u001b[1m210/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1607e-05\n",
            "\u001b[1m210/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1607e-05\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1599e-05\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1599e-05\n",
            "\u001b[1m221/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1593e-05\n",
            "\u001b[1m221/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1593e-05\n",
            "\u001b[1m227/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1583e-05\n",
            "\u001b[1m227/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1583e-05\n",
            "\u001b[1m233/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1574e-05\n",
            "\u001b[1m233/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1574e-05\n",
            "\u001b[1m239/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1565e-05\n",
            "\u001b[1m239/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1565e-05\n",
            "\u001b[1m245/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1557e-05\n",
            "\u001b[1m245/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1557e-05\n",
            "\u001b[1m251/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1550e-05\n",
            "\u001b[1m251/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1550e-05\n",
            "\u001b[1m257/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1542e-05\n",
            "\u001b[1m257/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1542e-05\n",
            "\u001b[1m262/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1533e-05\n",
            "\u001b[1m262/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1533e-05\n",
            "\u001b[1m268/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1523e-05\n",
            "\u001b[1m268/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1523e-05\n",
            "\u001b[1m274/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1513e-05\n",
            "\u001b[1m274/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1513e-05\n",
            "\u001b[1m280/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1502e-05\n",
            "\u001b[1m280/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1502e-05\n",
            "\u001b[1m286/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1491e-05\n",
            "\u001b[1m286/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1491e-05\n",
            "\u001b[1m292/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1479e-05\n",
            "\u001b[1m292/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1479e-05\n",
            "\u001b[1m298/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1466e-05\n",
            "\u001b[1m298/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1466e-05\n",
            "\u001b[1m304/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1453e-05\n",
            "\u001b[1m304/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1453e-05\n",
            "\u001b[1m310/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1441e-05\n",
            "\u001b[1m310/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1441e-05\n",
            "\u001b[1m316/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1429e-05\n",
            "\u001b[1m316/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1429e-05\n",
            "\u001b[1m322/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1417e-05\n",
            "\u001b[1m322/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1417e-05\n",
            "\u001b[1m328/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1407e-05\n",
            "\u001b[1m328/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1407e-05\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1397e-05\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1397e-05\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1386e-05\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1386e-05\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1375e-05\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1375e-05\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1364e-05\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1364e-05\n",
            "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1353e-05\n",
            "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1353e-05\n",
            "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1341e-05\n",
            "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.1341e-05\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0662e-05\n",
            "\n",
            "Epoch 14/50                                           \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 1.0662e-05\n",
            "\n",
            "Epoch 14/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.3660e-06\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 4.3660e-06\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.7054e-06 \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 7.7054e-06 \n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0022e-05\n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0022e-05\n",
            "\u001b[1m 17/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0815e-05\n",
            "\u001b[1m 17/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0815e-05\n",
            "\u001b[1m 23/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1492e-05\n",
            "\u001b[1m 23/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1492e-05\n",
            "\u001b[1m 28/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1617e-05\n",
            "\u001b[1m 28/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1617e-05\n",
            "\u001b[1m 33/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1639e-05\n",
            "\u001b[1m 33/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1639e-05\n",
            "\u001b[1m 38/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1626e-05\n",
            "\u001b[1m 38/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1626e-05\n",
            "\u001b[1m 44/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1559e-05\n",
            "\u001b[1m 44/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1559e-05\n",
            "\u001b[1m 49/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1478e-05\n",
            "\u001b[1m 49/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1478e-05\n",
            "\u001b[1m 55/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1381e-05\n",
            "\u001b[1m 55/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1381e-05\n",
            "\u001b[1m 60/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1294e-05\n",
            "\u001b[1m 60/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1294e-05\n",
            "\u001b[1m 65/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1213e-05\n",
            "\u001b[1m 65/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1213e-05\n",
            "\u001b[1m 71/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1122e-05\n",
            "\u001b[1m 71/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1122e-05\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1038e-05\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.1038e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0967e-05\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0967e-05\n",
            "\u001b[1m 88/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0914e-05\n",
            "\u001b[1m 88/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0914e-05\n",
            "\u001b[1m 94/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0855e-05\n",
            "\u001b[1m 94/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0855e-05\n",
            "\u001b[1m100/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0804e-05\n",
            "\u001b[1m100/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0804e-05\n",
            "\u001b[1m106/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0759e-05\n",
            "\u001b[1m106/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0759e-05\n",
            "\u001b[1m112/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0714e-05\n",
            "\u001b[1m112/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0714e-05\n",
            "\u001b[1m118/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0664e-05\n",
            "\u001b[1m118/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0664e-05\n",
            "\u001b[1m124/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0608e-05\n",
            "\u001b[1m124/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0608e-05\n",
            "\u001b[1m130/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0557e-05\n",
            "\u001b[1m130/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0557e-05\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0514e-05\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0514e-05\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0465e-05\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0465e-05\n",
            "\u001b[1m147/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0418e-05\n",
            "\u001b[1m147/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0418e-05\n",
            "\u001b[1m153/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0375e-05\n",
            "\u001b[1m153/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0375e-05\n",
            "\u001b[1m159/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0335e-05\n",
            "\u001b[1m159/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0335e-05\n",
            "\u001b[1m165/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0294e-05\n",
            "\u001b[1m165/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0294e-05\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0253e-05\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0253e-05\n",
            "\u001b[1m175/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0225e-05\n",
            "\u001b[1m175/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0225e-05\n",
            "\u001b[1m180/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0191e-05\n",
            "\u001b[1m180/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0191e-05\n",
            "\u001b[1m185/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0157e-05\n",
            "\u001b[1m185/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0157e-05\n",
            "\u001b[1m190/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0125e-05\n",
            "\u001b[1m190/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0125e-05\n",
            "\u001b[1m195/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0095e-05\n",
            "\u001b[1m195/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0095e-05\n",
            "\u001b[1m201/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0061e-05\n",
            "\u001b[1m201/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0061e-05\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0033e-05\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0033e-05\n",
            "\u001b[1m211/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0005e-05\n",
            "\u001b[1m211/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 1.0005e-05\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.9791e-06\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.9791e-06\n",
            "\u001b[1m220/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.9587e-06\n",
            "\u001b[1m220/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.9587e-06\n",
            "\u001b[1m225/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.9341e-06\n",
            "\u001b[1m225/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.9341e-06\n",
            "\u001b[1m231/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.9061e-06\n",
            "\u001b[1m231/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.9061e-06\n",
            "\u001b[1m237/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.8784e-06\n",
            "\u001b[1m237/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.8784e-06\n",
            "\u001b[1m242/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.8557e-06\n",
            "\u001b[1m242/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.8557e-06\n",
            "\u001b[1m248/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.8309e-06\n",
            "\u001b[1m248/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.8309e-06\n",
            "\u001b[1m254/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.8063e-06\n",
            "\u001b[1m254/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.8063e-06\n",
            "\u001b[1m260/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7818e-06\n",
            "\u001b[1m260/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7818e-06\n",
            "\u001b[1m266/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7579e-06\n",
            "\u001b[1m266/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7579e-06\n",
            "\u001b[1m272/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7357e-06\n",
            "\u001b[1m272/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7357e-06\n",
            "\u001b[1m278/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7139e-06\n",
            "\u001b[1m278/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.7139e-06\n",
            "\u001b[1m284/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6935e-06\n",
            "\u001b[1m284/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6935e-06\n",
            "\u001b[1m289/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6767e-06\n",
            "\u001b[1m289/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6767e-06\n",
            "\u001b[1m294/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6597e-06\n",
            "\u001b[1m294/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6597e-06\n",
            "\u001b[1m300/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6392e-06\n",
            "\u001b[1m300/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6392e-06\n",
            "\u001b[1m306/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6196e-06\n",
            "\u001b[1m306/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6196e-06\n",
            "\u001b[1m312/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6004e-06\n",
            "\u001b[1m312/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.6004e-06\n",
            "\u001b[1m318/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5813e-06\n",
            "\u001b[1m318/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5813e-06\n",
            "\u001b[1m324/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5630e-06\n",
            "\u001b[1m324/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5630e-06\n",
            "\u001b[1m329/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5478e-06\n",
            "\u001b[1m329/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5478e-06\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5329e-06\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5329e-06\n",
            "\u001b[1m339/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5183e-06\n",
            "\u001b[1m339/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5183e-06\n",
            "\u001b[1m344/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5049e-06\n",
            "\u001b[1m344/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.5049e-06\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.4894e-06\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.4894e-06\n",
            "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.4764e-06\n",
            "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.4764e-06\n",
            "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.4634e-06\n",
            "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.4634e-06\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.4504e-06\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 9.4504e-06\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.4804e-06\n",
            "\n",
            "Epoch 15/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.7898e-06\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 8.4804e-06\n",
            "\n",
            "Epoch 15/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 9.7898e-06\n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.8372e-06\n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.8372e-06\n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.7184e-06\n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.7184e-06\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.4565e-06\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.4565e-06\n",
            "\u001b[1m 23/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2755e-06\n",
            "\u001b[1m 23/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2755e-06\n",
            "\u001b[1m 29/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0728e-06\n",
            "\u001b[1m 29/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0728e-06\n",
            "\u001b[1m 35/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.9097e-06\n",
            "\u001b[1m 35/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.9097e-06\n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.7919e-06\n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.7919e-06\n",
            "\u001b[1m 47/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.7645e-06\n",
            "\u001b[1m 47/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.7645e-06\n",
            "\u001b[1m 53/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.8054e-06\n",
            "\u001b[1m 53/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.8054e-06\n",
            "\u001b[1m 58/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.8412e-06\n",
            "\u001b[1m 58/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.8412e-06\n",
            "\u001b[1m 63/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.8783e-06\n",
            "\u001b[1m 63/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.8783e-06\n",
            "\u001b[1m 68/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.9326e-06\n",
            "\u001b[1m 68/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.9326e-06\n",
            "\u001b[1m 73/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.9826e-06\n",
            "\u001b[1m 73/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.9826e-06\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0117e-06\n",
            "\u001b[1m 77/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0117e-06\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0545e-06\n",
            "\u001b[1m 83/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0545e-06\n",
            "\u001b[1m 88/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0916e-06\n",
            "\u001b[1m 88/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.0916e-06\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1193e-06\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1193e-06\n",
            "\u001b[1m 97/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.1504e-06\n",
            "\u001b[1m 97/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.1504e-06\n",
            "\u001b[1m103/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1848e-06\n",
            "\u001b[1m103/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1848e-06\n",
            "\u001b[1m108/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.2106e-06\n",
            "\u001b[1m108/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 7.2106e-06\n",
            "\u001b[1m114/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2391e-06\n",
            "\u001b[1m114/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2391e-06\n",
            "\u001b[1m120/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2648e-06\n",
            "\u001b[1m120/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2648e-06\n",
            "\u001b[1m126/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2844e-06\n",
            "\u001b[1m126/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2844e-06\n",
            "\u001b[1m131/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2953e-06\n",
            "\u001b[1m131/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2953e-06\n",
            "\u001b[1m137/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3032e-06\n",
            "\u001b[1m137/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3032e-06\n",
            "\u001b[1m143/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3044e-06\n",
            "\u001b[1m143/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3044e-06\n",
            "\u001b[1m149/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3054e-06\n",
            "\u001b[1m149/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3054e-06\n",
            "\u001b[1m155/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3060e-06\n",
            "\u001b[1m155/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3060e-06\n",
            "\u001b[1m160/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3067e-06\n",
            "\u001b[1m160/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3067e-06\n",
            "\u001b[1m166/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3054e-06\n",
            "\u001b[1m166/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3054e-06\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3040e-06\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3040e-06\n",
            "\u001b[1m177/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3012e-06\n",
            "\u001b[1m177/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.3012e-06\n",
            "\u001b[1m183/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2976e-06\n",
            "\u001b[1m183/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2976e-06\n",
            "\u001b[1m189/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2951e-06\n",
            "\u001b[1m189/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2951e-06\n",
            "\u001b[1m195/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2918e-06\n",
            "\u001b[1m195/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2918e-06\n",
            "\u001b[1m200/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2883e-06\n",
            "\u001b[1m200/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2883e-06\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2821e-06\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2821e-06\n",
            "\u001b[1m212/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2757e-06\n",
            "\u001b[1m212/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2757e-06\n",
            "\u001b[1m218/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2713e-06\n",
            "\u001b[1m218/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2713e-06\n",
            "\u001b[1m224/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2663e-06\n",
            "\u001b[1m224/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2663e-06\n",
            "\u001b[1m230/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2598e-06\n",
            "\u001b[1m230/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2598e-06\n",
            "\u001b[1m236/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2530e-06\n",
            "\u001b[1m236/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2530e-06\n",
            "\u001b[1m241/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2474e-06\n",
            "\u001b[1m241/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2474e-06\n",
            "\u001b[1m247/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2396e-06\n",
            "\u001b[1m247/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2396e-06\n",
            "\u001b[1m253/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2318e-06\n",
            "\u001b[1m253/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2318e-06\n",
            "\u001b[1m259/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2244e-06\n",
            "\u001b[1m259/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2244e-06\n",
            "\u001b[1m265/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2166e-06\n",
            "\u001b[1m265/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2166e-06\n",
            "\u001b[1m271/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2081e-06\n",
            "\u001b[1m271/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.2081e-06\n",
            "\u001b[1m277/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1999e-06\n",
            "\u001b[1m277/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1999e-06\n",
            "\u001b[1m282/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1939e-06\n",
            "\u001b[1m282/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1939e-06\n",
            "\u001b[1m288/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1870e-06\n",
            "\u001b[1m288/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1870e-06\n",
            "\u001b[1m294/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1806e-06\n",
            "\u001b[1m294/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1806e-06\n",
            "\u001b[1m300/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1743e-06\n",
            "\u001b[1m300/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1743e-06\n",
            "\u001b[1m306/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1682e-06\n",
            "\u001b[1m306/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1682e-06\n",
            "\u001b[1m312/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1620e-06\n",
            "\u001b[1m312/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1620e-06\n",
            "\u001b[1m318/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1558e-06\n",
            "\u001b[1m318/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1558e-06\n",
            "\u001b[1m324/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1498e-06\n",
            "\u001b[1m324/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1498e-06\n",
            "\u001b[1m329/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1446e-06\n",
            "\u001b[1m329/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1446e-06\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1391e-06\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1391e-06\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1320e-06\n",
            "\u001b[1m340/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1320e-06\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1248e-06\n",
            "\u001b[1m346/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1248e-06\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1180e-06\n",
            "\u001b[1m352/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1180e-06\n",
            "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1123e-06\n",
            "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1123e-06\n",
            "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1066e-06\n",
            "\u001b[1m364/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 7.1066e-06\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.8026e-06\n",
            "\n",
            "Epoch 16/50                                           \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 6.8026e-06\n",
            "\n",
            "Epoch 16/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.6433e-06\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 3.6433e-06\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6404e-06 \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6404e-06 \n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.0181e-06\n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.0181e-06\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1818e-06\n",
            "\u001b[1m 19/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.1818e-06\n",
            "\u001b[1m 25/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3004e-06\n",
            "\u001b[1m 25/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3004e-06\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3486e-06\n",
            "\u001b[1m 30/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.3486e-06\n",
            "\u001b[1m 35/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4230e-06\n",
            "\u001b[1m 35/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.4230e-06\n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5155e-06\n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5155e-06\n",
            "\u001b[1m 47/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5853e-06\n",
            "\u001b[1m 47/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.5853e-06\n",
            "\u001b[1m 53/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6566e-06\n",
            "\u001b[1m 53/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.6566e-06\n",
            "\u001b[1m 59/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7349e-06\n",
            "\u001b[1m 59/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7349e-06\n",
            "\u001b[1m 64/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7847e-06\n",
            "\u001b[1m 64/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.7847e-06\n",
            "\u001b[1m 70/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.8306e-06\n",
            "\u001b[1m 70/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.8306e-06\n",
            "\u001b[1m 76/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.8663e-06\n",
            "\u001b[1m 76/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.8663e-06\n",
            "\u001b[1m 82/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9022e-06\n",
            "\u001b[1m 82/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9022e-06\n",
            "\u001b[1m 88/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9392e-06\n",
            "\u001b[1m 88/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9392e-06\n",
            "\u001b[1m 94/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9737e-06\n",
            "\u001b[1m 94/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9737e-06\n",
            "\u001b[1m100/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.0036e-06\n",
            "\u001b[1m100/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.0036e-06\n",
            "\u001b[1m103/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0186e-06\n",
            "\u001b[1m103/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0186e-06\n",
            "\u001b[1m109/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0482e-06\n",
            "\u001b[1m109/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0482e-06\n",
            "\u001b[1m115/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0745e-06\n",
            "\u001b[1m115/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0745e-06\n",
            "\u001b[1m121/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0982e-06\n",
            "\u001b[1m121/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.0982e-06\n",
            "\u001b[1m127/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1189e-06 \n",
            "\u001b[1m127/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1189e-06 \n",
            "\u001b[1m133/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1381e-06\n",
            "\u001b[1m133/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1381e-06\n",
            "\u001b[1m138/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.1532e-06\n",
            "\u001b[1m138/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.1532e-06\n",
            "\u001b[1m144/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.1697e-06\n",
            "\u001b[1m144/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.1697e-06\n",
            "\u001b[1m150/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1843e-06 \n",
            "\u001b[1m150/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1843e-06 \n",
            "\u001b[1m156/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1988e-06\n",
            "\u001b[1m156/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.1988e-06\n",
            "\u001b[1m162/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2116e-06\n",
            "\u001b[1m162/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2116e-06\n",
            "\u001b[1m168/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2246e-06\n",
            "\u001b[1m168/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2246e-06\n",
            "\u001b[1m173/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2348e-06\n",
            "\u001b[1m173/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2348e-06\n",
            "\u001b[1m178/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2442e-06\n",
            "\u001b[1m178/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2442e-06\n",
            "\u001b[1m184/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2549e-06\n",
            "\u001b[1m184/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2549e-06\n",
            "\u001b[1m190/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2649e-06\n",
            "\u001b[1m190/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2649e-06\n",
            "\u001b[1m196/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2762e-06\n",
            "\u001b[1m196/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2762e-06\n",
            "\u001b[1m202/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2884e-06\n",
            "\u001b[1m202/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2884e-06\n",
            "\u001b[1m208/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2998e-06\n",
            "\u001b[1m208/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.2998e-06\n",
            "\u001b[1m214/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3106e-06\n",
            "\u001b[1m214/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3106e-06\n",
            "\u001b[1m219/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3181e-06\n",
            "\u001b[1m219/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3181e-06\n",
            "\u001b[1m225/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3268e-06\n",
            "\u001b[1m225/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3268e-06\n",
            "\u001b[1m231/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3344e-06\n",
            "\u001b[1m231/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3344e-06\n",
            "\u001b[1m237/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3409e-06\n",
            "\u001b[1m237/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3409e-06\n",
            "\u001b[1m243/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3489e-06\n",
            "\u001b[1m243/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3489e-06\n",
            "\u001b[1m249/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3564e-06\n",
            "\u001b[1m249/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3564e-06\n",
            "\u001b[1m254/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3620e-06\n",
            "\u001b[1m254/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3620e-06\n",
            "\u001b[1m260/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3676e-06\n",
            "\u001b[1m260/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3676e-06\n",
            "\u001b[1m266/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3720e-06\n",
            "\u001b[1m266/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3720e-06\n",
            "\u001b[1m271/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3748e-06\n",
            "\u001b[1m271/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3748e-06\n",
            "\u001b[1m277/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3781e-06\n",
            "\u001b[1m277/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3781e-06\n",
            "\u001b[1m283/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3805e-06\n",
            "\u001b[1m283/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3805e-06\n",
            "\u001b[1m288/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3825e-06\n",
            "\u001b[1m288/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3825e-06\n",
            "\u001b[1m294/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3849e-06\n",
            "\u001b[1m294/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3849e-06\n",
            "\u001b[1m300/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3874e-06 \n",
            "\u001b[1m300/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.3874e-06 \n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3891e-06\n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3891e-06\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3910e-06\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3910e-06\n",
            "\u001b[1m316/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3929e-06\n",
            "\u001b[1m316/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3929e-06\n",
            "\u001b[1m322/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3954e-06\n",
            "\u001b[1m322/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3954e-06\n",
            "\u001b[1m326/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3969e-06\n",
            "\u001b[1m326/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3969e-06\n",
            "\u001b[1m331/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3987e-06\n",
            "\u001b[1m331/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.3987e-06\n",
            "\u001b[1m336/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4002e-06\n",
            "\u001b[1m336/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4002e-06\n",
            "\u001b[1m342/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4019e-06\n",
            "\u001b[1m342/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4019e-06\n",
            "\u001b[1m348/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4038e-06\n",
            "\u001b[1m348/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4038e-06\n",
            "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4055e-06\n",
            "\u001b[1m354/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4055e-06\n",
            "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4070e-06\n",
            "\u001b[1m360/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4070e-06\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4081e-06\n",
            "\u001b[1m365/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4081e-06\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4773e-06\n",
            "\n",
            "Epoch 17/50                                           \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 5.4773e-06\n",
            "\n",
            "Epoch 17/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.4368e-06\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 4.4368e-06\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9729e-06  \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9729e-06  \n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9714e-06\n",
            "\u001b[1m 13/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9714e-06\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9181e-06\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 4.9181e-06\n",
            "\u001b[1m 22/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.8734e-06\n",
            "\u001b[1m 22/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.8734e-06\n",
            "\u001b[1m 28/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7887e-06\n",
            "\u001b[1m 28/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7887e-06\n",
            "\u001b[1m 33/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7443e-06\n",
            "\u001b[1m 33/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7443e-06\n",
            "\u001b[1m 39/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7241e-06\n",
            "\u001b[1m 39/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7241e-06\n",
            "\u001b[1m 45/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7288e-06\n",
            "\u001b[1m 45/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7288e-06\n",
            "\u001b[1m 49/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7381e-06\n",
            "\u001b[1m 49/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7381e-06\n",
            "\u001b[1m 53/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.7506e-06\n",
            "\u001b[1m 53/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.7506e-06\n",
            "\u001b[1m 59/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.7583e-06\n",
            "\u001b[1m 59/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.7583e-06\n",
            "\u001b[1m 65/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7641e-06\n",
            "\u001b[1m 65/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7641e-06\n",
            "\u001b[1m 70/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7669e-06\n",
            "\u001b[1m 70/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7669e-06\n",
            "\u001b[1m 76/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7678e-06\n",
            "\u001b[1m 76/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7678e-06\n",
            "\u001b[1m 81/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.7646e-06\n",
            "\u001b[1m 81/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.7646e-06\n",
            "\u001b[1m 86/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.7582e-06\n",
            "\u001b[1m 86/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.7582e-06\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7518e-06\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7518e-06\n",
            "\u001b[1m 97/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7479e-06\n",
            "\u001b[1m 97/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7479e-06\n",
            "\u001b[1m103/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7413e-06\n",
            "\u001b[1m103/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7413e-06\n",
            "\u001b[1m109/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7338e-06\n",
            "\u001b[1m109/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7338e-06\n",
            "\u001b[1m115/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7269e-06\n",
            "\u001b[1m115/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7269e-06\n",
            "\u001b[1m120/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7224e-06\n",
            "\u001b[1m120/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7224e-06\n",
            "\u001b[1m125/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7214e-06\n",
            "\u001b[1m125/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7214e-06\n",
            "\u001b[1m130/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7184e-06\n",
            "\u001b[1m130/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7184e-06\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7144e-06\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7144e-06\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7086e-06\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7086e-06\n",
            "\u001b[1m146/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7033e-06\n",
            "\u001b[1m146/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.7033e-06\n",
            "\u001b[1m151/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6984e-06\n",
            "\u001b[1m151/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6984e-06\n",
            "\u001b[1m156/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6939e-06\n",
            "\u001b[1m156/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6939e-06\n",
            "\u001b[1m161/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6891e-06\n",
            "\u001b[1m161/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6891e-06\n",
            "\u001b[1m166/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6890e-06\n",
            "\u001b[1m166/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6890e-06\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6888e-06\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6888e-06\n",
            "\u001b[1m176/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6878e-06\n",
            "\u001b[1m176/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6878e-06\n",
            "\u001b[1m180/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6861e-06\n",
            "\u001b[1m180/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6861e-06\n",
            "\u001b[1m185/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6846e-06\n",
            "\u001b[1m185/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6846e-06\n",
            "\u001b[1m189/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6836e-06\n",
            "\u001b[1m189/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6836e-06\n",
            "\u001b[1m194/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6820e-06\n",
            "\u001b[1m194/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6820e-06\n",
            "\u001b[1m200/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6789e-06\n",
            "\u001b[1m200/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6789e-06\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6754e-06\n",
            "\u001b[1m206/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6754e-06\n",
            "\u001b[1m211/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6736e-06\n",
            "\u001b[1m211/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6736e-06\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6731e-06\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6731e-06\n",
            "\u001b[1m222/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6723e-06\n",
            "\u001b[1m222/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6723e-06\n",
            "\u001b[1m228/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6711e-06\n",
            "\u001b[1m228/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6711e-06\n",
            "\u001b[1m234/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6686e-06\n",
            "\u001b[1m234/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6686e-06\n",
            "\u001b[1m239/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6664e-06\n",
            "\u001b[1m239/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6664e-06\n",
            "\u001b[1m244/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6639e-06\n",
            "\u001b[1m244/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6639e-06\n",
            "\u001b[1m249/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6614e-06\n",
            "\u001b[1m249/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6614e-06\n",
            "\u001b[1m255/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6580e-06\n",
            "\u001b[1m255/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6580e-06\n",
            "\u001b[1m260/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6550e-06\n",
            "\u001b[1m260/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6550e-06\n",
            "\u001b[1m265/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6518e-06\n",
            "\u001b[1m265/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6518e-06\n",
            "\u001b[1m270/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6488e-06\n",
            "\u001b[1m270/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6488e-06\n",
            "\u001b[1m275/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6459e-06\n",
            "\u001b[1m275/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6459e-06\n",
            "\u001b[1m281/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6424e-06\n",
            "\u001b[1m281/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6424e-06\n",
            "\u001b[1m284/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6406e-06\n",
            "\u001b[1m284/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6406e-06\n",
            "\u001b[1m289/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6375e-06\n",
            "\u001b[1m289/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6375e-06\n",
            "\u001b[1m294/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6342e-06\n",
            "\u001b[1m294/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6342e-06\n",
            "\u001b[1m300/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6312e-06\n",
            "\u001b[1m300/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6312e-06\n",
            "\u001b[1m306/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6282e-06\n",
            "\u001b[1m306/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6282e-06\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6255e-06\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6255e-06\n",
            "\u001b[1m316/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6232e-06\n",
            "\u001b[1m316/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6232e-06\n",
            "\u001b[1m321/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6214e-06\n",
            "\u001b[1m321/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6214e-06\n",
            "\u001b[1m327/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6191e-06\n",
            "\u001b[1m327/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6191e-06\n",
            "\u001b[1m333/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6168e-06\n",
            "\u001b[1m333/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6168e-06\n",
            "\u001b[1m338/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6150e-06\n",
            "\u001b[1m338/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6150e-06\n",
            "\u001b[1m344/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6126e-06\n",
            "\u001b[1m344/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6126e-06\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6100e-06\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6100e-06\n",
            "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6079e-06\n",
            "\u001b[1m355/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 4.6079e-06\n",
            "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6066e-06\n",
            "\u001b[1m358/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6066e-06\n",
            "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6045e-06\n",
            "\u001b[1m363/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6045e-06\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6023e-06\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.6023e-06\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.4350e-06\n",
            "\n",
            "Epoch 18/50                                           \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 4.4350e-06\n",
            "\n",
            "Epoch 18/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.8312e-06\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 2.8312e-06\n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2998e-06  \n",
            "\u001b[1m  7/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2998e-06  \n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2785e-06\n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2785e-06\n",
            "\u001b[1m 17/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2296e-06\n",
            "\u001b[1m 17/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2296e-06\n",
            "\u001b[1m 23/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2527e-06\n",
            "\u001b[1m 23/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2527e-06\n",
            "\u001b[1m 28/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.3264e-06\n",
            "\u001b[1m 28/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.3264e-06\n",
            "\u001b[1m 34/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.3899e-06\n",
            "\u001b[1m 34/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.3899e-06\n",
            "\u001b[1m 39/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4112e-06\n",
            "\u001b[1m 39/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4112e-06\n",
            "\u001b[1m 45/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4420e-06\n",
            "\u001b[1m 45/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4420e-06\n",
            "\u001b[1m 51/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4695e-06\n",
            "\u001b[1m 51/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4695e-06\n",
            "\u001b[1m 57/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4844e-06\n",
            "\u001b[1m 57/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4844e-06\n",
            "\u001b[1m 63/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4972e-06\n",
            "\u001b[1m 63/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4972e-06\n",
            "\u001b[1m 68/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5073e-06\n",
            "\u001b[1m 68/368\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5073e-06\n",
            "\u001b[1m 74/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5232e-06\n",
            "\u001b[1m 74/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5232e-06\n",
            "\u001b[1m 80/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5409e-06\n",
            "\u001b[1m 80/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5409e-06\n",
            "\u001b[1m 86/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5589e-06\n",
            "\u001b[1m 86/368\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5589e-06\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5747e-06\n",
            "\u001b[1m 92/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5747e-06\n",
            "\u001b[1m 97/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5854e-06\n",
            "\u001b[1m 97/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5854e-06\n",
            "\u001b[1m101/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5917e-06\n",
            "\u001b[1m101/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5917e-06\n",
            "\u001b[1m106/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5980e-06\n",
            "\u001b[1m106/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5980e-06\n",
            "\u001b[1m112/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6089e-06\n",
            "\u001b[1m112/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6089e-06\n",
            "\u001b[1m118/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6185e-06\n",
            "\u001b[1m118/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6185e-06\n",
            "\u001b[1m124/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6267e-06\n",
            "\u001b[1m124/368\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6267e-06\n",
            "\u001b[1m130/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6349e-06\n",
            "\u001b[1m130/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6349e-06\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6406e-06\n",
            "\u001b[1m135/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6406e-06\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6456e-06\n",
            "\u001b[1m141/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6456e-06\n",
            "\u001b[1m147/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6493e-06\n",
            "\u001b[1m147/368\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6493e-06\n",
            "\u001b[1m153/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6537e-06\n",
            "\u001b[1m153/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6537e-06\n",
            "\u001b[1m159/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6584e-06\n",
            "\u001b[1m159/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6584e-06\n",
            "\u001b[1m165/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6636e-06\n",
            "\u001b[1m165/368\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6636e-06\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6672e-06\n",
            "\u001b[1m171/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6672e-06\n",
            "\u001b[1m176/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6690e-06\n",
            "\u001b[1m176/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6690e-06\n",
            "\u001b[1m181/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6705e-06\n",
            "\u001b[1m181/368\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6705e-06\n",
            "\u001b[1m187/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6718e-06\n",
            "\u001b[1m187/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6718e-06\n",
            "\u001b[1m193/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6723e-06\n",
            "\u001b[1m193/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6723e-06\n",
            "\u001b[1m199/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6742e-06\n",
            "\u001b[1m199/368\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6742e-06\n",
            "\u001b[1m205/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6756e-06\n",
            "\u001b[1m205/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6756e-06\n",
            "\u001b[1m211/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6768e-06\n",
            "\u001b[1m211/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6768e-06\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6778e-06\n",
            "\u001b[1m216/368\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6778e-06\n",
            "\u001b[1m222/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6791e-06\n",
            "\u001b[1m222/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6791e-06\n",
            "\u001b[1m228/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6801e-06\n",
            "\u001b[1m228/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6801e-06\n",
            "\u001b[1m234/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6809e-06\n",
            "\u001b[1m234/368\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6809e-06\n",
            "\u001b[1m240/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6811e-06\n",
            "\u001b[1m240/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6811e-06\n",
            "\u001b[1m246/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6809e-06\n",
            "\u001b[1m246/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6809e-06\n",
            "\u001b[1m252/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6810e-06\n",
            "\u001b[1m252/368\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6810e-06\n",
            "\u001b[1m258/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6817e-06\n",
            "\u001b[1m258/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6817e-06\n",
            "\u001b[1m264/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6818e-06\n",
            "\u001b[1m264/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6818e-06\n",
            "\u001b[1m270/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6814e-06\n",
            "\u001b[1m270/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6814e-06\n",
            "\u001b[1m276/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6811e-06 \n",
            "\u001b[1m276/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6811e-06 \n",
            "\u001b[1m282/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6804e-06\n",
            "\u001b[1m282/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6804e-06\n",
            "\u001b[1m287/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6794e-06\n",
            "\u001b[1m287/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6794e-06\n",
            "\u001b[1m293/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6781e-06 \n",
            "\u001b[1m293/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6781e-06 \n",
            "\u001b[1m299/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6771e-06\n",
            "\u001b[1m299/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6771e-06\n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6764e-06\n",
            "\u001b[1m305/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6764e-06\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6759e-06\n",
            "\u001b[1m311/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6759e-06\n",
            "\u001b[1m317/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6752e-06\n",
            "\u001b[1m317/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6752e-06\n",
            "\u001b[1m323/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6742e-06\n",
            "\u001b[1m323/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6742e-06\n",
            "\u001b[1m328/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6735e-06\n",
            "\u001b[1m328/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6735e-06\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6724e-06\n",
            "\u001b[1m334/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6724e-06\n",
            "\u001b[1m339/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6713e-06\n",
            "\u001b[1m339/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6713e-06\n",
            "\u001b[1m345/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6701e-06\n",
            "\u001b[1m345/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6701e-06\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6694e-06\n",
            "\u001b[1m350/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6694e-06\n",
            "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6685e-06\n",
            "\u001b[1m356/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6685e-06\n",
            "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6676e-06\n",
            "\u001b[1m362/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6676e-06\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6667e-06\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.6667e-06\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6031e-06\n",
            "\n",
            "Epoch 19/50                                           \n",
            "\n",
            "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.6031e-06\n",
            "\n",
            "Epoch 19/50                                           \n",
            "\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.8142e-06\n",
            "\u001b[1m  1/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 1.8142e-06\n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5388e-06 \n",
            "\u001b[1m  6/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.5388e-06 \n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4024e-06\n",
            "\u001b[1m 12/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.4024e-06\n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3090e-06 \n",
            "\u001b[1m 18/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.3090e-06 \n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2778e-06\n",
            "\u001b[1m 29/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2508e-06\n",
            "\u001b[1m 24/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2778e-06\n",
            "\u001b[1m 29/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2508e-06\n",
            "\u001b[1m 35/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2245e-06\n",
            "\u001b[1m 35/368\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 3.2245e-06\n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2190e-06 \n",
            "\u001b[1m 41/368\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.2190e-06 \n",
            "  0%|          | 0/50 [01:04<?, ?trial/s, best loss=?]"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure data is in dense format for TensorFlow\n",
        "X_train_resampled_dense = X_train_resampled.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "num_classes = y_train_resampled.max() + 1\n",
        "\n",
        "# 2. Define the search space for TensorFlow MLP model\n",
        "space_tf_mlp = {\n",
        "    'num_hidden_layers': hp.choice('num_hidden_layers', [1, 2, 3]),\n",
        "    'neurons_l1': hp.choice('neurons_l1', [32, 64, 128, 256]),\n",
        "    'neurons_l2': hp.choice('neurons_l2', [32, 64, 128, 256]), # Only used if num_hidden_layers >= 2\n",
        "    'neurons_l3': hp.choice('neurons_l3', [32, 64, 128, 256]), # Only used if num_hidden_layers == 3\n",
        "    'activation': hp.choice('activation', ['relu', 'tanh']),\n",
        "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
        "    'batch_size': hp.choice('batch_size', [16, 32, 64]),\n",
        "    'epochs': 50 # Fixed epochs for tuning efficiency\n",
        "}\n",
        "\n",
        "# 3. Define the objective function for hyperopt\n",
        "def objective_tf_mlp(params):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train_resampled_dense.shape[1],)))\n",
        "\n",
        "    # Add hidden layers dynamically based on 'num_hidden_layers'\n",
        "    model.add(Dense(params['neurons_l1'], activation=params['activation']))\n",
        "    if params['num_hidden_layers'] >= 2:\n",
        "        model.add(Dense(params['neurons_l2'], activation=params['activation']))\n",
        "    if params['num_hidden_layers'] == 3:\n",
        "        model.add(Dense(params['neurons_l3'], activation=params['activation']))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=params['learning_rate'])\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    try:\n",
        "        # Train the model\n",
        "        model.fit(X_train_resampled_dense, y_train_resampled, epochs=params['epochs'], batch_size=params['batch_size'])\n",
        "\n",
        "        # Evaluate the trained model\n",
        "        y_pred_proba = model.predict(X_test_dense, verbose=0)\n",
        "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "        # Calculate F1-score (macro average)\n",
        "        f1 = f1_score(y_test_encoded, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "        # hyperopt minimizes the loss, so we return negative F1-score\n",
        "        return {'loss': -f1, 'status': STATUS_OK}\n",
        "    except Exception as e:\n",
        "        print(f\"Error during TensorFlow MLP model training/evaluation: {e}\")\n",
        "        return {'loss': float('inf'), 'status': STATUS_OK}\n",
        "\n",
        "# 4. Run hyperparameter tuning\n",
        "print(\"\\n--- Hyperparameter Tuning for TensorFlow MLP (SMOTE) ---\")\n",
        "trials = Trials()\n",
        "best_params = fmin(\n",
        "    fn=objective_tf_mlp,\n",
        "    space=space_tf_mlp,\n",
        "    algo=tpe.suggest,\n",
        "    max_evals=50, # Number of evaluations\n",
        "    trials=trials,\n",
        "    rstate=np.random.default_rng(42) # For reproducibility\n",
        ")\n",
        "\n",
        "print(f\"Raw best hyperparameters: {best_params}\")\n",
        "\n",
        "# Convert best_params from hyperopt's format to usable parameters\n",
        "final_best_params = {\n",
        "    'num_hidden_layers': [1, 2, 3][best_params['num_hidden_layers']],\n",
        "    'neurons_l1': [32, 64, 128, 256][best_params['neurons_l1']],\n",
        "    'neurons_l2': [32, 64, 128, 256][best_params['neurons_l2']],\n",
        "    'neurons_l3': [32, 64, 128, 256][best_params['neurons_l3']],\n",
        "    'activation': ['relu', 'tanh'][best_params['activation']],\n",
        "    'learning_rate': best_params['learning_rate'],\n",
        "    'batch_size': [16, 32, 64][best_params['batch_size']],\n",
        "    'epochs': 50 # Fixed as per space definition\n",
        "}\n",
        "print(f\"Optimized hyperparameters for TensorFlow MLP: {final_best_params}\")\n",
        "\n",
        "# 5. Build and retrain the TensorFlow MLP model with optimal hyperparameters\n",
        "model_tf_tuned = Sequential()\n",
        "model_tf_tuned.add(Input(shape=(X_train_resampled_dense.shape[1],)))\n",
        "model_tf_tuned.add(Dense(final_best_params['neurons_l1'], activation=final_best_params['activation']))\n",
        "if final_best_params['num_hidden_layers'] >= 2:\n",
        "    model_tf_tuned.add(Dense(final_best_params['neurons_l2'], activation=final_best_params['activation']))\n",
        "if final_best_params['num_hidden_layers'] == 3:\n",
        "    model_tf_tuned.add(Dense(final_best_params['neurons_l3'], activation=final_best_params['activation']))\n",
        "model_tf_tuned.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "optimizer_tuned = Adam(learning_rate=final_best_params['learning_rate'])\n",
        "model_tf_tuned.compile(optimizer=optimizer_tuned, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Retraining TensorFlow MLP (SMOTE) with optimal parameters ---\")\n",
        "model_tf_tuned.fit(X_train_resampled_dense, y_train_resampled,\n",
        "                   epochs=final_best_params['epochs'],\n",
        "                   batch_size=final_best_params['batch_size'],\n",
        "                   verbose=0)\n",
        "print(\"Retraining complete.\")\n",
        "\n",
        "# 6. Evaluate the retrained model on the test set\n",
        "y_pred_proba_tf_tuned = model_tf_tuned.predict(X_test_dense, verbose=0)\n",
        "y_pred_tf_tuned = np.argmax(y_pred_proba_tf_tuned, axis=1)\n",
        "\n",
        "accuracy_tf_tuned = accuracy_score(y_test_encoded, y_pred_tf_tuned)\n",
        "precision_tf_tuned = precision_score(y_test_encoded, y_pred_tf_tuned, average='macro', zero_division=0)\n",
        "recall_tf_tuned = recall_score(y_test_encoded, y_pred_tf_tuned, average='macro', zero_division=0)\n",
        "f1_tf_tuned = f1_score(y_test_encoded, y_pred_tf_tuned, average='macro', zero_division=0)\n",
        "roc_auc_tf_tuned = roc_auc_score(y_test_encoded, y_pred_proba_tf_tuned, multi_class='ovr', average='macro')\n",
        "\n",
        "print(f\"\\n--- Tuned TensorFlow MLP (SMOTE) Performance ---\")\n",
        "print(f\"정확도 (Accuracy): {accuracy_tf_tuned:.4f}\")\n",
        "print(f\"정밀도 (Precision, macro): {precision_tf_tuned:.4f}\")\n",
        "print(f\"재현율 (Recall, macro): {recall_tf_tuned:.4f}\")\n",
        "print(f\"F1 스코어 (F1 Score, macro): {f1_tf_tuned:.4f}\")\n",
        "print(f\"ROC AUC (macro, ovr): {roc_auc_tf_tuned:.4f}\")\n",
        "\n",
        "# 7. Add results to the existing 'results' dictionary\n",
        "results['TensorFlow MLP (Tuned, SMOTE)'] = {\n",
        "    'accuracy': accuracy_tf_tuned,\n",
        "    'precision': precision_tf_tuned,\n",
        "    'recall': recall_tf_tuned,\n",
        "    'f1_score': f1_tf_tuned,\n",
        "    'roc_auc': roc_auc_tf_tuned\n",
        "}\n",
        "\n",
        "# 8. Update and display the final performance summary\n",
        "print(\"\\n--- 모델 성능 요약 (TensorFlow MLP (Tuned, SMOTE) 추가) ---\")\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "print(\"\\n모델 성능 요약 (최종 업데이트):\")\n",
        "display(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MkAG35UaRYf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}